{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JXGJyNxO-wpl",
        "outputId": "38b361ba-12d5-4bc8-a4f4-420084c2fb60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.17.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=f725b84d1b56b5b303d92c5fefd2654e28bcea40eec7a89bf09c97c39e132f5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.1.0 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.23.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.28)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.17.4)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.35.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.182.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
            "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.7.0\n",
            "    Uninstalling google-ai-generativelanguage-0.7.0:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "adaef472474246229c4807a17caf2a40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.30)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.28)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.1.12)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.3.76)\n",
            "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.9)\n",
            "Requirement already satisfied: filetype<2,>=1.2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.32.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.75.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.75->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.3.1)\n",
            "Using cached google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "87332a9cd3ae4792b808df65e03c80eb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "!pip install langchain chromadb pypdf sentence-transformers huggingface_hub PyPDF2\n",
        "!pip install openai langchain chromadb pypdf tiktoken\n",
        "!pip install google-generativeai\n",
        "!pip install -U langchain-community\n",
        "!pip install langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mexc6aBhw5XC"
      },
      "source": [
        "#import pdf into file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3E5TQqow5BN"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import requests\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "temp_db_dir = tempfile.mkdtemp()\n",
        "# --- Load PDF and split ---\n",
        "pdf_url = \"https://arxiv.org/pdf/1706.03762\"\n",
        "pdf_path = \"sample.pdf\"\n",
        "\n",
        "# Download and save PDF\n",
        "with open(pdf_path, \"wb\") as f:\n",
        "    f.write(requests.get(pdf_url).content)\n",
        "docs = PyPDFLoader(\"sample.pdf\").load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoBWD33aAEg-"
      },
      "source": [
        "# **tradtional RAG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ohjG5WaqIyK"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader # Corrected import\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.schema import SystemMessage\n",
        "from dotenv import dotenv_values\n",
        "import os\n",
        "import shutil\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "import tempfile\n",
        "import requests\n",
        "\n",
        "temp_db_dir = tempfile.mkdtemp()\n",
        "# --- Load PDF and split ---\n",
        "pdf_url = \"https://arxiv.org/pdf/2212.04356\"\n",
        "pdf_path = \"sample.pdf\"\n",
        "\n",
        "# Download and save PDF\n",
        "with open(pdf_path, \"wb\") as f:\n",
        "    f.write(requests.get(pdf_url).content)\n",
        "docs = PyPDFLoader(\"sample.pdf\").load()\n",
        "chunks = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50).split_documents(docs)\n",
        "\n",
        "# --- Embed and store vectors ---\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=temp_db_dir)\n",
        "retriever = vectordb.as_retriever()\n",
        "# --- Ask question & retrieve context ---\n",
        "question = \"what is the core idea of this model?\"\n",
        "context = \"\\n\".join([doc.page_content for doc in retriever.get_relevant_documents(question)])\n",
        "\n",
        "# --- Load Gemini API key ---\n",
        "env_values = dotenv_values(\"/content/app.env\")\n",
        "google_api_key = env_values[\"GOOGLE_API_KEY\"]\n",
        "\n",
        "# --- Set up Gemini LLM ---\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.95, google_api_key=google_api_key)\n",
        "\n",
        "# --- Build prompt and get answer ---\n",
        "final_prompt = f\"You are a helpful assistant. Use the context below to answer the question.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"\n",
        "response = llm.invoke([SystemMessage(content=\"You are a helpful assistant.\"), HumanMessage(content=final_prompt)])\n",
        "\n",
        "# --- Output answer ---\n",
        "print(\"\\n💬 Answer:\\n\", response.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PdQxq-4_smC"
      },
      "source": [
        "# **with MMR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMuXNuPI-Vkh"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.schema import SystemMessage\n",
        "from dotenv import dotenv_values\n",
        "import os\n",
        "import shutil\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "import tempfile\n",
        "\n",
        "\n",
        "temp_db_dir = tempfile.mkdtemp()\n",
        "# --- Load PDF and split ---\n",
        "docs = PyPDFLoader(\"sample.pdf\").load()\n",
        "chunks = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50).split_documents(docs)\n",
        "\n",
        "# --- Embed and store vectors ---\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=temp_db_dir)\n",
        "retriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\n",
        "    \"k\": 5,         # number of documents to fetch\n",
        "    \"fetch_k\": 10,  # candidate pool size before MMR filters\n",
        "    \"lambda_mult\": 0.5  # balance between relevance and diversity\n",
        "})# --- Ask question & retrieve context ---\n",
        "question = \"what is the core idea of thi model?\"\n",
        "context = \"\\n\".join([doc.page_content for doc in retriever.get_relevant_documents(question)])\n",
        "\n",
        "# --- Load Gemini API key ---\n",
        "env_values = dotenv_values(\"/content/app.env\")\n",
        "google_api_key = env_values[\"GOOGLE_API_KEY\"]\n",
        "\n",
        "# --- Set up Gemini LLM ---\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.95, google_api_key=google_api_key)\n",
        "\n",
        "# --- Build prompt and get answer ---\n",
        "final_prompt = f\"You are a helpful assistant. Use the context below to answer the question.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"\n",
        "response = llm.invoke([SystemMessage(content=\"You are a helpful assistant.\"), HumanMessage(content=final_prompt)])\n",
        "\n",
        "# --- Output answer ---\n",
        "print(\"\\n💬 Answer:\\n\", response.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4u-NuRukrcX"
      },
      "source": [
        "# **with history**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6G1YV75QClJl"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from dotenv import dotenv_values\n",
        "import os, shutil\n",
        "\n",
        "# --- Step 1: Clear Chroma DB ---\n",
        "db_path = \"/content/chroma_db\"\n",
        "if os.path.exists(db_path):\n",
        "    shutil.rmtree(db_path)\n",
        "\n",
        "# --- Step 2: Load and split PDF ---\n",
        "loader = PyPDFLoader(\"sample.pdf\")\n",
        "documents = loader.load()\n",
        "chunks = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50).split_documents(documents)\n",
        "\n",
        "# --- Step 3: Embedding and DB ---\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_path)\n",
        "\n",
        "# --- Step 4: Load API key ---\n",
        "env_values = dotenv_values(\"app.env\")\n",
        "google_api_key = env_values[\"GOOGLE_API_KEY\"]\n",
        "\n",
        "# --- Step 5: Set up LLM ---\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.7,\n",
        "    google_api_key=google_api_key\n",
        ")\n",
        "\n",
        "# --- Step 6: Memory ---\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# --- Step 7: Conversational Retrieval with MMR ---\n",
        "retriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4, \"fetch_k\": 10})\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# --- Step 8: Chat interaction ---\n",
        "print(\"💬 Start chatting with the document (type 'exit' to stop):\\n\")\n",
        "while True:\n",
        "    user_input = input(\"👤 You: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    result = qa_chain.run(user_input)\n",
        "    print(\"🤖 AI:\", result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QsVfL38liMF"
      },
      "source": [
        "\n",
        "#*knowledge graph*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umsqNdJylhSp",
        "outputId": "e40bf4d7-5bb2-47c8-a5ba-1ff19fca2bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.1.12)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.12/dist-packages (5.28.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.30)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: filetype<2,>=1.2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from neo4j) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.75.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-google-genai PyPDF2 neo4j openai langchain-community pypdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5hBvl9mi74H"
      },
      "source": [
        "#knowledge graph with pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmEdfY2ni4KN",
        "outputId": "28a9d719-7a85-4f44-8fe0-6889a46ba1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URI: neo4j+s://2b4c3002.databases.neo4j.io\n",
            "USER: neo4j\n",
            "PASSWORD: SblDQNAj0l1pdRtxkdg7pTo7L2MJWXY4FbNH6T3qayE\n",
            "🧹 Neo4j database cleared.\n",
            "🔍 Processing chunk_1...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Speech Recognition\", \"related_to_core\", \"Weak Supervision\"), (\"Large-Scale\", \"related_to_core\", \"Weak Supervision\"), (\"Weak Supervision\", \"is_core_idea\", \"true\"), (\"chunk_1\", \"is_core_chunk\", \"true\"), (\"transcripts\", \"related_to_core\", \"Weak Supervision\"), (\"audio\", \"related_to_core\", \"Weak Supervision\"), (\"internet\", \"related_to_core\", \"Weak Supervision\"), (\"multilingual\", \"related_to_core\", \"Weak Supervision\"), (\"multitask supervision\", \"related_to_core\", \"Weak Supervision\"), (\"models\", \"related_to_core\", \"Weak Supervision\"), (\"benchmarks\", \"related_to_core\", \"Weak Supervision\"), (\"Speech Recognition\", \"via\", \"Weak Supervision\"), (\"chunk_1\", \"mentions\", \"Speech Recognition\"), (\"chunk_1\", \"mentions\", \"Large-Scale\"), (\"chunk_1\", \"mentions\", \"Weak Supervision\"), (\"chunk_1\", \"mentions\", \"transcripts\"), (\"chunk_1\", \"mentions\", \"audio\"), (\"chunk_1\", \"mentions\", \"internet\"), (\"chunk_1\", \"mentions\", \"multilingual\"), (\"chunk_1\", \"mentions\", \"multitask supervision\"), (\"chunk_1\", \"mentions\", \"models\"), (\"chunk_1\", \"mentions\", \"benchmarks\")]\n",
            "✅ Extracted: [('Speech Recognition', 'related_to_core', 'Weak Supervision'), ('Large-Scale', 'related_to_core', 'Weak Supervision'), ('Weak Supervision', 'is_core_idea', 'true'), ('chunk_1', 'is_core_chunk', 'true'), ('transcripts', 'related_to_core', 'Weak Supervision'), ('audio', 'related_to_core', 'Weak Supervision'), ('internet', 'related_to_core', 'Weak Supervision'), ('multilingual', 'related_to_core', 'Weak Supervision'), ('multitask supervision', 'related_to_core', 'Weak Supervision'), ('models', 'related_to_core', 'Weak Supervision'), ('benchmarks', 'related_to_core', 'Weak Supervision'), ('Speech Recognition', 'via', 'Weak Supervision'), ('chunk_1', 'mentions', 'Speech Recognition'), ('chunk_1', 'mentions', 'Large-Scale'), ('chunk_1', 'mentions', 'Weak Supervision'), ('chunk_1', 'mentions', 'transcripts'), ('chunk_1', 'mentions', 'audio'), ('chunk_1', 'mentions', 'internet'), ('chunk_1', 'mentions', 'multilingual'), ('chunk_1', 'mentions', 'multitask supervision'), ('chunk_1', 'mentions', 'models'), ('chunk_1', 'mentions', 'benchmarks')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_2...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"standard benchmarks\", \"related_to_core\", \"speech recognition\"), (\"models\", \"related_to_core\", \"speech recognition\"), (\"inference code\", \"related_to_core\", \"speech recognition\"), (\"robust speech processing\", \"related_to_core\", \"speech recognition\"), (\"speech recognition\", \"is_core_idea\", \"true\"), (\"unsupervised pre-training techniques\", \"related_to_core\", \"speech recognition\"), (\"chunk_2\", \"mentions\", \"standard benchmarks\"), (\"chunk_2\", \"mentions\", \"models\"), (\"chunk_2\", \"mentions\", \"inference code\"), (\"chunk_2\", \"mentions\", \"robust speech processing\"), (\"chunk_2\", \"mentions\", \"speech recognition\"), (\"chunk_2\", \"mentions\", \"unsupervised pre-training techniques\"), (\"speech recognition\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('standard benchmarks', 'related_to_core', 'speech recognition'), ('models', 'related_to_core', 'speech recognition'), ('inference code', 'related_to_core', 'speech recognition'), ('robust speech processing', 'related_to_core', 'speech recognition'), ('speech recognition', 'is_core_idea', 'true'), ('unsupervised pre-training techniques', 'related_to_core', 'speech recognition'), ('chunk_2', 'mentions', 'standard benchmarks'), ('chunk_2', 'mentions', 'models'), ('chunk_2', 'mentions', 'inference code'), ('chunk_2', 'mentions', 'robust speech processing'), ('chunk_2', 'mentions', 'speech recognition'), ('chunk_2', 'mentions', 'unsupervised pre-training techniques'), ('speech recognition', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_3...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Wav2Vec 2.0\", \"is_a\", \"method\"), (\"raw audio\", \"is_a\", \"data\"), (\"human labels\", \"is_a\", \"label\"), (\"speech\", \"is_a\", \"data\"), (\"datasets\", \"is_a\", \"data\"), (\"training data\", \"is_a\", \"data\"), (\"academic supervised dataset\", \"is_a\", \"dataset\"), (\"benchmarks\", \"is_a\", \"standard\"), (\"approach\", \"is_a\", \"method\"), (\"low-data setting\", \"is_a\", \"setting\"), (\"Wav2Vec 2.0\", \"learns_from\", \"raw audio\"), (\"methods\", \"learn_from\", \"raw audio\"), (\"methods\", \"require\", \"human labels\"), (\"methods\", \"use\", \"datasets\"), (\"methods\", \"scale_up_to\", \"training data\"), (\"approach\", \"fine_tuned_on\", \"benchmarks\"), (\"approach\", \"improves\", \"state of the art\"), (\"approach\", \"is_used_in\", \"low-data setting\"), (\"chunk_3\", \"mentions\", \"Wav2Vec 2.0\"), (\"chunk_3\", \"mentions\", \"raw audio\"), (\"chunk_3\", \"mentions\", \"human labels\"), (\"chunk_3\", \"mentions\", \"speech\"), (\"chunk_3\", \"mentions\", \"datasets\"), (\"chunk_3\", \"mentions\", \"training data\"), (\"chunk_3\", \"mentions\", \"academic supervised dataset\"), (\"chunk_3\", \"mentions\", \"benchmarks\"), (\"chunk_3\", \"mentions\", \"approach\"), (\"chunk_3\", \"mentions\", \"low-data setting\"), (\"Wav2Vec 2.0\", \"is_core_idea\", \"true\"), (\"chunk_3\", \"is_core_chunk\", \"true\"), (\"raw audio\", \"related_to_core\", \"Wav2Vec 2.0\"), (\"human labels\", \"related_to_core\", \"Wav2Vec 2.0\"), (\"speech\", \"related_to_core\", \"Wav2Vec 2.0\"), (\"datasets\", \"related_to_core\", \"Wav2Vec 2.0\"), (\"training data\", \"related_to_core\", \"Wav2Vec 2.0\"), (\"academic supervised dataset\", \"related_to_core\", \"Wav2Vec 2.0\"), (\"benchmarks\", \"related_to_core\", \"Wav2Vec 2.0\"), (\"approach\", \"related_to_core\", \"Wav2Vec 2.0\"), (\"low-data setting\", \"related_to_core\", \"Wav2Vec 2.0\")]\n",
            "✅ Extracted: [('Wav2Vec 2.0', 'is_a', 'method'), ('raw audio', 'is_a', 'data'), ('human labels', 'is_a', 'label'), ('speech', 'is_a', 'data'), ('datasets', 'is_a', 'data'), ('training data', 'is_a', 'data'), ('academic supervised dataset', 'is_a', 'dataset'), ('benchmarks', 'is_a', 'standard'), ('approach', 'is_a', 'method'), ('low-data setting', 'is_a', 'setting'), ('Wav2Vec 2.0', 'learns_from', 'raw audio'), ('methods', 'learn_from', 'raw audio'), ('methods', 'require', 'human labels'), ('methods', 'use', 'datasets'), ('methods', 'scale_up_to', 'training data'), ('approach', 'fine_tuned_on', 'benchmarks'), ('approach', 'improves', 'state of the art'), ('approach', 'is_used_in', 'low-data setting'), ('chunk_3', 'mentions', 'Wav2Vec 2.0'), ('chunk_3', 'mentions', 'raw audio'), ('chunk_3', 'mentions', 'human labels'), ('chunk_3', 'mentions', 'speech'), ('chunk_3', 'mentions', 'datasets'), ('chunk_3', 'mentions', 'training data'), ('chunk_3', 'mentions', 'academic supervised dataset'), ('chunk_3', 'mentions', 'benchmarks'), ('chunk_3', 'mentions', 'approach'), ('chunk_3', 'mentions', 'low-data setting'), ('Wav2Vec 2.0', 'is_core_idea', 'true'), ('chunk_3', 'is_core_chunk', 'true'), ('raw audio', 'related_to_core', 'Wav2Vec 2.0'), ('human labels', 'related_to_core', 'Wav2Vec 2.0'), ('speech', 'related_to_core', 'Wav2Vec 2.0'), ('datasets', 'related_to_core', 'Wav2Vec 2.0'), ('training data', 'related_to_core', 'Wav2Vec 2.0'), ('academic supervised dataset', 'related_to_core', 'Wav2Vec 2.0'), ('benchmarks', 'related_to_core', 'Wav2Vec 2.0'), ('approach', 'related_to_core', 'Wav2Vec 2.0'), ('low-data setting', 'related_to_core', 'Wav2Vec 2.0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_4...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"pre-trained audio encoders\", \"learn\", \"high-quality representations\"), (\"pre-trained audio encoders\", \"lack\", \"decoder mapping\"), (\"decoder mapping\", \"maps\", \"representations\"), (\"representations\", \"to\", \"usable outputs\"), (\"speech\", \"has_representation\", \"high-quality representations\"), (\"speech recognition\", \"requires\", \"fine-tuning stage\"), (\"fine-tuning stage\", \"is\", \"complex process\"), (\"fine-tuning stage\", \"requires\", \"skilled practitioner\"), (\"chunk_4\", \"mentions\", \"pre-trained audio encoders\"), (\"chunk_4\", \"mentions\", \"high-quality representations\"), (\"chunk_4\", \"mentions\", \"speech\"), (\"chunk_4\", \"mentions\", \"decoder mapping\"), (\"chunk_4\", \"mentions\", \"representations\"), (\"chunk_4\", \"mentions\", \"usable outputs\"), (\"chunk_4\", \"mentions\", \"speech recognition\"), (\"chunk_4\", \"mentions\", \"fine-tuning stage\"), (\"chunk_4\", \"mentions\", \"skilled practitioner\"), (\"pre-trained audio encoders\", \"is_core_idea\", \"true\"), (\"chunk_4\", \"is_core_chunk\", \"true\"), (\"high-quality representations\", \"related_to_core\", \"pre-trained audio encoders\"), (\"speech\", \"related_to_core\", \"pre-trained audio encoders\"), (\"decoder mapping\", \"related_to_core\", \"pre-trained audio encoders\"), (\"representations\", \"related_to_core\", \"pre-trained audio encoders\"), (\"usable outputs\", \"related_to_core\", \"pre-trained audio encoders\"), (\"speech recognition\", \"related_to_core\", \"pre-trained audio encoders\"), (\"fine-tuning stage\", \"related_to_core\", \"pre-trained audio encoders\"), (\"skilled practitioner\", \"related_to_core\", \"pre-trained audio encoders\")]\n",
            "✅ Extracted: [('pre-trained audio encoders', 'learn', 'high-quality representations'), ('pre-trained audio encoders', 'lack', 'decoder mapping'), ('decoder mapping', 'maps', 'representations'), ('representations', 'to', 'usable outputs'), ('speech', 'has_representation', 'high-quality representations'), ('speech recognition', 'requires', 'fine-tuning stage'), ('fine-tuning stage', 'is', 'complex process'), ('fine-tuning stage', 'requires', 'skilled practitioner'), ('chunk_4', 'mentions', 'pre-trained audio encoders'), ('chunk_4', 'mentions', 'high-quality representations'), ('chunk_4', 'mentions', 'speech'), ('chunk_4', 'mentions', 'decoder mapping'), ('chunk_4', 'mentions', 'representations'), ('chunk_4', 'mentions', 'usable outputs'), ('chunk_4', 'mentions', 'speech recognition'), ('chunk_4', 'mentions', 'fine-tuning stage'), ('chunk_4', 'mentions', 'skilled practitioner'), ('pre-trained audio encoders', 'is_core_idea', 'true'), ('chunk_4', 'is_core_chunk', 'true'), ('high-quality representations', 'related_to_core', 'pre-trained audio encoders'), ('speech', 'related_to_core', 'pre-trained audio encoders'), ('decoder mapping', 'related_to_core', 'pre-trained audio encoders'), ('representations', 'related_to_core', 'pre-trained audio encoders'), ('usable outputs', 'related_to_core', 'pre-trained audio encoders'), ('speech recognition', 'related_to_core', 'pre-trained audio encoders'), ('fine-tuning stage', 'related_to_core', 'pre-trained audio encoders'), ('skilled practitioner', 'related_to_core', 'pre-trained audio encoders')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_5...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Machine learning methods\", \"are_adept_at\", \"finding patterns\"), (\"training dataset\", \"boost\", \"performance\"), (\"held-out data\", \"is_from\", \"same dataset\"), (\"chunk_5\", \"mentions\", \"Machine learning methods\"), (\"chunk_5\", \"mentions\", \"training dataset\"), (\"chunk_5\", \"mentions\", \"held-out data\"), (\"Machine learning methods\", \"is_core_idea\", \"true\"), (\"chunk_5\", \"is_core_chunk\", \"true\"), (\"training dataset\", \"related_to_core\", \"Machine learning methods\"), (\"held-out data\", \"related_to_core\", \"Machine learning methods\")]\n",
            "✅ Extracted: [('Machine learning methods', 'are_adept_at', 'finding patterns'), ('training dataset', 'boost', 'performance'), ('held-out data', 'is_from', 'same dataset'), ('chunk_5', 'mentions', 'Machine learning methods'), ('chunk_5', 'mentions', 'training dataset'), ('chunk_5', 'mentions', 'held-out data'), ('Machine learning methods', 'is_core_idea', 'true'), ('chunk_5', 'is_core_chunk', 'true'), ('training dataset', 'related_to_core', 'Machine learning methods'), ('held-out data', 'related_to_core', 'Machine learning methods')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_6...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"datasets\", \"mentions\", \"datasets\"), (\"distributions\", \"mentions\", \"distributions\"), (\"Radford et al. (2021)\", \"mentions\", \"Radford et al. (2021)\"), (\"object classiﬁcation accuracy\", \"mentions\", \"object classiﬁcation accuracy\"), (\"computer vision model\", \"mentions\", \"computer vision model\"), (\"ImageNet dataset\", \"mentions\", \"ImageNet dataset\"), (\"Russakovsky et al., 2015\", \"mentions\", \"Russakovsky et al., 2015\"), (\"average accuracy\", \"mentions\", \"average accuracy\"), (\"objects\", \"mentions\", \"objects\"), (\"image datasets\", \"mentions\", \"image datasets\"), (\"chunk_6\", \"mentions\", \"datasets\"), (\"chunk_6\", \"mentions\", \"distributions\"), (\"chunk_6\", \"mentions\", \"Radford et al. (2021)\"), (\"chunk_6\", \"mentions\", \"object classiﬁcation accuracy\"), (\"chunk_6\", \"mentions\", \"computer vision model\"), (\"chunk_6\", \"mentions\", \"ImageNet dataset\"), (\"chunk_6\", \"mentions\", \"Russakovsky et al., 2015\"), (\"chunk_6\", \"mentions\", \"average accuracy\"), (\"chunk_6\", \"mentions\", \"objects\"), (\"chunk_6\", \"mentions\", \"image datasets\"), (\"object classiﬁcation accuracy\", \"related_to_core\", \"computer vision model\"), (\"datasets\", \"related_to_core\", \"computer vision model\"), (\"distributions\", \"related_to_core\", \"computer vision model\"), (\"Radford et al. (2021)\", \"related_to_core\", \"computer vision model\"), (\"ImageNet dataset\", \"related_to_core\", \"computer vision model\"), (\"Russakovsky et al., 2015\", \"related_to_core\", \"computer vision model\"), (\"average accuracy\", \"related_to_core\", \"computer vision model\"), (\"objects\", \"related_to_core\", \"computer vision model\"), (\"image datasets\", \"related_to_core\", \"computer vision model\"), (\"computer vision model\", \"is_core_idea\", \"true\"), (\"chunk_6\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('datasets', 'mentions', 'datasets'), ('distributions', 'mentions', 'distributions'), ('Radford et al. (2021)', 'mentions', 'Radford et al. (2021)'), ('object classiﬁcation accuracy', 'mentions', 'object classiﬁcation accuracy'), ('computer vision model', 'mentions', 'computer vision model'), ('ImageNet dataset', 'mentions', 'ImageNet dataset'), ('Russakovsky et al., 2015', 'mentions', 'Russakovsky et al., 2015'), ('average accuracy', 'mentions', 'average accuracy'), ('objects', 'mentions', 'objects'), ('image datasets', 'mentions', 'image datasets'), ('chunk_6', 'mentions', 'datasets'), ('chunk_6', 'mentions', 'distributions'), ('chunk_6', 'mentions', 'Radford et al. (2021)'), ('chunk_6', 'mentions', 'object classiﬁcation accuracy'), ('chunk_6', 'mentions', 'computer vision model'), ('chunk_6', 'mentions', 'ImageNet dataset'), ('chunk_6', 'mentions', 'Russakovsky et al., 2015'), ('chunk_6', 'mentions', 'average accuracy'), ('chunk_6', 'mentions', 'objects'), ('chunk_6', 'mentions', 'image datasets'), ('object classiﬁcation accuracy', 'related_to_core', 'computer vision model'), ('datasets', 'related_to_core', 'computer vision model'), ('distributions', 'related_to_core', 'computer vision model'), ('Radford et al. (2021)', 'related_to_core', 'computer vision model'), ('ImageNet dataset', 'related_to_core', 'computer vision model'), ('Russakovsky et al., 2015', 'related_to_core', 'computer vision model'), ('average accuracy', 'related_to_core', 'computer vision model'), ('objects', 'related_to_core', 'computer vision model'), ('image datasets', 'related_to_core', 'computer vision model'), ('computer vision model', 'is_core_idea', 'true'), ('chunk_6', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_7...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"dataset\", \"instance_of\", \"entity\"), (\"errors\", \"instance_of\", \"entity\"), (\"dataset-speciﬁc quirks\", \"instance_of\", \"entity\"), (\"humans\", \"instance_of\", \"entity\"), (\"unsupervised pre-training\", \"instance_of\", \"technique\"), (\"audio encoders\", \"instance_of\", \"model\"), (\"decoder\", \"instance_of\", \"model\"), (\"dataset-speciﬁc\", \"instance_of\", \"property\"), (\"unsupervised pre-training\", \"improved\", \"quality\"), (\"audio encoders\", \"part_of\", \"system\"), (\"decoder\", \"part_of\", \"system\"), (\"chunk_7\", \"mentions\", \"dataset\"), (\"chunk_7\", \"mentions\", \"errors\"), (\"chunk_7\", \"mentions\", \"dataset-speciﬁc quirks\"), (\"chunk_7\", \"mentions\", \"humans\"), (\"chunk_7\", \"mentions\", \"unsupervised pre-training\"), (\"chunk_7\", \"mentions\", \"audio encoders\"), (\"chunk_7\", \"mentions\", \"decoder\"), (\"chunk_7\", \"mentions\", \"dataset-speciﬁc\"), (\"dataset\", \"is_core_idea\", \"true\"), (\"chunk_7\", \"is_core_chunk\", \"true\"), (\"errors\", \"related_to_core\", \"dataset\"), (\"dataset-speciﬁc quirks\", \"related_to_core\", \"dataset\"), (\"humans\", \"related_to_core\", \"dataset\"), (\"unsupervised pre-training\", \"related_to_core\", \"dataset\"), (\"audio encoders\", \"related_to_core\", \"dataset\"), (\"decoder\", \"related_to_core\", \"dataset\"), (\"dataset-speciﬁc\", \"related_to_core\", \"dataset\")]\n",
            "✅ Extracted: [('dataset', 'instance_of', 'entity'), ('errors', 'instance_of', 'entity'), ('dataset-speciﬁc quirks', 'instance_of', 'entity'), ('humans', 'instance_of', 'entity'), ('unsupervised pre-training', 'instance_of', 'technique'), ('audio encoders', 'instance_of', 'model'), ('decoder', 'instance_of', 'model'), ('dataset-speciﬁc', 'instance_of', 'property'), ('unsupervised pre-training', 'improved', 'quality'), ('audio encoders', 'part_of', 'system'), ('decoder', 'part_of', 'system'), ('chunk_7', 'mentions', 'dataset'), ('chunk_7', 'mentions', 'errors'), ('chunk_7', 'mentions', 'dataset-speciﬁc quirks'), ('chunk_7', 'mentions', 'humans'), ('chunk_7', 'mentions', 'unsupervised pre-training'), ('chunk_7', 'mentions', 'audio encoders'), ('chunk_7', 'mentions', 'decoder'), ('chunk_7', 'mentions', 'dataset-speciﬁc'), ('dataset', 'is_core_idea', 'true'), ('chunk_7', 'is_core_chunk', 'true'), ('errors', 'related_to_core', 'dataset'), ('dataset-speciﬁc quirks', 'related_to_core', 'dataset'), ('humans', 'related_to_core', 'dataset'), ('unsupervised pre-training', 'related_to_core', 'dataset'), ('audio encoders', 'related_to_core', 'dataset'), ('decoder', 'related_to_core', 'dataset'), ('dataset-speciﬁc', 'related_to_core', 'dataset')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_8...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"tuning\", \"is_a\", \"weakness\"), (\"speech recognition system\", \"has_goal\", \"work reliably\"), (\"decoder\", \"requires\", \"supervised ﬁne-tuning\"), (\"deployment distribution\", \"is_for\", \"decoder\"), (\"Narayanan et al. (2018)\", \"demonstrated\", \"speech recognition systems\"), (\"Likhomanenko et al. (2020)\", \"demonstrated\", \"speech recognition systems\"), (\"Chan et al. (2021)\", \"demonstrated\", \"speech recognition systems\"), (\"speech recognition systems\", \"are\", \"pre-trained\"), (\"chunk_8\", \"mentions\", \"tuning\"), (\"chunk_8\", \"mentions\", \"speech recognition system\"), (\"chunk_8\", \"mentions\", \"decoder\"), (\"chunk_8\", \"mentions\", \"deployment distribution\"), (\"chunk_8\", \"mentions\", \"Narayanan et al. (2018)\"), (\"chunk_8\", \"mentions\", \"Likhomanenko et al. (2020)\"), (\"chunk_8\", \"mentions\", \"Chan et al. (2021)\"), (\"chunk_8\", \"mentions\", \"speech recognition systems\"), (\"tuning\", \"is_core_idea\", \"true\"), (\"chunk_8\", \"is_core_chunk\", \"true\"), (\"speech recognition system\", \"related_to_core\", \"tuning\"), (\"decoder\", \"related_to_core\", \"tuning\"), (\"deployment distribution\", \"related_to_core\", \"tuning\"), (\"Narayanan et al. (2018)\", \"related_to_core\", \"tuning\"), (\"Likhomanenko et al. (2020)\", \"related_to_core\", \"tuning\"), (\"Chan et al. (2021)\", \"related_to_core\", \"tuning\"), (\"speech recognition systems\", \"related_to_core\", \"tuning\")]\n",
            "✅ Extracted: [('tuning', 'is_a', 'weakness'), ('speech recognition system', 'has_goal', 'work reliably'), ('decoder', 'requires', 'supervised ﬁne-tuning'), ('deployment distribution', 'is_for', 'decoder'), ('Narayanan et al. (2018)', 'demonstrated', 'speech recognition systems'), ('Likhomanenko et al. (2020)', 'demonstrated', 'speech recognition systems'), ('Chan et al. (2021)', 'demonstrated', 'speech recognition systems'), ('speech recognition systems', 'are', 'pre-trained'), ('chunk_8', 'mentions', 'tuning'), ('chunk_8', 'mentions', 'speech recognition system'), ('chunk_8', 'mentions', 'decoder'), ('chunk_8', 'mentions', 'deployment distribution'), ('chunk_8', 'mentions', 'Narayanan et al. (2018)'), ('chunk_8', 'mentions', 'Likhomanenko et al. (2020)'), ('chunk_8', 'mentions', 'Chan et al. (2021)'), ('chunk_8', 'mentions', 'speech recognition systems'), ('tuning', 'is_core_idea', 'true'), ('chunk_8', 'is_core_chunk', 'true'), ('speech recognition system', 'related_to_core', 'tuning'), ('decoder', 'related_to_core', 'tuning'), ('deployment distribution', 'related_to_core', 'tuning'), ('Narayanan et al. (2018)', 'related_to_core', 'tuning'), ('Likhomanenko et al. (2020)', 'related_to_core', 'tuning'), ('Chan et al. (2021)', 'related_to_core', 'tuning'), ('speech recognition systems', 'related_to_core', 'tuning')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_9...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"datasets/domains\", \"exhibit\", \"higher robustness\"), (\"datasets/domains\", \"generalize\", \"held-out datasets\"), (\"models\", \"trained on\", \"single source\"), (\"datasets/domains\", \"combining\", \"speech recognition datasets\"), (\"SpeechStew\", \"mixes together\", \"datasets\"), (\"SpeechStew\", \"mixes together\", \"pre-existing datasets\"), (\"supervision\", \"amount\", \"5,140 hours\"), (\"chunk_9\", \"mentions\", \"datasets/domains\"), (\"chunk_9\", \"mentions\", \"robustness\"), (\"chunk_9\", \"mentions\", \"held-out datasets\"), (\"chunk_9\", \"mentions\", \"models\"), (\"chunk_9\", \"mentions\", \"single source\"), (\"chunk_9\", \"mentions\", \"speech recognition datasets\"), (\"chunk_9\", \"mentions\", \"SpeechStew\"), (\"chunk_9\", \"mentions\", \"datasets\"), (\"chunk_9\", \"mentions\", \"pre-existing datasets\"), (\"chunk_9\", \"mentions\", \"supervision\"), (\"datasets/domains\", \"is_core_idea\", \"true\"), (\"chunk_9\", \"is_core_chunk\", \"true\"), (\"robustness\", \"related_to_core\", \"datasets/domains\"), (\"held-out datasets\", \"related_to_core\", \"datasets/domains\"), (\"models\", \"related_to_core\", \"datasets/domains\"), (\"single source\", \"related_to_core\", \"datasets/domains\"), (\"speech recognition datasets\", \"related_to_core\", \"datasets/domains\"), (\"SpeechStew\", \"related_to_core\", \"datasets/domains\"), (\"datasets\", \"related_to_core\", \"datasets/domains\"), (\"pre-existing datasets\", \"related_to_core\", \"datasets/domains\"), (\"supervision\", \"related_to_core\", \"datasets/domains\")]\n",
            "✅ Extracted: [('datasets/domains', 'exhibit', 'higher robustness'), ('datasets/domains', 'generalize', 'held-out datasets'), ('models', 'trained on', 'single source'), ('datasets/domains', 'combining', 'speech recognition datasets'), ('SpeechStew', 'mixes together', 'datasets'), ('SpeechStew', 'mixes together', 'pre-existing datasets'), ('supervision', 'amount', '5,140 hours'), ('chunk_9', 'mentions', 'datasets/domains'), ('chunk_9', 'mentions', 'robustness'), ('chunk_9', 'mentions', 'held-out datasets'), ('chunk_9', 'mentions', 'models'), ('chunk_9', 'mentions', 'single source'), ('chunk_9', 'mentions', 'speech recognition datasets'), ('chunk_9', 'mentions', 'SpeechStew'), ('chunk_9', 'mentions', 'datasets'), ('chunk_9', 'mentions', 'pre-existing datasets'), ('chunk_9', 'mentions', 'supervision'), ('datasets/domains', 'is_core_idea', 'true'), ('chunk_9', 'is_core_chunk', 'true'), ('robustness', 'related_to_core', 'datasets/domains'), ('held-out datasets', 'related_to_core', 'datasets/domains'), ('models', 'related_to_core', 'datasets/domains'), ('single source', 'related_to_core', 'datasets/domains'), ('speech recognition datasets', 'related_to_core', 'datasets/domains'), ('SpeechStew', 'related_to_core', 'datasets/domains'), ('datasets', 'related_to_core', 'datasets/domains'), ('pre-existing datasets', 'related_to_core', 'datasets/domains'), ('supervision', 'related_to_core', 'datasets/domains')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_10...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"unlabeled speech data\", \"utilized in\", \"Zhang et al. (2021)\"), (\"speech recognition\", \"related_to_core\", \"datasets\"), (\"datasets\", \"is_core_idea\", \"true\"), (\"chunk_10\", \"is_core_chunk\", \"true\"), (\"Chen et al. (2021)\", \"make use of\", \"automated\"), (\"Galvez et al. (2021)\", \"make use of\", \"automated\"), (\"unlabeled speech data\", \"related_to_core\", \"datasets\"), (\"Zhang et al. (2021)\", \"related_to_core\", \"datasets\"), (\"Chen et al. (2021)\", \"related_to_core\", \"datasets\"), (\"Galvez et al. (2021)\", \"related_to_core\", \"datasets\"), (\"chunk_10\", \"mentions\", \"unlabeled speech data\"), (\"chunk_10\", \"mentions\", \"Zhang et al. (2021)\"), (\"chunk_10\", \"mentions\", \"speech recognition\"), (\"chunk_10\", \"mentions\", \"datasets\"), (\"chunk_10\", \"mentions\", \"Chen et al. (2021)\"), (\"chunk_10\", \"mentions\", \"Galvez et al. (2021)\")]\n",
            "✅ Extracted: [('unlabeled speech data', 'utilized in', 'Zhang et al. (2021)'), ('speech recognition', 'related_to_core', 'datasets'), ('datasets', 'is_core_idea', 'true'), ('chunk_10', 'is_core_chunk', 'true'), ('Chen et al. (2021)', 'make use of', 'automated'), ('Galvez et al. (2021)', 'make use of', 'automated'), ('unlabeled speech data', 'related_to_core', 'datasets'), ('Zhang et al. (2021)', 'related_to_core', 'datasets'), ('Chen et al. (2021)', 'related_to_core', 'datasets'), ('Galvez et al. (2021)', 'related_to_core', 'datasets'), ('chunk_10', 'mentions', 'unlabeled speech data'), ('chunk_10', 'mentions', 'Zhang et al. (2021)'), ('chunk_10', 'mentions', 'speech recognition'), ('chunk_10', 'mentions', 'datasets'), ('chunk_10', 'mentions', 'Chen et al. (2021)'), ('chunk_10', 'mentions', 'Galvez et al. (2021)')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_11...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Speech Recognition\", \"related_to_core\", \"Weak Supervision\"), (\"Large-Scale\", \"related_to_core\", \"Weak Supervision\"), (\"pipelines\", \"related_to_core\", \"Weak Supervision\"), (\"training data\", \"related_to_core\", \"Weak Supervision\"), (\"computer vision\", \"related_to_core\", \"Weak Supervision\"), (\"crowdsourced datasets\", \"related_to_core\", \"Weak Supervision\"), (\"ImageNet\", \"related_to_core\", \"Weak Supervision\"), (\"Speech Recognition\", \"via\", \"Weak Supervision\"), (\"pipelines\", \"to scale\", \"Speech Recognition\"), (\"Weak Supervision\", \"to\", \"Speech Recognition\"), (\"Speech Recognition\", \"understudied for\", \"speech recognition\"), (\"computer vision\", \"has demonstrated\", \"moving beyond gold-standard crowdsourced datasets\"), (\"chunk_11\", \"mentions\", \"Speech Recognition\"), (\"chunk_11\", \"mentions\", \"Large-Scale\"), (\"chunk_11\", \"mentions\", \"Weak Supervision\"), (\"chunk_11\", \"mentions\", \"pipelines\"), (\"chunk_11\", \"mentions\", \"training data\"), (\"chunk_11\", \"mentions\", \"computer vision\"), (\"chunk_11\", \"mentions\", \"crowdsourced datasets\"), (\"chunk_11\", \"mentions\", \"ImageNet\"), (\"Weak Supervision\", \"is_core_idea\", \"true\"), (\"chunk_11\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('Speech Recognition', 'related_to_core', 'Weak Supervision'), ('Large-Scale', 'related_to_core', 'Weak Supervision'), ('pipelines', 'related_to_core', 'Weak Supervision'), ('training data', 'related_to_core', 'Weak Supervision'), ('computer vision', 'related_to_core', 'Weak Supervision'), ('crowdsourced datasets', 'related_to_core', 'Weak Supervision'), ('ImageNet', 'related_to_core', 'Weak Supervision'), ('Speech Recognition', 'via', 'Weak Supervision'), ('pipelines', 'to scale', 'Speech Recognition'), ('Weak Supervision', 'to', 'Speech Recognition'), ('Speech Recognition', 'understudied for', 'speech recognition'), ('computer vision', 'has demonstrated', 'moving beyond gold-standard crowdsourced datasets'), ('chunk_11', 'mentions', 'Speech Recognition'), ('chunk_11', 'mentions', 'Large-Scale'), ('chunk_11', 'mentions', 'Weak Supervision'), ('chunk_11', 'mentions', 'pipelines'), ('chunk_11', 'mentions', 'training data'), ('chunk_11', 'mentions', 'computer vision'), ('chunk_11', 'mentions', 'crowdsourced datasets'), ('chunk_11', 'mentions', 'ImageNet'), ('Weak Supervision', 'is_core_idea', 'true'), ('chunk_11', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_12...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"weakly supervised datasets\", \"improves\", \"robustness\"), (\"weakly supervised datasets\", \"improves\", \"generalization\"), (\"models\", \"generalization\", \"weakly supervised datasets\"), (\"speech recognition\", \"related_to_core\", \"Whisper2\"), (\"labeled audio data\", \"related_to_core\", \"Whisper2\"), (\"Whisper2\", \"is_core_idea\", \"true\"), (\"chunk_12\", \"is_core_chunk\", \"true\"), (\"chunk_12\", \"mentions\", \"weakly supervised datasets\"), (\"chunk_12\", \"mentions\", \"models\"), (\"chunk_12\", \"mentions\", \"speech recognition\"), (\"chunk_12\", \"mentions\", \"labeled audio data\"), (\"chunk_12\", \"mentions\", \"Whisper2\"), (\"robustness\", \"related_to_core\", \"Whisper2\"), (\"generalization\", \"related_to_core\", \"Whisper2\")]\n",
            "✅ Extracted: [('weakly supervised datasets', 'improves', 'robustness'), ('weakly supervised datasets', 'improves', 'generalization'), ('models', 'generalization', 'weakly supervised datasets'), ('speech recognition', 'related_to_core', 'Whisper2'), ('labeled audio data', 'related_to_core', 'Whisper2'), ('Whisper2', 'is_core_idea', 'true'), ('chunk_12', 'is_core_chunk', 'true'), ('chunk_12', 'mentions', 'weakly supervised datasets'), ('chunk_12', 'mentions', 'models'), ('chunk_12', 'mentions', 'speech recognition'), ('chunk_12', 'mentions', 'labeled audio data'), ('chunk_12', 'mentions', 'Whisper2'), ('robustness', 'related_to_core', 'Whisper2'), ('generalization', 'related_to_core', 'Whisper2')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_13...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"transfer\", \"predicate\", \"datasets\"), (\"chunk_13\", \"mentions\", \"transfer\"), (\"chunk_13\", \"mentions\", \"datasets\"), (\"dataset-speciﬁc ﬁne-tuning\", \"predicate\", \"achieve high-quality results\"), (\"chunk_13\", \"mentions\", \"dataset-speciﬁc ﬁne-tuning\"), (\"chunk_13\", \"mentions\", \"high-quality results\"), (\"weakly supervised pre-training\", \"predicate\", \"English-only speech recognition\"), (\"chunk_13\", \"mentions\", \"weakly supervised pre-training\"), (\"chunk_13\", \"mentions\", \"English-only speech recognition\"), (\"weakly supervised pre-training\", \"predicate\", \"multilingual\"), (\"weakly supervised pre-training\", \"predicate\", \"multitask\"), (\"chunk_13\", \"mentions\", \"multilingual\"), (\"chunk_13\", \"mentions\", \"multitask\"), (\"audio\", \"predicate\", \"languages\"), (\"chunk_13\", \"mentions\", \"audio\"), (\"chunk_13\", \"mentions\", \"languages\"), (\"weakly supervised pre-training\", \"is_core_idea\", \"true\"), (\"chunk_13\", \"is_core_chunk\", \"true\"), (\"transfer\", \"related_to_core\", \"weakly supervised pre-training\"), (\"datasets\", \"related_to_core\", \"weakly supervised pre-training\"), (\"dataset-speciﬁc ﬁne-tuning\", \"related_to_core\", \"weakly supervised pre-training\"), (\"high-quality results\", \"related_to_core\", \"weakly supervised pre-training\"), (\"English-only speech recognition\", \"related_to_core\", \"weakly supervised pre-training\"), (\"multilingual\", \"related_to_core\", \"weakly supervised pre-training\"), (\"multitask\", \"related_to_core\", \"weakly supervised pre-training\"), (\"audio\", \"related_to_core\", \"weakly supervised pre-training\"), (\"languages\", \"related_to_core\", \"weakly supervised pre-training\")]\n",
            "✅ Extracted: [('transfer', 'predicate', 'datasets'), ('chunk_13', 'mentions', 'transfer'), ('chunk_13', 'mentions', 'datasets'), ('dataset-speciﬁc ﬁne-tuning', 'predicate', 'achieve high-quality results'), ('chunk_13', 'mentions', 'dataset-speciﬁc ﬁne-tuning'), ('chunk_13', 'mentions', 'high-quality results'), ('weakly supervised pre-training', 'predicate', 'English-only speech recognition'), ('chunk_13', 'mentions', 'weakly supervised pre-training'), ('chunk_13', 'mentions', 'English-only speech recognition'), ('weakly supervised pre-training', 'predicate', 'multilingual'), ('weakly supervised pre-training', 'predicate', 'multitask'), ('chunk_13', 'mentions', 'multilingual'), ('chunk_13', 'mentions', 'multitask'), ('audio', 'predicate', 'languages'), ('chunk_13', 'mentions', 'audio'), ('chunk_13', 'mentions', 'languages'), ('weakly supervised pre-training', 'is_core_idea', 'true'), ('chunk_13', 'is_core_chunk', 'true'), ('transfer', 'related_to_core', 'weakly supervised pre-training'), ('datasets', 'related_to_core', 'weakly supervised pre-training'), ('dataset-speciﬁc ﬁne-tuning', 'related_to_core', 'weakly supervised pre-training'), ('high-quality results', 'related_to_core', 'weakly supervised pre-training'), ('English-only speech recognition', 'related_to_core', 'weakly supervised pre-training'), ('multilingual', 'related_to_core', 'weakly supervised pre-training'), ('multitask', 'related_to_core', 'weakly supervised pre-training'), ('audio', 'related_to_core', 'weakly supervised pre-training'), ('languages', 'related_to_core', 'weakly supervised pre-training')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_14...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"X→en translation data\", \"is_core_idea\", \"true\"), (\"chunk_14\", \"is_core_chunk\", \"true\"), (\"chunk_14\", \"mentions\", \"X→en translation data\"), (\"models\", \"related_to_core\", \"X→en translation data\"), (\"joint multilingual and multitask training\", \"related_to_core\", \"X→en translation data\"), (\"speech recognition\", \"related_to_core\", \"X→en translation data\"), (\"weakly supervised pre-training\", \"related_to_core\", \"X→en translation data\"), (\"self-supervision\", \"related_to_core\", \"X→en translation data\"), (\"self-training techniques\", \"related_to_core\", \"X→en translation data\"), (\"large-scale speech recognition\", \"related_to_core\", \"X→en translation data\"), (\"chunk_14\", \"mentions\", \"models\"), (\"chunk_14\", \"mentions\", \"joint multilingual and multitask training\"), (\"chunk_14\", \"mentions\", \"speech recognition\"), (\"chunk_14\", \"mentions\", \"weakly supervised pre-training\"), (\"chunk_14\", \"mentions\", \"self-supervision\"), (\"chunk_14\", \"mentions\", \"self-training techniques\"), (\"chunk_14\", \"mentions\", \"large-scale speech recognition\")]\n",
            "✅ Extracted: [('X→en translation data', 'is_core_idea', 'true'), ('chunk_14', 'is_core_chunk', 'true'), ('chunk_14', 'mentions', 'X→en translation data'), ('models', 'related_to_core', 'X→en translation data'), ('joint multilingual and multitask training', 'related_to_core', 'X→en translation data'), ('speech recognition', 'related_to_core', 'X→en translation data'), ('weakly supervised pre-training', 'related_to_core', 'X→en translation data'), ('self-supervision', 'related_to_core', 'X→en translation data'), ('self-training techniques', 'related_to_core', 'X→en translation data'), ('large-scale speech recognition', 'related_to_core', 'X→en translation data'), ('chunk_14', 'mentions', 'models'), ('chunk_14', 'mentions', 'joint multilingual and multitask training'), ('chunk_14', 'mentions', 'speech recognition'), ('chunk_14', 'mentions', 'weakly supervised pre-training'), ('chunk_14', 'mentions', 'self-supervision'), ('chunk_14', 'mentions', 'self-training techniques'), ('chunk_14', 'mentions', 'large-scale speech recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_15...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"robust speech recognition\", \"is_core_idea\", \"true\"), (\"chunk_15\", \"is_core_chunk\", \"true\"), (\"speech recognition\", \"related_to_core\", \"robust speech recognition\"), (\"inference code\", \"related_to_core\", \"robust speech recognition\"), (\"models\", \"related_to_core\", \"robust speech recognition\"), (\"web-scale text\", \"related_to_core\", \"robust speech recognition\"), (\"machine learning systems\", \"related_to_core\", \"robust speech recognition\"), (\"data pre-processing\", \"related_to_core\", \"robust speech recognition\"), (\"training\", \"related_to_core\", \"robust speech recognition\"), (\"chunk_15\", \"mentions\", \"robust speech recognition\"), (\"chunk_15\", \"mentions\", \"speech recognition\"), (\"chunk_15\", \"mentions\", \"inference code\"), (\"chunk_15\", \"mentions\", \"models\"), (\"chunk_15\", \"mentions\", \"web-scale text\"), (\"chunk_15\", \"mentions\", \"machine learning systems\"), (\"chunk_15\", \"mentions\", \"data pre-processing\"), (\"chunk_15\", \"mentions\", \"training\")]\n",
            "✅ Extracted: [('robust speech recognition', 'is_core_idea', 'true'), ('chunk_15', 'is_core_chunk', 'true'), ('speech recognition', 'related_to_core', 'robust speech recognition'), ('inference code', 'related_to_core', 'robust speech recognition'), ('models', 'related_to_core', 'robust speech recognition'), ('web-scale text', 'related_to_core', 'robust speech recognition'), ('machine learning systems', 'related_to_core', 'robust speech recognition'), ('data pre-processing', 'related_to_core', 'robust speech recognition'), ('training', 'related_to_core', 'robust speech recognition'), ('chunk_15', 'mentions', 'robust speech recognition'), ('chunk_15', 'mentions', 'speech recognition'), ('chunk_15', 'mentions', 'inference code'), ('chunk_15', 'mentions', 'models'), ('chunk_15', 'mentions', 'web-scale text'), ('chunk_15', 'mentions', 'machine learning systems'), ('chunk_15', 'mentions', 'data pre-processing'), ('chunk_15', 'mentions', 'training')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_16...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Whisper models\", \"predict\", \"raw text\"), (\"raw text\", \"of\", \"transcripts\"), (\"transcripts\", \"without\", \"standardization\"), (\"sequence-to-sequence models\", \"learn to map\", \"utterances\"), (\"utterances\", \"and\", \"transcribed form\"), (\"speech recognition pipeline\", \"removes\", \"need\"), (\"inverse text normalization\", \"step\", \"speech recognition pipeline\"), (\"chunk_16\", \"mentions\", \"Whisper models\"), (\"chunk_16\", \"mentions\", \"raw text\"), (\"chunk_16\", \"mentions\", \"transcripts\"), (\"chunk_16\", \"mentions\", \"sequence-to-sequence models\"), (\"chunk_16\", \"mentions\", \"utterances\"), (\"chunk_16\", \"mentions\", \"transcribed form\"), (\"chunk_16\", \"mentions\", \"speech recognition pipeline\"), (\"chunk_16\", \"mentions\", \"inverse text normalization\"), (\"Whisper models\", \"is_core_idea\", \"true\"), (\"chunk_16\", \"is_core_chunk\", \"true\"), (\"raw text\", \"related_to_core\", \"Whisper models\"), (\"transcripts\", \"related_to_core\", \"Whisper models\"), (\"sequence-to-sequence models\", \"related_to_core\", \"Whisper models\"), (\"utterances\", \"related_to_core\", \"Whisper models\"), (\"transcribed form\", \"related_to_core\", \"Whisper models\"), (\"speech recognition pipeline\", \"related_to_core\", \"Whisper models\"), (\"inverse text normalization\", \"related_to_core\", \"Whisper models\")]\n",
            "✅ Extracted: [('Whisper models', 'predict', 'raw text'), ('raw text', 'of', 'transcripts'), ('transcripts', 'without', 'standardization'), ('sequence-to-sequence models', 'learn to map', 'utterances'), ('utterances', 'and', 'transcribed form'), ('speech recognition pipeline', 'removes', 'need'), ('inverse text normalization', 'step', 'speech recognition pipeline'), ('chunk_16', 'mentions', 'Whisper models'), ('chunk_16', 'mentions', 'raw text'), ('chunk_16', 'mentions', 'transcripts'), ('chunk_16', 'mentions', 'sequence-to-sequence models'), ('chunk_16', 'mentions', 'utterances'), ('chunk_16', 'mentions', 'transcribed form'), ('chunk_16', 'mentions', 'speech recognition pipeline'), ('chunk_16', 'mentions', 'inverse text normalization'), ('Whisper models', 'is_core_idea', 'true'), ('chunk_16', 'is_core_chunk', 'true'), ('raw text', 'related_to_core', 'Whisper models'), ('transcripts', 'related_to_core', 'Whisper models'), ('sequence-to-sequence models', 'related_to_core', 'Whisper models'), ('utterances', 'related_to_core', 'Whisper models'), ('transcribed form', 'related_to_core', 'Whisper models'), ('speech recognition pipeline', 'related_to_core', 'Whisper models'), ('inverse text normalization', 'related_to_core', 'Whisper models')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_17...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"naturalistic transcriptions\", \"mentions\", \"naturalistic transcriptions\"), (\"dataset\", \"mentions\", \"dataset\"), (\"audio\", \"mentions\", \"audio\"), (\"tran- scripts\", \"mentions\", \"tran- scripts\"), (\"Internet\", \"mentions\", \"Internet\"), (\"distribution\", \"mentions\", \"distribution\"), (\"environments\", \"mentions\", \"environments\"), (\"recording setups\", \"mentions\", \"recording setups\"), (\"speakers\", \"mentions\", \"speakers\"), (\"languages\", \"mentions\", \"languages\"), (\"audio quality\", \"mentions\", \"audio quality\"), (\"model\", \"mentions\", \"model\"), (\"transcript quality\", \"mentions\", \"transcript quality\"), (\"chunk_17\", \"mentions\", \"naturalistic transcriptions\"), (\"chunk_17\", \"mentions\", \"dataset\"), (\"chunk_17\", \"mentions\", \"audio\"), (\"chunk_17\", \"mentions\", \"tran- scripts\"), (\"chunk_17\", \"mentions\", \"Internet\"), (\"chunk_17\", \"mentions\", \"distribution\"), (\"chunk_17\", \"mentions\", \"environments\"), (\"chunk_17\", \"mentions\", \"recording setups\"), (\"chunk_17\", \"mentions\", \"speakers\"), (\"chunk_17\", \"mentions\", \"languages\"), (\"chunk_17\", \"mentions\", \"audio quality\"), (\"chunk_17\", \"mentions\", \"model\"), (\"chunk_17\", \"mentions\", \"transcript quality\")]\n",
            "✅ Extracted: [('naturalistic transcriptions', 'mentions', 'naturalistic transcriptions'), ('dataset', 'mentions', 'dataset'), ('audio', 'mentions', 'audio'), ('tran- scripts', 'mentions', 'tran- scripts'), ('Internet', 'mentions', 'Internet'), ('distribution', 'mentions', 'distribution'), ('environments', 'mentions', 'environments'), ('recording setups', 'mentions', 'recording setups'), ('speakers', 'mentions', 'speakers'), ('languages', 'mentions', 'languages'), ('audio quality', 'mentions', 'audio quality'), ('model', 'mentions', 'model'), ('transcript quality', 'mentions', 'transcript quality'), ('chunk_17', 'mentions', 'naturalistic transcriptions'), ('chunk_17', 'mentions', 'dataset'), ('chunk_17', 'mentions', 'audio'), ('chunk_17', 'mentions', 'tran- scripts'), ('chunk_17', 'mentions', 'Internet'), ('chunk_17', 'mentions', 'distribution'), ('chunk_17', 'mentions', 'environments'), ('chunk_17', 'mentions', 'recording setups'), ('chunk_17', 'mentions', 'speakers'), ('chunk_17', 'mentions', 'languages'), ('chunk_17', 'mentions', 'audio quality'), ('chunk_17', 'mentions', 'model'), ('chunk_17', 'mentions', 'transcript quality')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_18...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"transcripts\", \"mentions\", \"transcripts\"), (\"chunk_18\", \"mentions\", \"transcripts\"), (\"dataset\", \"mentions\", \"dataset\"), (\"chunk_18\", \"mentions\", \"dataset\"), (\"filtering methods\", \"mentions\", \"filtering methods\"), (\"chunk_18\", \"mentions\", \"filtering methods\"), (\"transcript quality\", \"mentions\", \"transcript quality\"), (\"chunk_18\", \"mentions\", \"transcript quality\"), (\"internet\", \"mentions\", \"internet\"), (\"chunk_18\", \"mentions\", \"internet\"), (\"ASR systems\", \"mentions\", \"ASR systems\"), (\"chunk_18\", \"mentions\", \"ASR systems\"), (\"training\", \"mentions\", \"training\"), (\"chunk_18\", \"mentions\", \"training\"), (\"datasets\", \"mentions\", \"datasets\"), (\"chunk_18\", \"mentions\", \"datasets\"), (\"human-generated data\", \"mentions\", \"human-generated data\"), (\"chunk_18\", \"mentions\", \"human-generated data\"), (\"machine-generated data\", \"mentions\", \"machine-generated data\"), (\"chunk_18\", \"mentions\", \"machine-generated data\"), (\"translation systems\", \"mentions\", \"translation systems\"), (\"chunk_18\", \"mentions\", \"translation systems\"), (\"transcript-ese\", \"mentions\", \"transcript-ese\"), (\"chunk_18\", \"mentions\", \"transcript-ese\"), (\"transcripts\", \"is_core_idea\", \"true\"), (\"chunk_18\", \"is_core_chunk\", \"true\"), (\"filtering methods\", \"related_to_core\", \"transcripts\"), (\"dataset\", \"related_to_core\", \"transcripts\"), (\"transcript quality\", \"related_to_core\", \"transcripts\"), (\"internet\", \"related_to_core\", \"transcripts\"), (\"ASR systems\", \"related_to_core\", \"transcripts\"), (\"training\", \"related_to_core\", \"transcripts\"), (\"datasets\", \"related_to_core\", \"transcripts\"), (\"human-generated data\", \"related_to_core\", \"transcripts\"), (\"machine-generated data\", \"related_to_core\", \"transcripts\"), (\"translation systems\", \"related_to_core\", \"transcripts\"), (\"transcript-ese\", \"related_to_core\", \"transcripts\"), (\"filtering methods\", \"improves\", \"transcript quality\"), (\"training\", \"impair\", \"translation systems\")]\n",
            "✅ Extracted: [('transcripts', 'mentions', 'transcripts'), ('chunk_18', 'mentions', 'transcripts'), ('dataset', 'mentions', 'dataset'), ('chunk_18', 'mentions', 'dataset'), ('filtering methods', 'mentions', 'filtering methods'), ('chunk_18', 'mentions', 'filtering methods'), ('transcript quality', 'mentions', 'transcript quality'), ('chunk_18', 'mentions', 'transcript quality'), ('internet', 'mentions', 'internet'), ('chunk_18', 'mentions', 'internet'), ('ASR systems', 'mentions', 'ASR systems'), ('chunk_18', 'mentions', 'ASR systems'), ('training', 'mentions', 'training'), ('chunk_18', 'mentions', 'training'), ('datasets', 'mentions', 'datasets'), ('chunk_18', 'mentions', 'datasets'), ('human-generated data', 'mentions', 'human-generated data'), ('chunk_18', 'mentions', 'human-generated data'), ('machine-generated data', 'mentions', 'machine-generated data'), ('chunk_18', 'mentions', 'machine-generated data'), ('translation systems', 'mentions', 'translation systems'), ('chunk_18', 'mentions', 'translation systems'), ('transcript-ese', 'mentions', 'transcript-ese'), ('chunk_18', 'mentions', 'transcript-ese'), ('transcripts', 'is_core_idea', 'true'), ('chunk_18', 'is_core_chunk', 'true'), ('filtering methods', 'related_to_core', 'transcripts'), ('dataset', 'related_to_core', 'transcripts'), ('transcript quality', 'related_to_core', 'transcripts'), ('internet', 'related_to_core', 'transcripts'), ('ASR systems', 'related_to_core', 'transcripts'), ('training', 'related_to_core', 'transcripts'), ('datasets', 'related_to_core', 'transcripts'), ('human-generated data', 'related_to_core', 'transcripts'), ('machine-generated data', 'related_to_core', 'transcripts'), ('translation systems', 'related_to_core', 'transcripts'), ('transcript-ese', 'related_to_core', 'transcripts'), ('filtering methods', 'improves', 'transcript quality'), ('training', 'impair', 'translation systems')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_19...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"heuristics\", \"relation\", \"detect\"), (\"heuristics\", \"relation\", \"remove\"), (\"machine-generated transcripts\", \"relation\", \"detected_by\", \"heuristics\"), (\"training dataset\", \"relation\", \"contains\", \"machine-generated transcripts\"), (\"ASR systems\", \"relation\", \"output\", \"subset of written language\"), (\"written language\", \"relation\", \"limited_by\", \"ASR systems\"), (\"audio signals\", \"relation\", \"difficult_to_predict\", \"complex punctuation\"), (\"audio signals\", \"relation\", \"difficult_to_predict\", \"formatting whitespace\"), (\"audio signals\", \"relation\", \"difficult_to_predict\", \"stylistic aspects\"), (\"complex punctuation\", \"part_of\", \"written language\"), (\"exclamation points\", \"instance_of\", \"complex punctuation\"), (\"commas\", \"instance_of\", \"complex punctuation\"), (\"question marks\", \"instance_of\", \"complex punctuation\"), (\"formatting whitespace\", \"part_of\", \"written language\"), (\"paragraphs\", \"instance_of\", \"formatting whitespace\"), (\"stylistic aspects\", \"part_of\", \"written language\"), (\"capitalization\", \"instance_of\", \"stylistic aspects\"), (\"chunk_19\", \"mentions\", \"heuristics\"), (\"chunk_19\", \"mentions\", \"machine-generated transcripts\"), (\"chunk_19\", \"mentions\", \"training dataset\"), (\"chunk_19\", \"mentions\", \"ASR systems\"), (\"chunk_19\", \"mentions\", \"written language\"), (\"chunk_19\", \"mentions\", \"audio signals\"), (\"chunk_19\", \"mentions\", \"complex punctuation\"), (\"chunk_19\", \"mentions\", \"exclamation points\"), (\"chunk_19\", \"mentions\", \"commas\"), (\"chunk_19\", \"mentions\", \"question marks\"), (\"chunk_19\", \"mentions\", \"formatting whitespace\"), (\"chunk_19\", \"mentions\", \"paragraphs\"), (\"chunk_19\", \"mentions\", \"stylistic aspects\"), (\"chunk_19\", \"mentions\", \"capitalization\"), (\"machine-generated transcripts\", \"is_core_idea\", \"true\"), (\"chunk_19\", \"is_core_chunk\", \"true\"), (\"heuristics\", \"related_to_core\", \"machine-generated transcripts\"), (\"training dataset\", \"related_to_core\", \"machine-generated transcripts\"), (\"ASR systems\", \"related_to_core\", \"machine-generated transcripts\"), (\"written language\", \"related_to_core\", \"machine-generated transcripts\"), (\"audio signals\", \"related_to_core\", \"machine-generated transcripts\"), (\"complex punctuation\", \"related_to_core\", \"machine-generated transcripts\"), (\"exclamation points\", \"related_to_core\", \"machine-generated transcripts\"), (\"commas\", \"related_to_core\", \"machine-generated transcripts\"), (\"question marks\", \"related_to_core\", \"machine-generated transcripts\"), (\"formatting whitespace\", \"related_to_core\", \"machine-generated transcripts\"), (\"paragraphs\", \"related_to_core\", \"machine-generated transcripts\"), (\"stylistic aspects\", \"related_to_core\", \"machine-generated transcripts\"), (\"capitalization\", \"related_to_core\", \"machine-generated transcripts\")]\n",
            "✅ Extracted: [('heuristics', 'relation', 'detect'), ('heuristics', 'relation', 'remove'), ('machine-generated transcripts', 'relation', 'detected_by', 'heuristics'), ('training dataset', 'relation', 'contains', 'machine-generated transcripts'), ('ASR systems', 'relation', 'output', 'subset of written language'), ('written language', 'relation', 'limited_by', 'ASR systems'), ('audio signals', 'relation', 'difficult_to_predict', 'complex punctuation'), ('audio signals', 'relation', 'difficult_to_predict', 'formatting whitespace'), ('audio signals', 'relation', 'difficult_to_predict', 'stylistic aspects'), ('complex punctuation', 'part_of', 'written language'), ('exclamation points', 'instance_of', 'complex punctuation'), ('commas', 'instance_of', 'complex punctuation'), ('question marks', 'instance_of', 'complex punctuation'), ('formatting whitespace', 'part_of', 'written language'), ('paragraphs', 'instance_of', 'formatting whitespace'), ('stylistic aspects', 'part_of', 'written language'), ('capitalization', 'instance_of', 'stylistic aspects'), ('chunk_19', 'mentions', 'heuristics'), ('chunk_19', 'mentions', 'machine-generated transcripts'), ('chunk_19', 'mentions', 'training dataset'), ('chunk_19', 'mentions', 'ASR systems'), ('chunk_19', 'mentions', 'written language'), ('chunk_19', 'mentions', 'audio signals'), ('chunk_19', 'mentions', 'complex punctuation'), ('chunk_19', 'mentions', 'exclamation points'), ('chunk_19', 'mentions', 'commas'), ('chunk_19', 'mentions', 'question marks'), ('chunk_19', 'mentions', 'formatting whitespace'), ('chunk_19', 'mentions', 'paragraphs'), ('chunk_19', 'mentions', 'stylistic aspects'), ('chunk_19', 'mentions', 'capitalization'), ('machine-generated transcripts', 'is_core_idea', 'true'), ('chunk_19', 'is_core_chunk', 'true'), ('heuristics', 'related_to_core', 'machine-generated transcripts'), ('training dataset', 'related_to_core', 'machine-generated transcripts'), ('ASR systems', 'related_to_core', 'machine-generated transcripts'), ('written language', 'related_to_core', 'machine-generated transcripts'), ('audio signals', 'related_to_core', 'machine-generated transcripts'), ('complex punctuation', 'related_to_core', 'machine-generated transcripts'), ('exclamation points', 'related_to_core', 'machine-generated transcripts'), ('commas', 'related_to_core', 'machine-generated transcripts'), ('question marks', 'related_to_core', 'machine-generated transcripts'), ('formatting whitespace', 'related_to_core', 'machine-generated transcripts'), ('paragraphs', 'related_to_core', 'machine-generated transcripts'), ('stylistic aspects', 'related_to_core', 'machine-generated transcripts'), ('capitalization', 'related_to_core', 'machine-generated transcripts')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Skipping invalid triple: ('machine-generated transcripts', 'relation', 'detected_by', 'heuristics')\n",
            "⚠️ Skipping invalid triple: ('training dataset', 'relation', 'contains', 'machine-generated transcripts')\n",
            "⚠️ Skipping invalid triple: ('ASR systems', 'relation', 'output', 'subset of written language')\n",
            "⚠️ Skipping invalid triple: ('written language', 'relation', 'limited_by', 'ASR systems')\n",
            "⚠️ Skipping invalid triple: ('audio signals', 'relation', 'difficult_to_predict', 'complex punctuation')\n",
            "⚠️ Skipping invalid triple: ('audio signals', 'relation', 'difficult_to_predict', 'formatting whitespace')\n",
            "⚠️ Skipping invalid triple: ('audio signals', 'relation', 'difficult_to_predict', 'stylistic aspects')\n",
            "🔍 Processing chunk_20...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"ASR systems\", \"includes\", \"inverse text normalization\"), (\"inverse text normalization\", \"is\", \"simple\"), (\"inverse text normalization\", \"is\", \"rule-based\"), (\"audio language detector\", \"created by\", \"ﬁne-tuning a prototype model\"), (\"prototype model\", \"trained on\", \"prototype version of the dataset\"), (\"prototype version of the dataset\", \"on\", \"VoxLingua107\"), (\"VoxLingua107\", \"Valk & Alum¨ae\", \"2021\"), (\"chunk_20\", \"mentions\", \"ASR systems\"), (\"chunk_20\", \"mentions\", \"inverse text normalization\"), (\"chunk_20\", \"mentions\", \"audio language detector\"), (\"chunk_20\", \"mentions\", \"prototype model\"), (\"chunk_20\", \"mentions\", \"prototype version of the dataset\"), (\"chunk_20\", \"mentions\", \"VoxLingua107\"), (\"audio language detector\", \"is_core_idea\", \"true\"), (\"chunk_20\", \"is_core_chunk\", \"true\"), (\"ASR systems\", \"related_to_core\", \"audio language detector\"), (\"inverse text normalization\", \"related_to_core\", \"audio language detector\"), (\"prototype model\", \"related_to_core\", \"audio language detector\"), (\"prototype version of the dataset\", \"related_to_core\", \"audio language detector\"), (\"VoxLingua107\", \"related_to_core\", \"audio language detector\")]\n",
            "✅ Extracted: [('ASR systems', 'includes', 'inverse text normalization'), ('inverse text normalization', 'is', 'simple'), ('inverse text normalization', 'is', 'rule-based'), ('audio language detector', 'created by', 'ﬁne-tuning a prototype model'), ('prototype model', 'trained on', 'prototype version of the dataset'), ('prototype version of the dataset', 'on', 'VoxLingua107'), ('VoxLingua107', 'Valk & Alum¨ae', '2021'), ('chunk_20', 'mentions', 'ASR systems'), ('chunk_20', 'mentions', 'inverse text normalization'), ('chunk_20', 'mentions', 'audio language detector'), ('chunk_20', 'mentions', 'prototype model'), ('chunk_20', 'mentions', 'prototype version of the dataset'), ('chunk_20', 'mentions', 'VoxLingua107'), ('audio language detector', 'is_core_idea', 'true'), ('chunk_20', 'is_core_chunk', 'true'), ('ASR systems', 'related_to_core', 'audio language detector'), ('inverse text normalization', 'related_to_core', 'audio language detector'), ('prototype model', 'related_to_core', 'audio language detector'), ('prototype version of the dataset', 'related_to_core', 'audio language detector'), ('VoxLingua107', 'related_to_core', 'audio language detector')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_21...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"CLD2\", \"mentions\", \"CLD2\"), (\"chunk_21\", \"mentions\", \"CLD2\"), (\"transcript\", \"mentions\", \"transcript\"), (\"chunk_21\", \"mentions\", \"transcript\"), (\"audio\", \"mentions\", \"audio\"), (\"chunk_21\", \"mentions\", \"audio\"), (\"speech recognition\", \"mentions\", \"speech recognition\"), (\"chunk_21\", \"mentions\", \"speech recognition\"), (\"dataset\", \"mentions\", \"dataset\"), (\"chunk_21\", \"mentions\", \"dataset\"), (\"transcript language\", \"mentions\", \"transcript language\"), (\"chunk_21\", \"mentions\", \"transcript language\"), (\"English\", \"mentions\", \"English\"), (\"chunk_21\", \"mentions\", \"English\"), (\"speech translation\", \"mentions\", \"speech translation\"), (\"chunk_21\", \"mentions\", \"speech translation\"), (\"fuzzy de-duping\", \"mentions\", \"fuzzy de-duping\"), (\"chunk_21\", \"mentions\", \"fuzzy de-duping\"), (\"training dataset\", \"mentions\", \"training dataset\"), (\"chunk_21\", \"mentions\", \"training dataset\"), (\"transcript\", \"according_to\", \"CLD2\"), (\"audio\", \"paired_with\", \"transcript\"), (\"speech recognition\", \"training_example_in\", \"dataset\"), (\"transcript language\", \"is\", \"English\"), (\"dataset\", \"contains\", \"speech translation\"), (\"fuzzy de-duping\", \"reduces\", \"duplication\"), (\"fuzzy de-duping\", \"reduces\", \"generated content\"), (\"training dataset\", \"contains\", \"transcript\"), (\"dataset\", \"is_core_idea\", \"true\"), (\"chunk_21\", \"is_core_chunk\", \"true\"), (\"CLD2\", \"related_to_core\", \"dataset\"), (\"transcript\", \"related_to_core\", \"dataset\"), (\"audio\", \"related_to_core\", \"dataset\"), (\"speech recognition\", \"related_to_core\", \"dataset\"), (\"transcript language\", \"related_to_core\", \"dataset\"), (\"English\", \"related_to_core\", \"dataset\"), (\"speech translation\", \"related_to_core\", \"dataset\"), (\"fuzzy de-duping\", \"related_to_core\", \"dataset\"), (\"training dataset\", \"related_to_core\", \"dataset\")]\n",
            "✅ Extracted: [('CLD2', 'mentions', 'CLD2'), ('chunk_21', 'mentions', 'CLD2'), ('transcript', 'mentions', 'transcript'), ('chunk_21', 'mentions', 'transcript'), ('audio', 'mentions', 'audio'), ('chunk_21', 'mentions', 'audio'), ('speech recognition', 'mentions', 'speech recognition'), ('chunk_21', 'mentions', 'speech recognition'), ('dataset', 'mentions', 'dataset'), ('chunk_21', 'mentions', 'dataset'), ('transcript language', 'mentions', 'transcript language'), ('chunk_21', 'mentions', 'transcript language'), ('English', 'mentions', 'English'), ('chunk_21', 'mentions', 'English'), ('speech translation', 'mentions', 'speech translation'), ('chunk_21', 'mentions', 'speech translation'), ('fuzzy de-duping', 'mentions', 'fuzzy de-duping'), ('chunk_21', 'mentions', 'fuzzy de-duping'), ('training dataset', 'mentions', 'training dataset'), ('chunk_21', 'mentions', 'training dataset'), ('transcript', 'according_to', 'CLD2'), ('audio', 'paired_with', 'transcript'), ('speech recognition', 'training_example_in', 'dataset'), ('transcript language', 'is', 'English'), ('dataset', 'contains', 'speech translation'), ('fuzzy de-duping', 'reduces', 'duplication'), ('fuzzy de-duping', 'reduces', 'generated content'), ('training dataset', 'contains', 'transcript'), ('dataset', 'is_core_idea', 'true'), ('chunk_21', 'is_core_chunk', 'true'), ('CLD2', 'related_to_core', 'dataset'), ('transcript', 'related_to_core', 'dataset'), ('audio', 'related_to_core', 'dataset'), ('speech recognition', 'related_to_core', 'dataset'), ('transcript language', 'related_to_core', 'dataset'), ('English', 'related_to_core', 'dataset'), ('speech translation', 'related_to_core', 'dataset'), ('fuzzy de-duping', 'related_to_core', 'dataset'), ('training dataset', 'related_to_core', 'dataset')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_22...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"training dataset\", \"mentions\", \"training dataset\"), (\"audio ﬁles\", \"mentions\", \"audio ﬁles\"), (\"30-second segments\", \"mentions\", \"30-second segments\"), (\"transcript\", \"mentions\", \"transcript\"), (\"time segment\", \"mentions\", \"time segment\"), (\"audio\", \"mentions\", \"audio\"), (\"segments\", \"mentions\", \"segments\"), (\"speech\", \"mentions\", \"speech\"), (\"voice activity detection\", \"mentions\", \"voice activity detection\"), (\"ﬁltering pass\", \"mentions\", \"ﬁltering pass\"), (\"model\", \"mentions\", \"model\"), (\"error rate\", \"mentions\", \"error rate\"), (\"training\", \"mentions\", \"training\"), (\"audio ﬁles\", \"into\", \"30-second segments\"), (\"30-second segments\", \"paired with\", \"transcript\"), (\"transcript\", \"occurs within\", \"time segment\"), (\"segments\", \"as\", \"training data\"), (\"training data\", \"for\", \"voice activity detection\"), (\"model\", \"on\", \"training\"), (\"chunk_22\", \"mentions\", \"training dataset\"), (\"chunk_22\", \"mentions\", \"audio ﬁles\"), (\"chunk_22\", \"mentions\", \"30-second segments\"), (\"chunk_22\", \"mentions\", \"transcript\"), (\"chunk_22\", \"mentions\", \"time segment\"), (\"chunk_22\", \"mentions\", \"audio\"), (\"chunk_22\", \"mentions\", \"segments\"), (\"chunk_22\", \"mentions\", \"speech\"), (\"chunk_22\", \"mentions\", \"voice activity detection\"), (\"chunk_22\", \"mentions\", \"ﬁltering pass\"), (\"chunk_22\", \"mentions\", \"model\"), (\"chunk_22\", \"mentions\", \"error rate\"), (\"chunk_22\", \"mentions\", \"training\"), (\"training\", \"is_core_idea\", \"true\"), (\"chunk_22\", \"is_core_chunk\", \"true\"), (\"training dataset\", \"related_to_core\", \"training\"), (\"audio ﬁles\", \"related_to_core\", \"training\"), (\"30-second segments\", \"related_to_core\", \"training\"), (\"transcript\", \"related_to_core\", \"training\"), (\"time segment\", \"related_to_core\", \"training\"), (\"audio\", \"related_to_core\", \"training\"), (\"segments\", \"related_to_core\", \"training\"), (\"speech\", \"related_to_core\", \"training\"), (\"voice activity detection\", \"related_to_core\", \"training\"), (\"ﬁltering pass\", \"related_to_core\", \"training\"), (\"model\", \"related_to_core\", \"training\"), (\"error rate\", \"related_to_core\", \"training\")]\n",
            "✅ Extracted: [('training dataset', 'mentions', 'training dataset'), ('audio ﬁles', 'mentions', 'audio ﬁles'), ('30-second segments', 'mentions', '30-second segments'), ('transcript', 'mentions', 'transcript'), ('time segment', 'mentions', 'time segment'), ('audio', 'mentions', 'audio'), ('segments', 'mentions', 'segments'), ('speech', 'mentions', 'speech'), ('voice activity detection', 'mentions', 'voice activity detection'), ('ﬁltering pass', 'mentions', 'ﬁltering pass'), ('model', 'mentions', 'model'), ('error rate', 'mentions', 'error rate'), ('training', 'mentions', 'training'), ('audio ﬁles', 'into', '30-second segments'), ('30-second segments', 'paired with', 'transcript'), ('transcript', 'occurs within', 'time segment'), ('segments', 'as', 'training data'), ('training data', 'for', 'voice activity detection'), ('model', 'on', 'training'), ('chunk_22', 'mentions', 'training dataset'), ('chunk_22', 'mentions', 'audio ﬁles'), ('chunk_22', 'mentions', '30-second segments'), ('chunk_22', 'mentions', 'transcript'), ('chunk_22', 'mentions', 'time segment'), ('chunk_22', 'mentions', 'audio'), ('chunk_22', 'mentions', 'segments'), ('chunk_22', 'mentions', 'speech'), ('chunk_22', 'mentions', 'voice activity detection'), ('chunk_22', 'mentions', 'ﬁltering pass'), ('chunk_22', 'mentions', 'model'), ('chunk_22', 'mentions', 'error rate'), ('chunk_22', 'mentions', 'training'), ('training', 'is_core_idea', 'true'), ('chunk_22', 'is_core_chunk', 'true'), ('training dataset', 'related_to_core', 'training'), ('audio ﬁles', 'related_to_core', 'training'), ('30-second segments', 'related_to_core', 'training'), ('transcript', 'related_to_core', 'training'), ('time segment', 'related_to_core', 'training'), ('audio', 'related_to_core', 'training'), ('segments', 'related_to_core', 'training'), ('speech', 'related_to_core', 'training'), ('voice activity detection', 'related_to_core', 'training'), ('ﬁltering pass', 'related_to_core', 'training'), ('model', 'related_to_core', 'training'), ('error rate', 'related_to_core', 'training')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_23...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Speech Recognition\", \"related_to_core\", \"Weak Supervision\"), (\"Data Sources\", \"related_to_core\", \"Weak Supervision\"), (\"Error Rate\", \"related_to_core\", \"Weak Supervision\"), (\"Machine-Generated Captions\", \"related_to_core\", \"Weak Supervision\"), (\"Filtering Heuristics\", \"related_to_core\", \"Weak Supervision\"), (\"Speech Recognition\", \"is_core_idea\", \"false\"), (\"Weak Supervision\", \"is_core_idea\", \"true\"), (\"chunk_23\", \"is_core_chunk\", \"true\"), (\"Speech Recognition\", \"part_of\", \"Large-Scale Weak Supervision\"), (\"chunk_23\", \"mentions\", \"Speech Recognition\"), (\"chunk_23\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_23\", \"mentions\", \"Data Sources\"), (\"chunk_23\", \"mentions\", \"Error Rate\"), (\"chunk_23\", \"mentions\", \"Machine-Generated Captions\"), (\"chunk_23\", \"mentions\", \"Filtering Heuristics\"), (\"Data Sources\", \"sorted_by\", \"Error Rate\"), (\"Data Sources\", \"sorted_by\", \"Data Source Size\"), (\"Machine-Generated Captions\", \"low_quality\", \"true\"), (\"Filtering Heuristics\", \"did_not_detect\", \"Machine-Generated Captions\"), (\"Weak Supervision\", \"achieves\", \"Robust Speech Recognition\")]\n",
            "✅ Extracted: [('Speech Recognition', 'related_to_core', 'Weak Supervision'), ('Data Sources', 'related_to_core', 'Weak Supervision'), ('Error Rate', 'related_to_core', 'Weak Supervision'), ('Machine-Generated Captions', 'related_to_core', 'Weak Supervision'), ('Filtering Heuristics', 'related_to_core', 'Weak Supervision'), ('Speech Recognition', 'is_core_idea', 'false'), ('Weak Supervision', 'is_core_idea', 'true'), ('chunk_23', 'is_core_chunk', 'true'), ('Speech Recognition', 'part_of', 'Large-Scale Weak Supervision'), ('chunk_23', 'mentions', 'Speech Recognition'), ('chunk_23', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_23', 'mentions', 'Data Sources'), ('chunk_23', 'mentions', 'Error Rate'), ('chunk_23', 'mentions', 'Machine-Generated Captions'), ('chunk_23', 'mentions', 'Filtering Heuristics'), ('Data Sources', 'sorted_by', 'Error Rate'), ('Data Sources', 'sorted_by', 'Data Source Size'), ('Machine-Generated Captions', 'low_quality', 'true'), ('Filtering Heuristics', 'did_not_detect', 'Machine-Generated Captions'), ('Weak Supervision', 'achieves', 'Robust Speech Recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_24...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"filtering heuristics\", \"is_core_idea\", \"true\"), (\"chunk_24\", \"is_core_chunk\", \"true\"), (\"chunk_24\", \"mentions\", \"filtering heuristics\"), (\"contamination\", \"related_to_core\", \"filtering heuristics\"), (\"de-duplication\", \"related_to_core\", \"filtering heuristics\"), (\"transcript level\", \"related_to_core\", \"filtering heuristics\"), (\"training dataset\", \"related_to_core\", \"filtering heuristics\"), (\"evaluation datasets\", \"related_to_core\", \"filtering heuristics\"), (\"TED-LIUM 3\", \"related_to_core\", \"filtering heuristics\"), (\"speech recognition\", \"related_to_core\", \"filtering heuristics\"), (\"architecture\", \"related_to_core\", \"filtering heuristics\"), (\"chunk_24\", \"mentions\", \"contamination\"), (\"chunk_24\", \"mentions\", \"de-duplication\"), (\"de-duplication\", \"at\", \"transcript level\"), (\"chunk_24\", \"mentions\", \"transcript level\"), (\"de-duplication\", \"between\", \"training dataset\"), (\"de-duplication\", \"between\", \"evaluation datasets\"), (\"chunk_24\", \"mentions\", \"training dataset\"), (\"chunk_24\", \"mentions\", \"evaluation datasets\"), (\"chunk_24\", \"mentions\", \"TED-LIUM 3\"), (\"chunk_24\", \"mentions\", \"speech recognition\"), (\"chunk_24\", \"mentions\", \"architecture\")]\n",
            "✅ Extracted: [('filtering heuristics', 'is_core_idea', 'true'), ('chunk_24', 'is_core_chunk', 'true'), ('chunk_24', 'mentions', 'filtering heuristics'), ('contamination', 'related_to_core', 'filtering heuristics'), ('de-duplication', 'related_to_core', 'filtering heuristics'), ('transcript level', 'related_to_core', 'filtering heuristics'), ('training dataset', 'related_to_core', 'filtering heuristics'), ('evaluation datasets', 'related_to_core', 'filtering heuristics'), ('TED-LIUM 3', 'related_to_core', 'filtering heuristics'), ('speech recognition', 'related_to_core', 'filtering heuristics'), ('architecture', 'related_to_core', 'filtering heuristics'), ('chunk_24', 'mentions', 'contamination'), ('chunk_24', 'mentions', 'de-duplication'), ('de-duplication', 'at', 'transcript level'), ('chunk_24', 'mentions', 'transcript level'), ('de-duplication', 'between', 'training dataset'), ('de-duplication', 'between', 'evaluation datasets'), ('chunk_24', 'mentions', 'training dataset'), ('chunk_24', 'mentions', 'evaluation datasets'), ('chunk_24', 'mentions', 'TED-LIUM 3'), ('chunk_24', 'mentions', 'speech recognition'), ('chunk_24', 'mentions', 'architecture')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_25...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"encoder-decoder Transformer\", \"is_core_idea\", \"true\"), (\"chunk_25\", \"is_core_chunk\", \"true\"), (\"chunk_25\", \"mentions\", \"encoder-decoder Transformer\"), (\"Vaswani et al.\", \"related_to_core\", \"encoder-decoder Transformer\"), (\"audio\", \"related_to_core\", \"encoder-decoder Transformer\"), (\"16,000 Hz\", \"related_to_core\", \"encoder-decoder Transformer\"), (\"80-channel log-magnitude Mel spectrogram\", \"related_to_core\", \"encoder-decoder Transformer\"), (\"25-millisecond windows\", \"related_to_core\", \"encoder-decoder Transformer\"), (\"10 milliseconds\", \"related_to_core\", \"encoder-decoder Transformer\"), (\"feature normalization\", \"related_to_core\", \"encoder-decoder Transformer\"), (\"encoder-decoder Transformer\", \"instance of\", \"Transformer\"), (\"chunk_25\", \"mentions\", \"Vaswani et al.\"), (\"chunk_25\", \"mentions\", \"audio\"), (\"chunk_25\", \"mentions\", \"16,000 Hz\"), (\"chunk_25\", \"mentions\", \"80-channel log-magnitude Mel spectrogram\"), (\"chunk_25\", \"mentions\", \"25-millisecond windows\"), (\"chunk_25\", \"mentions\", \"10 milliseconds\"), (\"chunk_25\", \"mentions\", \"feature normalization\"), (\"audio\", \"re-sampled to\", \"16,000 Hz\"), (\"80-channel log-magnitude Mel spectrogram\", \"computed on\", \"25-millisecond windows\"), (\"25-millisecond windows\", \"stride\", \"10 milliseconds\")]\n",
            "✅ Extracted: [('encoder-decoder Transformer', 'is_core_idea', 'true'), ('chunk_25', 'is_core_chunk', 'true'), ('chunk_25', 'mentions', 'encoder-decoder Transformer'), ('Vaswani et al.', 'related_to_core', 'encoder-decoder Transformer'), ('audio', 'related_to_core', 'encoder-decoder Transformer'), ('16,000 Hz', 'related_to_core', 'encoder-decoder Transformer'), ('80-channel log-magnitude Mel spectrogram', 'related_to_core', 'encoder-decoder Transformer'), ('25-millisecond windows', 'related_to_core', 'encoder-decoder Transformer'), ('10 milliseconds', 'related_to_core', 'encoder-decoder Transformer'), ('feature normalization', 'related_to_core', 'encoder-decoder Transformer'), ('encoder-decoder Transformer', 'instance of', 'Transformer'), ('chunk_25', 'mentions', 'Vaswani et al.'), ('chunk_25', 'mentions', 'audio'), ('chunk_25', 'mentions', '16,000 Hz'), ('chunk_25', 'mentions', '80-channel log-magnitude Mel spectrogram'), ('chunk_25', 'mentions', '25-millisecond windows'), ('chunk_25', 'mentions', '10 milliseconds'), ('chunk_25', 'mentions', 'feature normalization'), ('audio', 're-sampled to', '16,000 Hz'), ('80-channel log-magnitude Mel spectrogram', 'computed on', '25-millisecond windows'), ('25-millisecond windows', 'stride', '10 milliseconds')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_26...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"pre-training dataset\", \"is_core_idea\", \"true\"), (\"chunk_26\", \"is_core_chunk\", \"true\"), (\"encoder\", \"related_to_core\", \"pre-training dataset\"), (\"convolution layers\", \"related_to_core\", \"pre-training dataset\"), (\"GELU activation function\", \"related_to_core\", \"pre-training dataset\"), (\"Sinusoidal position embeddings\", \"related_to_core\", \"pre-training dataset\"), (\"Transformer blocks\", \"related_to_core\", \"pre-training dataset\"), (\"pre-activation residual blocks\", \"related_to_core\", \"pre-training dataset\"), (\"encoder\", \"processes\", \"input representation\"), (\"convolution layers\", \"has_width\", \"3\"), (\"convolution layers\", \"uses\", \"GELU activation function\"), (\"convolution layer\", \"has_stride\", \"two\"), (\"encoder\", \"applies\", \"Transformer blocks\"), (\"chunk_26\", \"mentions\", \"pre-training dataset\"), (\"chunk_26\", \"mentions\", \"encoder\"), (\"chunk_26\", \"mentions\", \"convolution layers\"), (\"chunk_26\", \"mentions\", \"GELU activation function\"), (\"chunk_26\", \"mentions\", \"Sinusoidal position embeddings\"), (\"chunk_26\", \"mentions\", \"Transformer blocks\"), (\"chunk_26\", \"mentions\", \"pre-activation residual blocks\")]\n",
            "✅ Extracted: [('pre-training dataset', 'is_core_idea', 'true'), ('chunk_26', 'is_core_chunk', 'true'), ('encoder', 'related_to_core', 'pre-training dataset'), ('convolution layers', 'related_to_core', 'pre-training dataset'), ('GELU activation function', 'related_to_core', 'pre-training dataset'), ('Sinusoidal position embeddings', 'related_to_core', 'pre-training dataset'), ('Transformer blocks', 'related_to_core', 'pre-training dataset'), ('pre-activation residual blocks', 'related_to_core', 'pre-training dataset'), ('encoder', 'processes', 'input representation'), ('convolution layers', 'has_width', '3'), ('convolution layers', 'uses', 'GELU activation function'), ('convolution layer', 'has_stride', 'two'), ('encoder', 'applies', 'Transformer blocks'), ('chunk_26', 'mentions', 'pre-training dataset'), ('chunk_26', 'mentions', 'encoder'), ('chunk_26', 'mentions', 'convolution layers'), ('chunk_26', 'mentions', 'GELU activation function'), ('chunk_26', 'mentions', 'Sinusoidal position embeddings'), ('chunk_26', 'mentions', 'Transformer blocks'), ('chunk_26', 'mentions', 'pre-activation residual blocks')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_27...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"layer normalization\", \"applied_to\", \"encoder output\"), (\"encoder\", \"has\", \"same width\"), (\"encoder\", \"has\", \"same number of transformer blocks\"), (\"decoder\", \"uses\", \"learned position embeddings\"), (\"decoder\", \"uses\", \"tied input-output token representations\"), (\"decoder\", \"has\", \"same width\"), (\"decoder\", \"has\", \"same number of transformer blocks\"), (\"model architecture\", \"summarized_in\", \"Figure 1\"), (\"byte-level BPE text tokenizer\", \"used_in\", \"GPT-2\"), (\"English-only models\", \"use\", \"byte-level BPE text tokenizer\"), (\"vocabulary\", \"refit_by\", \"English-only models\"), (\"chunk_27\", \"mentions\", \"layer normalization\"), (\"chunk_27\", \"mentions\", \"encoder output\"), (\"chunk_27\", \"mentions\", \"decoder\"), (\"chunk_27\", \"mentions\", \"learned position embeddings\"), (\"chunk_27\", \"mentions\", \"input-output token representations\"), (\"chunk_27\", \"mentions\", \"encoder\"), (\"chunk_27\", \"mentions\", \"transformer blocks\"), (\"chunk_27\", \"mentions\", \"model architecture\"), (\"chunk_27\", \"mentions\", \"byte-level BPE text tokenizer\"), (\"chunk_27\", \"mentions\", \"GPT-2\"), (\"chunk_27\", \"mentions\", \"English-only models\"), (\"chunk_27\", \"mentions\", \"vocabulary\"), (\"model architecture\", \"is_core_idea\", \"true\"), (\"chunk_27\", \"is_core_chunk\", \"true\"), (\"layer normalization\", \"related_to_core\", \"model architecture\"), (\"encoder output\", \"related_to_core\", \"model architecture\"), (\"decoder\", \"related_to_core\", \"model architecture\"), (\"learned position embeddings\", \"related_to_core\", \"model architecture\"), (\"input-output token representations\", \"related_to_core\", \"model architecture\"), (\"encoder\", \"related_to_core\", \"model architecture\"), (\"transformer blocks\", \"related_to_core\", \"model architecture\"), (\"byte-level BPE text tokenizer\", \"related_to_core\", \"model architecture\"), (\"GPT-2\", \"related_to_core\", \"model architecture\"), (\"English-only models\", \"related_to_core\", \"model architecture\"), (\"vocabulary\", \"related_to_core\", \"model architecture\")]\n",
            "✅ Extracted: [('layer normalization', 'applied_to', 'encoder output'), ('encoder', 'has', 'same width'), ('encoder', 'has', 'same number of transformer blocks'), ('decoder', 'uses', 'learned position embeddings'), ('decoder', 'uses', 'tied input-output token representations'), ('decoder', 'has', 'same width'), ('decoder', 'has', 'same number of transformer blocks'), ('model architecture', 'summarized_in', 'Figure 1'), ('byte-level BPE text tokenizer', 'used_in', 'GPT-2'), ('English-only models', 'use', 'byte-level BPE text tokenizer'), ('vocabulary', 'refit_by', 'English-only models'), ('chunk_27', 'mentions', 'layer normalization'), ('chunk_27', 'mentions', 'encoder output'), ('chunk_27', 'mentions', 'decoder'), ('chunk_27', 'mentions', 'learned position embeddings'), ('chunk_27', 'mentions', 'input-output token representations'), ('chunk_27', 'mentions', 'encoder'), ('chunk_27', 'mentions', 'transformer blocks'), ('chunk_27', 'mentions', 'model architecture'), ('chunk_27', 'mentions', 'byte-level BPE text tokenizer'), ('chunk_27', 'mentions', 'GPT-2'), ('chunk_27', 'mentions', 'English-only models'), ('chunk_27', 'mentions', 'vocabulary'), ('model architecture', 'is_core_idea', 'true'), ('chunk_27', 'is_core_chunk', 'true'), ('layer normalization', 'related_to_core', 'model architecture'), ('encoder output', 'related_to_core', 'model architecture'), ('decoder', 'related_to_core', 'model architecture'), ('learned position embeddings', 'related_to_core', 'model architecture'), ('input-output token representations', 'related_to_core', 'model architecture'), ('encoder', 'related_to_core', 'model architecture'), ('transformer blocks', 'related_to_core', 'model architecture'), ('byte-level BPE text tokenizer', 'related_to_core', 'model architecture'), ('GPT-2', 'related_to_core', 'model architecture'), ('English-only models', 'related_to_core', 'model architecture'), ('vocabulary', 'related_to_core', 'model architecture')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_28...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"multilingual models\", \"avoid\", \"excessive fragmentation\"), (\"chunk_28\", \"mentions\", \"multilingual models\"), (\"GPT-2 BPE vocabulary\", \"is\", \"English\"), (\"chunk_28\", \"mentions\", \"GPT-2 BPE vocabulary\"), (\"Multitask Format\", \"is_core_idea\", \"true\"), (\"chunk_28\", \"mentions\", \"Multitask Format\"), (\"chunk_28\", \"is_core_chunk\", \"true\"), (\"words\", \"spoken in\", \"audio snippet\"), (\"chunk_28\", \"mentions\", \"words\"), (\"audio snippet\", \"related_to_core\", \"Multitask Format\"), (\"chunk_28\", \"mentions\", \"audio snippet\"), (\"speech recognition\", \"is_core_idea\", \"true\"), (\"chunk_28\", \"mentions\", \"speech recognition\"), (\"speech recognition system\", \"involve\", \"components\"), (\"chunk_28\", \"mentions\", \"speech recognition system\"), (\"voice activ\", \"related_to_core\", \"Multitask Format\"), (\"chunk_28\", \"mentions\", \"voice activ\")]\n",
            "✅ Extracted: [('multilingual models', 'avoid', 'excessive fragmentation'), ('chunk_28', 'mentions', 'multilingual models'), ('GPT-2 BPE vocabulary', 'is', 'English'), ('chunk_28', 'mentions', 'GPT-2 BPE vocabulary'), ('Multitask Format', 'is_core_idea', 'true'), ('chunk_28', 'mentions', 'Multitask Format'), ('chunk_28', 'is_core_chunk', 'true'), ('words', 'spoken in', 'audio snippet'), ('chunk_28', 'mentions', 'words'), ('audio snippet', 'related_to_core', 'Multitask Format'), ('chunk_28', 'mentions', 'audio snippet'), ('speech recognition', 'is_core_idea', 'true'), ('chunk_28', 'mentions', 'speech recognition'), ('speech recognition system', 'involve', 'components'), ('chunk_28', 'mentions', 'speech recognition system'), ('voice activ', 'related_to_core', 'Multitask Format'), ('chunk_28', 'mentions', 'voice activ')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_29...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"speaker diarization\", \"related_to_core\", \"speech recognition\"), (\"inverse text normalization\", \"related_to_core\", \"speech recognition\"), (\"speech recognition\", \"is_core_idea\", \"true\"), (\"chunk_29\", \"is_core_chunk\", \"true\"), (\"speaker diarization\", \"is_a\", \"task\"), (\"inverse text normalization\", \"is_a\", \"task\"), (\"speech recognition\", \"is_a\", \"model\"), (\"speech processing pipeline\", \"related_to_core\", \"speech recognition\"), (\"chunk_29\", \"mentions\", \"detection\"), (\"chunk_29\", \"mentions\", \"speaker diarization\"), (\"chunk_29\", \"mentions\", \"inverse text normalization\"), (\"chunk_29\", \"mentions\", \"speech recognition\"), (\"chunk_29\", \"mentions\", \"speech processing pipeline\"), (\"detection\", \"related_to_core\", \"speech recognition\"), (\"detection\", \"is_a\", \"task\"), (\"detection\", \"related_to_core\", \"speech recognition\"), (\"speech processing pipeline\", \"is_a\", \"pipeline\"), (\"detection\", \"related_to_core\", \"speech recognition\")]\n",
            "✅ Extracted: [('speaker diarization', 'related_to_core', 'speech recognition'), ('inverse text normalization', 'related_to_core', 'speech recognition'), ('speech recognition', 'is_core_idea', 'true'), ('chunk_29', 'is_core_chunk', 'true'), ('speaker diarization', 'is_a', 'task'), ('inverse text normalization', 'is_a', 'task'), ('speech recognition', 'is_a', 'model'), ('speech processing pipeline', 'related_to_core', 'speech recognition'), ('chunk_29', 'mentions', 'detection'), ('chunk_29', 'mentions', 'speaker diarization'), ('chunk_29', 'mentions', 'inverse text normalization'), ('chunk_29', 'mentions', 'speech recognition'), ('chunk_29', 'mentions', 'speech processing pipeline'), ('detection', 'related_to_core', 'speech recognition'), ('detection', 'is_a', 'task'), ('detection', 'related_to_core', 'speech recognition'), ('speech processing pipeline', 'is_a', 'pipeline'), ('detection', 'related_to_core', 'speech recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_30...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"input audio signal\", \"mentions\", \"transcription\"), (\"input audio signal\", \"mentions\", \"translation\"), (\"input audio signal\", \"mentions\", \"voice activity detection\"), (\"input audio signal\", \"mentions\", \"alignment\"), (\"input audio signal\", \"mentions\", \"language identiﬁcation\"), (\"chunk_30\", \"mentions\", \"input audio signal\"), (\"chunk_30\", \"mentions\", \"transcription\"), (\"chunk_30\", \"mentions\", \"translation\"), (\"chunk_30\", \"mentions\", \"voice activity detection\"), (\"chunk_30\", \"mentions\", \"alignment\"), (\"chunk_30\", \"mentions\", \"language identiﬁcation\"), (\"chunk_30\", \"mentions\", \"task speciﬁcation\"), (\"chunk_30\", \"mentions\", \"tasks\"), (\"chunk_30\", \"mentions\", \"conditioning information\"), (\"chunk_30\", \"mentions\", \"input tokens\"), (\"chunk_30\", \"mentions\", \"decoder\"), (\"chunk_30\", \"mentions\", \"audio-conditional language model\"), (\"transcription\", \"related_to_core\", \"input audio signal\"), (\"translation\", \"related_to_core\", \"input audio signal\"), (\"voice activity detection\", \"related_to_core\", \"input audio signal\"), (\"alignment\", \"related_to_core\", \"input audio signal\"), (\"language identiﬁcation\", \"related_to_core\", \"input audio signal\"), (\"task speciﬁcation\", \"related_to_core\", \"input audio signal\"), (\"tasks\", \"related_to_core\", \"input audio signal\"), (\"conditioning information\", \"related_to_core\", \"input audio signal\"), (\"input tokens\", \"related_to_core\", \"input audio signal\"), (\"decoder\", \"related_to_core\", \"input audio signal\"), (\"audio-conditional language model\", \"related_to_core\", \"input audio signal\"), (\"input audio signal\", \"is_core_idea\", \"true\"), (\"chunk_30\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('input audio signal', 'mentions', 'transcription'), ('input audio signal', 'mentions', 'translation'), ('input audio signal', 'mentions', 'voice activity detection'), ('input audio signal', 'mentions', 'alignment'), ('input audio signal', 'mentions', 'language identiﬁcation'), ('chunk_30', 'mentions', 'input audio signal'), ('chunk_30', 'mentions', 'transcription'), ('chunk_30', 'mentions', 'translation'), ('chunk_30', 'mentions', 'voice activity detection'), ('chunk_30', 'mentions', 'alignment'), ('chunk_30', 'mentions', 'language identiﬁcation'), ('chunk_30', 'mentions', 'task speciﬁcation'), ('chunk_30', 'mentions', 'tasks'), ('chunk_30', 'mentions', 'conditioning information'), ('chunk_30', 'mentions', 'input tokens'), ('chunk_30', 'mentions', 'decoder'), ('chunk_30', 'mentions', 'audio-conditional language model'), ('transcription', 'related_to_core', 'input audio signal'), ('translation', 'related_to_core', 'input audio signal'), ('voice activity detection', 'related_to_core', 'input audio signal'), ('alignment', 'related_to_core', 'input audio signal'), ('language identiﬁcation', 'related_to_core', 'input audio signal'), ('task speciﬁcation', 'related_to_core', 'input audio signal'), ('tasks', 'related_to_core', 'input audio signal'), ('conditioning information', 'related_to_core', 'input audio signal'), ('input tokens', 'related_to_core', 'input audio signal'), ('decoder', 'related_to_core', 'input audio signal'), ('audio-conditional language model', 'related_to_core', 'input audio signal'), ('input audio signal', 'is_core_idea', 'true'), ('chunk_30', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_31...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"history of text\", \"related_to_core\", \"Transcript\"), (\"transcript text\", \"related_to_core\", \"Transcript\"), (\"decoder\", \"related_to_core\", \"Transcript\"), (\"audio segment\", \"related_to_core\", \"Transcript\"), (\"<|startoftranscript|> token\", \"related_to_core\", \"Transcript\"), (\"language\", \"related_to_core\", \"Transcript\"), (\"training\", \"related_to_core\", \"Transcript\"), (\"chunk_31\", \"mentions\", \"history of text\"), (\"chunk_31\", \"mentions\", \"transcript text\"), (\"chunk_31\", \"mentions\", \"decoder\"), (\"chunk_31\", \"mentions\", \"audio segment\"), (\"chunk_31\", \"mentions\", \"<|startoftranscript|> token\"), (\"chunk_31\", \"mentions\", \"language\"), (\"chunk_31\", \"mentions\", \"training\"), (\"Transcript\", \"is_core_idea\", \"true\"), (\"chunk_31\", \"is_core_chunk\", \"true\"), (\"history of text\", \"predicate\", \"condition\"), (\"decoder\", \"predicate\", \"context\"), (\"language\", \"predicate\", \"spoken\"), (\"Transcript\", \"predicate\", \"resolve\"), (\"Transcript\", \"predicate\", \"learn\"), (\"chunk_31\", \"mentions\", \"Transcript\")]\n",
            "✅ Extracted: [('history of text', 'related_to_core', 'Transcript'), ('transcript text', 'related_to_core', 'Transcript'), ('decoder', 'related_to_core', 'Transcript'), ('audio segment', 'related_to_core', 'Transcript'), ('<|startoftranscript|> token', 'related_to_core', 'Transcript'), ('language', 'related_to_core', 'Transcript'), ('training', 'related_to_core', 'Transcript'), ('chunk_31', 'mentions', 'history of text'), ('chunk_31', 'mentions', 'transcript text'), ('chunk_31', 'mentions', 'decoder'), ('chunk_31', 'mentions', 'audio segment'), ('chunk_31', 'mentions', '<|startoftranscript|> token'), ('chunk_31', 'mentions', 'language'), ('chunk_31', 'mentions', 'training'), ('Transcript', 'is_core_idea', 'true'), ('chunk_31', 'is_core_chunk', 'true'), ('history of text', 'predicate', 'condition'), ('decoder', 'predicate', 'context'), ('language', 'predicate', 'spoken'), ('Transcript', 'predicate', 'resolve'), ('Transcript', 'predicate', 'learn'), ('chunk_31', 'mentions', 'Transcript')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_32...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"language targets\", \"is_core_idea\", \"true\"), (\"chunk_32\", \"is_core_chunk\", \"true\"), (\"VoxLingua107 model\", \"related_to_core\", \"language targets\"), (\"audio segment\", \"related_to_core\", \"language targets\"), (\"speech\", \"related_to_core\", \"language targets\"), (\"<|nospeech|> token\", \"related_to_core\", \"language targets\"), (\"task\", \"related_to_core\", \"language targets\"), (\"transcription\", \"related_to_core\", \"language targets\"), (\"translation\", \"related_to_core\", \"language targets\"), (\"<|transcribe|> token\", \"related_to_core\", \"language targets\"), (\"<|translate|> token\", \"related_to_core\", \"language targets\"), (\"timestamps\", \"related_to_core\", \"language targets\"), (\"<|notimestamps|> token\", \"related_to_core\", \"language targets\"), (\"chunk_32\", \"mentions\", \"language targets\"), (\"language targets\", \"sourced_from\", \"VoxLingua107 model\"), (\"model\", \"trained_to_predict\", \"<|nospeech|> token\"), (\"chunk_32\", \"mentions\", \"VoxLingua107 model\"), (\"chunk_32\", \"mentions\", \"audio segment\"), (\"chunk_32\", \"mentions\", \"speech\"), (\"chunk_32\", \"mentions\", \"<|nospeech|> token\"), (\"chunk_32\", \"mentions\", \"task\"), (\"chunk_32\", \"mentions\", \"transcription\"), (\"chunk_32\", \"mentions\", \"translation\"), (\"chunk_32\", \"mentions\", \"<|transcribe|> token\"), (\"chunk_32\", \"mentions\", \"<|translate|> token\"), (\"chunk_32\", \"mentions\", \"timestamps\"), (\"chunk_32\", \"mentions\", \"<|notimestamps|> token\")]\n",
            "✅ Extracted: [('language targets', 'is_core_idea', 'true'), ('chunk_32', 'is_core_chunk', 'true'), ('VoxLingua107 model', 'related_to_core', 'language targets'), ('audio segment', 'related_to_core', 'language targets'), ('speech', 'related_to_core', 'language targets'), ('<|nospeech|> token', 'related_to_core', 'language targets'), ('task', 'related_to_core', 'language targets'), ('transcription', 'related_to_core', 'language targets'), ('translation', 'related_to_core', 'language targets'), ('<|transcribe|> token', 'related_to_core', 'language targets'), ('<|translate|> token', 'related_to_core', 'language targets'), ('timestamps', 'related_to_core', 'language targets'), ('<|notimestamps|> token', 'related_to_core', 'language targets'), ('chunk_32', 'mentions', 'language targets'), ('language targets', 'sourced_from', 'VoxLingua107 model'), ('model', 'trained_to_predict', '<|nospeech|> token'), ('chunk_32', 'mentions', 'VoxLingua107 model'), ('chunk_32', 'mentions', 'audio segment'), ('chunk_32', 'mentions', 'speech'), ('chunk_32', 'mentions', '<|nospeech|> token'), ('chunk_32', 'mentions', 'task'), ('chunk_32', 'mentions', 'transcription'), ('chunk_32', 'mentions', 'translation'), ('chunk_32', 'mentions', '<|transcribe|> token'), ('chunk_32', 'mentions', '<|translate|> token'), ('chunk_32', 'mentions', 'timestamps'), ('chunk_32', 'mentions', '<|notimestamps|> token')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_33...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"timestamp prediction\", \"is_core_idea\", \"true\"), (\"chunk_33\", \"is_core_chunk\", \"true\"), (\"chunk_33\", \"mentions\", \"timestamp prediction\"), (\"audio segment\", \"related_to_core\", \"timestamp prediction\"), (\"time\", \"related_to_core\", \"timestamp prediction\"), (\"20 milliseconds\", \"related_to_core\", \"timestamp prediction\"), (\"time resolution\", \"related_to_core\", \"timestamp prediction\"), (\"Whisper models\", \"related_to_core\", \"timestamp prediction\"), (\"vocabulary\", \"related_to_core\", \"timestamp prediction\"), (\"tokens\", \"related_to_core\", \"timestamp prediction\"), (\"prediction\", \"related_to_core\", \"timestamp prediction\"), (\"caption tokens\", \"related_to_core\", \"timestamp prediction\"), (\"time token\", \"related_to_core\", \"timestamp prediction\"), (\"caption's text\", \"related_to_core\", \"timestamp prediction\"), (\"audio segment\", \"predicate\", \"relative to\"), (\"time\", \"predicate\", \"relative to\"), (\"audio segment\",), (\"time\",), (\"20 milliseconds\",), (\"time\", \"predicate\", \"quantizing\"), (\"time resolution\",), (\"Whisper models\",), (\"vocabulary\",), (\"tokens\",), (\"prediction\",), (\"caption tokens\",), (\"time token\",), (\"caption's text\",), (\"chunk_33\", \"mentions\", \"audio segment\"), (\"chunk_33\", \"mentions\", \"time\"), (\"chunk_33\", \"mentions\", \"20 milliseconds\"), (\"chunk_33\", \"mentions\", \"time resolution\"), (\"chunk_33\", \"mentions\", \"Whisper models\"), (\"chunk_33\", \"mentions\", \"vocabulary\"), (\"chunk_33\", \"mentions\", \"tokens\"), (\"chunk_33\", \"mentions\", \"prediction\"), (\"chunk_33\", \"mentions\", \"caption tokens\"), (\"chunk_33\", \"mentions\", \"time token\"), (\"chunk_33\", \"mentions\", \"caption's text\")]\n",
            "✅ Extracted: [('timestamp prediction', 'is_core_idea', 'true'), ('chunk_33', 'is_core_chunk', 'true'), ('chunk_33', 'mentions', 'timestamp prediction'), ('audio segment', 'related_to_core', 'timestamp prediction'), ('time', 'related_to_core', 'timestamp prediction'), ('20 milliseconds', 'related_to_core', 'timestamp prediction'), ('time resolution', 'related_to_core', 'timestamp prediction'), ('Whisper models', 'related_to_core', 'timestamp prediction'), ('vocabulary', 'related_to_core', 'timestamp prediction'), ('tokens', 'related_to_core', 'timestamp prediction'), ('prediction', 'related_to_core', 'timestamp prediction'), ('caption tokens', 'related_to_core', 'timestamp prediction'), ('time token', 'related_to_core', 'timestamp prediction'), (\"caption's text\", 'related_to_core', 'timestamp prediction'), ('audio segment', 'predicate', 'relative to'), ('time', 'predicate', 'relative to'), ('audio segment',), ('time',), ('20 milliseconds',), ('time', 'predicate', 'quantizing'), ('time resolution',), ('Whisper models',), ('vocabulary',), ('tokens',), ('prediction',), ('caption tokens',), ('time token',), (\"caption's text\",), ('chunk_33', 'mentions', 'audio segment'), ('chunk_33', 'mentions', 'time'), ('chunk_33', 'mentions', '20 milliseconds'), ('chunk_33', 'mentions', 'time resolution'), ('chunk_33', 'mentions', 'Whisper models'), ('chunk_33', 'mentions', 'vocabulary'), ('chunk_33', 'mentions', 'tokens'), ('chunk_33', 'mentions', 'prediction'), ('chunk_33', 'mentions', 'caption tokens'), ('chunk_33', 'mentions', 'time token'), ('chunk_33', 'mentions', \"caption's text\")]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Skipping invalid triple: ('audio segment',)\n",
            "⚠️ Skipping invalid triple: ('time',)\n",
            "⚠️ Skipping invalid triple: ('20 milliseconds',)\n",
            "⚠️ Skipping invalid triple: ('time resolution',)\n",
            "⚠️ Skipping invalid triple: ('Whisper models',)\n",
            "⚠️ Skipping invalid triple: ('vocabulary',)\n",
            "⚠️ Skipping invalid triple: ('tokens',)\n",
            "⚠️ Skipping invalid triple: ('prediction',)\n",
            "⚠️ Skipping invalid triple: ('caption tokens',)\n",
            "⚠️ Skipping invalid triple: ('time token',)\n",
            "⚠️ Skipping invalid triple: (\"caption's text\",)\n",
            "🔍 Processing chunk_34...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"end time token\", \"is_core_idea\", \"true\"), (\"chunk_34\", \"is_core_chunk\", \"true\"), (\"chunk_34\", \"mentions\", \"end time token\"), (\"transcript segment\", \"related_to_core\", \"end time token\"), (\"chunk_34\", \"mentions\", \"transcript segment\"), (\"audio chunk\", \"related_to_core\", \"end time token\"), (\"chunk_34\", \"mentions\", \"audio chunk\"), (\"start time token\", \"related_to_core\", \"end time token\"), (\"chunk_34\", \"mentions\", \"start time token\"), (\"timestamp mode\", \"related_to_core\", \"end time token\"), (\"chunk_34\", \"mentions\", \"timestamp mode\"), (\"audio window\", \"related_to_core\", \"end time token\"), (\"chunk_34\", \"mentions\", \"audio window\"), (\"<|endoftranscript|> token\", \"related_to_core\", \"end time token\"), (\"chunk_34\", \"mentions\", \"<|endoftranscript|> token\"), (\"transcript segment\", \"is_included_in\", \"audio chunk\"), (\"start time token\", \"is_predicted_in\", \"timestamp mode\"), (\"decoding\", \"should_be_performed_on\", \"audio window\")]\n",
            "✅ Extracted: [('end time token', 'is_core_idea', 'true'), ('chunk_34', 'is_core_chunk', 'true'), ('chunk_34', 'mentions', 'end time token'), ('transcript segment', 'related_to_core', 'end time token'), ('chunk_34', 'mentions', 'transcript segment'), ('audio chunk', 'related_to_core', 'end time token'), ('chunk_34', 'mentions', 'audio chunk'), ('start time token', 'related_to_core', 'end time token'), ('chunk_34', 'mentions', 'start time token'), ('timestamp mode', 'related_to_core', 'end time token'), ('chunk_34', 'mentions', 'timestamp mode'), ('audio window', 'related_to_core', 'end time token'), ('chunk_34', 'mentions', 'audio window'), ('<|endoftranscript|> token', 'related_to_core', 'end time token'), ('chunk_34', 'mentions', '<|endoftranscript|> token'), ('transcript segment', 'is_included_in', 'audio chunk'), ('start time token', 'is_predicted_in', 'timestamp mode'), ('decoding', 'should_be_performed_on', 'audio window')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_35...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"training loss\", \"object_of\", \"mask out\"), (\"context text\", \"previous_to\", \"training loss\"), (\"model\", \"predicate\", \"train\"), (\"tokens\", \"object_of\", \"predict\"), (\"Figure 1\", \"contains\", \"overview\"), (\"format\", \"part_of\", \"Figure 1\"), (\"training setup\", \"part_of\", \"Figure 1\"), (\"chunk_35\", \"mentions\", \"training loss\"), (\"chunk_35\", \"mentions\", \"context text\"), (\"chunk_35\", \"mentions\", \"model\"), (\"chunk_35\", \"mentions\", \"tokens\"), (\"chunk_35\", \"mentions\", \"Figure 1\"), (\"chunk_35\", \"mentions\", \"format\"), (\"chunk_35\", \"mentions\", \"training setup\"), (\"model\", \"is_core_idea\", \"true\"), (\"chunk_35\", \"is_core_chunk\", \"true\"), (\"training loss\", \"related_to_core\", \"model\"), (\"context text\", \"related_to_core\", \"model\"), (\"tokens\", \"related_to_core\", \"model\"), (\"Figure 1\", \"related_to_core\", \"model\"), (\"format\", \"related_to_core\", \"model\"), (\"training setup\", \"related_to_core\", \"model\")]\n",
            "✅ Extracted: [('training loss', 'object_of', 'mask out'), ('context text', 'previous_to', 'training loss'), ('model', 'predicate', 'train'), ('tokens', 'object_of', 'predict'), ('Figure 1', 'contains', 'overview'), ('format', 'part_of', 'Figure 1'), ('training setup', 'part_of', 'Figure 1'), ('chunk_35', 'mentions', 'training loss'), ('chunk_35', 'mentions', 'context text'), ('chunk_35', 'mentions', 'model'), ('chunk_35', 'mentions', 'tokens'), ('chunk_35', 'mentions', 'Figure 1'), ('chunk_35', 'mentions', 'format'), ('chunk_35', 'mentions', 'training setup'), ('model', 'is_core_idea', 'true'), ('chunk_35', 'is_core_chunk', 'true'), ('training loss', 'related_to_core', 'model'), ('context text', 'related_to_core', 'model'), ('tokens', 'related_to_core', 'model'), ('Figure 1', 'related_to_core', 'model'), ('format', 'related_to_core', 'model'), ('training setup', 'related_to_core', 'model')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_36...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_36\", \"is_core_chunk\", \"true\"), (\"Speech Recognition\", \"related_to_core\", \"Large-Scale Weak Supervision\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"2 × Conv1D\"), (\"2 × Conv1D\", \"related_to_core\", \"GELU\"), (\"GELU\", \"related_to_core\", \"cross attention\"), (\"cross attention\", \"related_to_core\", \"Log-Mel Spectrogram\"), (\"Log-Mel Spectrogram\", \"related_to_core\", \"Tokens in Multitask Training Format\"), (\"Tokens in Multitask Training Format\", \"related_to_core\", \"Transformer\"), (\"Transformer\", \"related_to_core\", \"Encoder Blocks\"), (\"Encoder Blocks\", \"related_to_core\", \"Decoder Blocks\"), (\"Decoder Blocks\", \"related_to_core\", \"next-token\"), (\"next-token\", \"related_to_core\", \"prediction\"), (\"prediction\", \"related_to_core\", \"Sinusoidal\"), (\"Sinusoidal\", \"related_to_core\", \"Positional\"), (\"Positional\", \"related_to_core\", \"Encoding\"), (\"Encoding\", \"related_to_core\", \"Learned\"), (\"Learned\", \"related_to_core\", \"Positional\"), (\"Positional\", \"related_to_core\", \"Encoding\"), (\"Encoding\", \"related_to_core\", \"Multitask training data\"), (\"Multitask training data\", \"related_to_core\", \"Sequence-to-sequence learning\"), (\"Sequence-to-sequence learning\", \"related_to_core\", \"Multitask training format\"), (\"Multitask training format\", \"related_to_core\", \"English transcription\"), (\"chunk_36\", \"mentions\", \"Speech Recognition\"), (\"chunk_36\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_36\", \"mentions\", \"2 × Conv1D\"), (\"chunk_36\", \"mentions\", \"GELU\"), (\"chunk_36\", \"mentions\", \"cross attention\"), (\"chunk_36\", \"mentions\", \"Log-Mel Spectrogram\"), (\"chunk_36\", \"mentions\", \"Tokens in Multitask Training Format\"), (\"chunk_36\", \"mentions\", \"Transformer\"), (\"chunk_36\", \"mentions\", \"Encoder Blocks\"), (\"chunk_36\", \"mentions\", \"Decoder Blocks\"), (\"chunk_36\", \"mentions\", \"next-token\"), (\"chunk_36\", \"mentions\", \"prediction\"), (\"chunk_36\", \"mentions\", \"Sinusoidal\"), (\"chunk_36\", \"mentions\", \"Positional\"), (\"chunk_36\", \"mentions\", \"Encoding\"), (\"chunk_36\", \"mentions\", \"Learned\"), (\"chunk_36\", \"mentions\", \"Multitask training data\"), (\"chunk_36\", \"mentions\", \"Sequence-to-sequence learning\"), (\"chunk_36\", \"mentions\", \"Multitask training format\"), (\"chunk_36\", \"mentions\", \"English transcription\"), (\"Positional\", \"related_to_core\", \"Positional Encoding\")]\n",
            "✅ Extracted: [('Speech Recognition', 'is_core_idea', 'true'), ('chunk_36', 'is_core_chunk', 'true'), ('Speech Recognition', 'related_to_core', 'Large-Scale Weak Supervision'), ('Large-Scale Weak Supervision', 'related_to_core', '2 × Conv1D'), ('2 × Conv1D', 'related_to_core', 'GELU'), ('GELU', 'related_to_core', 'cross attention'), ('cross attention', 'related_to_core', 'Log-Mel Spectrogram'), ('Log-Mel Spectrogram', 'related_to_core', 'Tokens in Multitask Training Format'), ('Tokens in Multitask Training Format', 'related_to_core', 'Transformer'), ('Transformer', 'related_to_core', 'Encoder Blocks'), ('Encoder Blocks', 'related_to_core', 'Decoder Blocks'), ('Decoder Blocks', 'related_to_core', 'next-token'), ('next-token', 'related_to_core', 'prediction'), ('prediction', 'related_to_core', 'Sinusoidal'), ('Sinusoidal', 'related_to_core', 'Positional'), ('Positional', 'related_to_core', 'Encoding'), ('Encoding', 'related_to_core', 'Learned'), ('Learned', 'related_to_core', 'Positional'), ('Positional', 'related_to_core', 'Encoding'), ('Encoding', 'related_to_core', 'Multitask training data'), ('Multitask training data', 'related_to_core', 'Sequence-to-sequence learning'), ('Sequence-to-sequence learning', 'related_to_core', 'Multitask training format'), ('Multitask training format', 'related_to_core', 'English transcription'), ('chunk_36', 'mentions', 'Speech Recognition'), ('chunk_36', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_36', 'mentions', '2 × Conv1D'), ('chunk_36', 'mentions', 'GELU'), ('chunk_36', 'mentions', 'cross attention'), ('chunk_36', 'mentions', 'Log-Mel Spectrogram'), ('chunk_36', 'mentions', 'Tokens in Multitask Training Format'), ('chunk_36', 'mentions', 'Transformer'), ('chunk_36', 'mentions', 'Encoder Blocks'), ('chunk_36', 'mentions', 'Decoder Blocks'), ('chunk_36', 'mentions', 'next-token'), ('chunk_36', 'mentions', 'prediction'), ('chunk_36', 'mentions', 'Sinusoidal'), ('chunk_36', 'mentions', 'Positional'), ('chunk_36', 'mentions', 'Encoding'), ('chunk_36', 'mentions', 'Learned'), ('chunk_36', 'mentions', 'Multitask training data'), ('chunk_36', 'mentions', 'Sequence-to-sequence learning'), ('chunk_36', 'mentions', 'Multitask training format'), ('chunk_36', 'mentions', 'English transcription'), ('Positional', 'related_to_core', 'Positional Encoding')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_37...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Multitask training format\", \"is_core_idea\", \"true\"), (\"chunk_37\", \"is_core_chunk\", \"true\"), (\"chunk_37\", \"mentions\", \"Multitask training format\"), (\"English transcription\", \"related_to_core\", \"Multitask training format\"), (\"chunk_37\", \"mentions\", \"English transcription\"), (\"Any-to-English speech translation\", \"related_to_core\", \"Multitask training format\"), (\"chunk_37\", \"mentions\", \"Any-to-English speech translation\"), (\"Non-English transcription\", \"related_to_core\", \"Multitask training format\"), (\"chunk_37\", \"mentions\", \"Non-English transcription\"), (\"speech\", \"related_to_core\", \"Multitask training format\"), (\"chunk_37\", \"mentions\", \"speech\"), (\"tokens\", \"related_to_core\", \"Multitask training format\"), (\"chunk_37\", \"mentions\", \"tokens\"), (\"timestamp\", \"related_to_core\", \"Multitask training format\"), (\"chunk_37\", \"mentions\", \"timestamp\"), (\"TRANSCRIPT\", \"related_to_core\", \"Multitask training format\"), (\"chunk_37\", \"mentions\", \"TRANSCRIPT\"), (\"LANGUAGE\", \"related_to_core\", \"Multitask training format\"), (\"chunk_37\", \"mentions\", \"LANGUAGE\"), (\"TAG\", \"related_to_core\", \"Multitask training format\"), (\"chunk_37\", \"mentions\", \"TAG\")]\n",
            "✅ Extracted: [('Multitask training format', 'is_core_idea', 'true'), ('chunk_37', 'is_core_chunk', 'true'), ('chunk_37', 'mentions', 'Multitask training format'), ('English transcription', 'related_to_core', 'Multitask training format'), ('chunk_37', 'mentions', 'English transcription'), ('Any-to-English speech translation', 'related_to_core', 'Multitask training format'), ('chunk_37', 'mentions', 'Any-to-English speech translation'), ('Non-English transcription', 'related_to_core', 'Multitask training format'), ('chunk_37', 'mentions', 'Non-English transcription'), ('speech', 'related_to_core', 'Multitask training format'), ('chunk_37', 'mentions', 'speech'), ('tokens', 'related_to_core', 'Multitask training format'), ('chunk_37', 'mentions', 'tokens'), ('timestamp', 'related_to_core', 'Multitask training format'), ('chunk_37', 'mentions', 'timestamp'), ('TRANSCRIPT', 'related_to_core', 'Multitask training format'), ('chunk_37', 'mentions', 'TRANSCRIPT'), ('LANGUAGE', 'related_to_core', 'Multitask training format'), ('chunk_37', 'mentions', 'LANGUAGE'), ('TAG', 'related_to_core', 'Multitask training format'), ('chunk_37', 'mentions', 'TAG')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_38...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Voice activity detection\", \"abbreviation\", \"VAD\"), (\"chunk_38\", \"mentions\", \"Voice activity detection\"), (\"Custom vocabulary\", \"related_to_core\", \"Time-aligned transcription\"), (\"chunk_38\", \"mentions\", \"Custom vocabulary\"), (\"Time-aligned transcription\", \"is_core_idea\", \"true\"), (\"chunk_38\", \"is_core_chunk\", \"true\"), (\"chunk_38\", \"mentions\", \"Time-aligned transcription\"), (\"Text-only transcription\", \"related_to_core\", \"Time-aligned transcription\"), (\"chunk_38\", \"mentions\", \"Text-only transcription\"), (\"English Translation\", \"related_to_core\", \"Time-aligned transcription\"), (\"chunk_38\", \"mentions\", \"English Translation\"), (\"Transcription\", \"related_to_core\", \"Time-aligned transcription\"), (\"chunk_38\", \"mentions\", \"Transcription\"), (\"Language identification\", \"related_to_core\", \"Time-aligned transcription\"), (\"chunk_38\", \"mentions\", \"Language identification\"), (\"MLP\", \"related_to_core\", \"Time-aligned transcription\"), (\"chunk_38\", \"mentions\", \"MLP\"), (\"self attention\", \"related_to_core\", \"Time-aligned transcription\"), (\"chunk_38\", \"mentions\", \"self attention\"), (\"cross attention\", \"related_to_core\", \"Time-aligned transcription\"), (\"chunk_38\", \"mentions\", \"cross attention\")]\n",
            "✅ Extracted: [('Voice activity detection', 'abbreviation', 'VAD'), ('chunk_38', 'mentions', 'Voice activity detection'), ('Custom vocabulary', 'related_to_core', 'Time-aligned transcription'), ('chunk_38', 'mentions', 'Custom vocabulary'), ('Time-aligned transcription', 'is_core_idea', 'true'), ('chunk_38', 'is_core_chunk', 'true'), ('chunk_38', 'mentions', 'Time-aligned transcription'), ('Text-only transcription', 'related_to_core', 'Time-aligned transcription'), ('chunk_38', 'mentions', 'Text-only transcription'), ('English Translation', 'related_to_core', 'Time-aligned transcription'), ('chunk_38', 'mentions', 'English Translation'), ('Transcription', 'related_to_core', 'Time-aligned transcription'), ('chunk_38', 'mentions', 'Transcription'), ('Language identification', 'related_to_core', 'Time-aligned transcription'), ('chunk_38', 'mentions', 'Language identification'), ('MLP', 'related_to_core', 'Time-aligned transcription'), ('chunk_38', 'mentions', 'MLP'), ('self attention', 'related_to_core', 'Time-aligned transcription'), ('chunk_38', 'mentions', 'self attention'), ('cross attention', 'related_to_core', 'Time-aligned transcription'), ('chunk_38', 'mentions', 'cross attention')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_39...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"MLP\", \"mentions\", \"MLP\"), (\"chunk_39\", \"mentions\", \"MLP\"), (\"self attention\", \"mentions\", \"self attention\"), (\"chunk_39\", \"mentions\", \"self attention\"), (\"cross attention\", \"mentions\", \"cross attention\"), (\"chunk_39\", \"mentions\", \"cross attention\"), (\"TRANS-CRIBE\", \"mentions\", \"TRANS-CRIBE\"), (\"chunk_39\", \"mentions\", \"TRANS-CRIBE\"), (\"sequence-to-sequence Transformer model\", \"mentions\", \"sequence-to-sequence Transformer model\"), (\"chunk_39\", \"mentions\", \"sequence-to-sequence Transformer model\"), (\"speech processing tasks\", \"mentions\", \"speech processing tasks\"), (\"chunk_39\", \"mentions\", \"speech processing tasks\"), (\"multilingual speech recognition\", \"mentions\", \"multilingual speech recognition\"), (\"chunk_39\", \"mentions\", \"multilingual speech recognition\"), (\"speech translation\", \"mentions\", \"speech translation\"), (\"chunk_39\", \"mentions\", \"speech translation\"), (\"spoken language identiﬁcation\", \"mentions\", \"spoken language identiﬁcation\"), (\"chunk_39\", \"mentions\", \"spoken language identiﬁcation\"), (\"voice activity detection\", \"mentions\", \"voice activity detection\"), (\"chunk_39\", \"mentions\", \"voice activity detection\"), (\"sequence-to-sequence Transformer model\", \"is_core_idea\", \"true\"), (\"chunk_39\", \"is_core_chunk\", \"true\"), (\"MLP\", \"related_to_core\", \"sequence-to-sequence Transformer model\"), (\"self attention\", \"related_to_core\", \"sequence-to-sequence Transformer model\"), (\"cross attention\", \"related_to_core\", \"sequence-to-sequence Transformer model\"), (\"TRANS-CRIBE\", \"related_to_core\", \"sequence-to-sequence Transformer model\"), (\"speech processing tasks\", \"related_to_core\", \"sequence-to-sequence Transformer model\"), (\"multilingual speech recognition\", \"related_to_core\", \"sequence-to-sequence Transformer model\"), (\"speech translation\", \"related_to_core\", \"sequence-to-sequence Transformer model\"), (\"spoken language identiﬁcation\", \"related_to_core\", \"sequence-to-sequence Transformer model\"), (\"voice activity detection\", \"related_to_core\", \"sequence-to-sequence Transformer model\")]\n",
            "✅ Extracted: [('MLP', 'mentions', 'MLP'), ('chunk_39', 'mentions', 'MLP'), ('self attention', 'mentions', 'self attention'), ('chunk_39', 'mentions', 'self attention'), ('cross attention', 'mentions', 'cross attention'), ('chunk_39', 'mentions', 'cross attention'), ('TRANS-CRIBE', 'mentions', 'TRANS-CRIBE'), ('chunk_39', 'mentions', 'TRANS-CRIBE'), ('sequence-to-sequence Transformer model', 'mentions', 'sequence-to-sequence Transformer model'), ('chunk_39', 'mentions', 'sequence-to-sequence Transformer model'), ('speech processing tasks', 'mentions', 'speech processing tasks'), ('chunk_39', 'mentions', 'speech processing tasks'), ('multilingual speech recognition', 'mentions', 'multilingual speech recognition'), ('chunk_39', 'mentions', 'multilingual speech recognition'), ('speech translation', 'mentions', 'speech translation'), ('chunk_39', 'mentions', 'speech translation'), ('spoken language identiﬁcation', 'mentions', 'spoken language identiﬁcation'), ('chunk_39', 'mentions', 'spoken language identiﬁcation'), ('voice activity detection', 'mentions', 'voice activity detection'), ('chunk_39', 'mentions', 'voice activity detection'), ('sequence-to-sequence Transformer model', 'is_core_idea', 'true'), ('chunk_39', 'is_core_chunk', 'true'), ('MLP', 'related_to_core', 'sequence-to-sequence Transformer model'), ('self attention', 'related_to_core', 'sequence-to-sequence Transformer model'), ('cross attention', 'related_to_core', 'sequence-to-sequence Transformer model'), ('TRANS-CRIBE', 'related_to_core', 'sequence-to-sequence Transformer model'), ('speech processing tasks', 'related_to_core', 'sequence-to-sequence Transformer model'), ('multilingual speech recognition', 'related_to_core', 'sequence-to-sequence Transformer model'), ('speech translation', 'related_to_core', 'sequence-to-sequence Transformer model'), ('spoken language identiﬁcation', 'related_to_core', 'sequence-to-sequence Transformer model'), ('voice activity detection', 'related_to_core', 'sequence-to-sequence Transformer model')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_40...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"tasks\", \"represented_as\", \"sequence of tokens\"), (\"decoder\", \"predicts\", \"sequence of tokens\"), (\"single model\", \"replaces\", \"many different stages\"), (\"speech processing pipeline\", \"traditional\", \"true\"), (\"multitask training format\", \"uses\", \"set of special tokens\"), (\"special tokens\", \"serve as\", \"task speciﬁers\"), (\"special tokens\", \"serve as\", \"classiﬁcation targets\"), (\"models\", \"suite of\", \"true\"), (\"Whisper\", \"scaling properties\", \"true\"), (\"chunk_40\", \"mentions\", \"tasks\"), (\"chunk_40\", \"mentions\", \"sequence of tokens\"), (\"chunk_40\", \"mentions\", \"decoder\"), (\"chunk_40\", \"mentions\", \"single model\"), (\"chunk_40\", \"mentions\", \"speech processing pipeline\"), (\"chunk_40\", \"mentions\", \"multitask training format\"), (\"chunk_40\", \"mentions\", \"special tokens\"), (\"chunk_40\", \"mentions\", \"classiﬁcation targets\"), (\"chunk_40\", \"mentions\", \"models\"), (\"chunk_40\", \"mentions\", \"Whisper\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_40\", \"is_core_chunk\", \"true\"), (\"tasks\", \"related_to_core\", \"Whisper\"), (\"sequence of tokens\", \"related_to_core\", \"Whisper\"), (\"decoder\", \"related_to_core\", \"Whisper\"), (\"single model\", \"related_to_core\", \"Whisper\"), (\"speech processing pipeline\", \"related_to_core\", \"Whisper\"), (\"multitask training format\", \"related_to_core\", \"Whisper\"), (\"special tokens\", \"related_to_core\", \"Whisper\"), (\"classiﬁcation targets\", \"related_to_core\", \"Whisper\"), (\"models\", \"related_to_core\", \"Whisper\")]\n",
            "✅ Extracted: [('tasks', 'represented_as', 'sequence of tokens'), ('decoder', 'predicts', 'sequence of tokens'), ('single model', 'replaces', 'many different stages'), ('speech processing pipeline', 'traditional', 'true'), ('multitask training format', 'uses', 'set of special tokens'), ('special tokens', 'serve as', 'task speciﬁers'), ('special tokens', 'serve as', 'classiﬁcation targets'), ('models', 'suite of', 'true'), ('Whisper', 'scaling properties', 'true'), ('chunk_40', 'mentions', 'tasks'), ('chunk_40', 'mentions', 'sequence of tokens'), ('chunk_40', 'mentions', 'decoder'), ('chunk_40', 'mentions', 'single model'), ('chunk_40', 'mentions', 'speech processing pipeline'), ('chunk_40', 'mentions', 'multitask training format'), ('chunk_40', 'mentions', 'special tokens'), ('chunk_40', 'mentions', 'classiﬁcation targets'), ('chunk_40', 'mentions', 'models'), ('chunk_40', 'mentions', 'Whisper'), ('Whisper', 'is_core_idea', 'true'), ('chunk_40', 'is_core_chunk', 'true'), ('tasks', 'related_to_core', 'Whisper'), ('sequence of tokens', 'related_to_core', 'Whisper'), ('decoder', 'related_to_core', 'Whisper'), ('single model', 'related_to_core', 'Whisper'), ('speech processing pipeline', 'related_to_core', 'Whisper'), ('multitask training format', 'related_to_core', 'Whisper'), ('special tokens', 'related_to_core', 'Whisper'), ('classiﬁcation targets', 'related_to_core', 'Whisper'), ('models', 'related_to_core', 'Whisper')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_41...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"data parallelism\", \"related_to_core\", \"training\"), (\"accelerators\", \"related_to_core\", \"training\"), (\"FP16\", \"related_to_core\", \"training\"), (\"dynamic loss scaling\", \"related_to_core\", \"training\"), (\"activation checkpointing\", \"related_to_core\", \"training\"), (\"AdamW\", \"related_to_core\", \"training\"), (\"gradient norm clipping\", \"related_to_core\", \"training\"), (\"linear learning rate decay\", \"related_to_core\", \"training\"), (\"batch size\", \"related_to_core\", \"training\"), (\"segments\", \"related_to_core\", \"training\"), (\"training\", \"is_core_idea\", \"true\"), (\"chunk_41\", \"is_core_chunk\", \"true\"), (\"chunk_41\", \"mentions\", \"data parallelism\"), (\"chunk_41\", \"mentions\", \"accelerators\"), (\"chunk_41\", \"mentions\", \"FP16\"), (\"chunk_41\", \"mentions\", \"dynamic loss scaling\"), (\"chunk_41\", \"mentions\", \"activation checkpointing\"), (\"chunk_41\", \"mentions\", \"AdamW\"), (\"chunk_41\", \"mentions\", \"gradient norm clipping\"), (\"chunk_41\", \"mentions\", \"linear learning rate decay\"), (\"chunk_41\", \"mentions\", \"batch size\"), (\"chunk_41\", \"mentions\", \"segments\"), (\"chunk_41\", \"mentions\", \"training\")]\n",
            "✅ Extracted: [('data parallelism', 'related_to_core', 'training'), ('accelerators', 'related_to_core', 'training'), ('FP16', 'related_to_core', 'training'), ('dynamic loss scaling', 'related_to_core', 'training'), ('activation checkpointing', 'related_to_core', 'training'), ('AdamW', 'related_to_core', 'training'), ('gradient norm clipping', 'related_to_core', 'training'), ('linear learning rate decay', 'related_to_core', 'training'), ('batch size', 'related_to_core', 'training'), ('segments', 'related_to_core', 'training'), ('training', 'is_core_idea', 'true'), ('chunk_41', 'is_core_chunk', 'true'), ('chunk_41', 'mentions', 'data parallelism'), ('chunk_41', 'mentions', 'accelerators'), ('chunk_41', 'mentions', 'FP16'), ('chunk_41', 'mentions', 'dynamic loss scaling'), ('chunk_41', 'mentions', 'activation checkpointing'), ('chunk_41', 'mentions', 'AdamW'), ('chunk_41', 'mentions', 'gradient norm clipping'), ('chunk_41', 'mentions', 'linear learning rate decay'), ('chunk_41', 'mentions', 'batch size'), ('chunk_41', 'mentions', 'segments'), ('chunk_41', 'mentions', 'training')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_42...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"dataset\", \"mentions\", \"dataset\"), (\"epochs\", \"mentions\", \"epochs\"), (\"over-ﬁtting\", \"mentions\", \"over-ﬁtting\"), (\"data augmentation\", \"mentions\", \"data augmentation\"), (\"regularization\", \"mentions\", \"regularization\"), (\"generalization\", \"mentions\", \"generalization\"), (\"robustness\", \"mentions\", \"robustness\"), (\"hyperparameters\", \"mentions\", \"hyperparameters\"), (\"Whisper models\", \"mentions\", \"Whisper models\"), (\"chunk_42\", \"mentions\", \"dataset\"), (\"chunk_42\", \"mentions\", \"epochs\"), (\"chunk_42\", \"mentions\", \"over-ﬁtting\"), (\"chunk_42\", \"mentions\", \"data augmentation\"), (\"chunk_42\", \"mentions\", \"regularization\"), (\"chunk_42\", \"mentions\", \"generalization\"), (\"chunk_42\", \"mentions\", \"robustness\"), (\"chunk_42\", \"mentions\", \"hyperparameters\"), (\"chunk_42\", \"mentions\", \"Whisper models\"), (\"dataset\", \"related_to_core\", \"Whisper models\"), (\"epochs\", \"related_to_core\", \"Whisper models\"), (\"over-ﬁtting\", \"related_to_core\", \"Whisper models\"), (\"data augmentation\", \"related_to_core\", \"Whisper models\"), (\"regularization\", \"related_to_core\", \"Whisper models\"), (\"generalization\", \"related_to_core\", \"Whisper models\"), (\"robustness\", \"related_to_core\", \"Whisper models\"), (\"hyperparameters\", \"related_to_core\", \"Whisper models\"), (\"Whisper models\", \"is_core_idea\", \"true\"), (\"chunk_42\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('dataset', 'mentions', 'dataset'), ('epochs', 'mentions', 'epochs'), ('over-ﬁtting', 'mentions', 'over-ﬁtting'), ('data augmentation', 'mentions', 'data augmentation'), ('regularization', 'mentions', 'regularization'), ('generalization', 'mentions', 'generalization'), ('robustness', 'mentions', 'robustness'), ('hyperparameters', 'mentions', 'hyperparameters'), ('Whisper models', 'mentions', 'Whisper models'), ('chunk_42', 'mentions', 'dataset'), ('chunk_42', 'mentions', 'epochs'), ('chunk_42', 'mentions', 'over-ﬁtting'), ('chunk_42', 'mentions', 'data augmentation'), ('chunk_42', 'mentions', 'regularization'), ('chunk_42', 'mentions', 'generalization'), ('chunk_42', 'mentions', 'robustness'), ('chunk_42', 'mentions', 'hyperparameters'), ('chunk_42', 'mentions', 'Whisper models'), ('dataset', 'related_to_core', 'Whisper models'), ('epochs', 'related_to_core', 'Whisper models'), ('over-ﬁtting', 'related_to_core', 'Whisper models'), ('data augmentation', 'related_to_core', 'Whisper models'), ('regularization', 'related_to_core', 'Whisper models'), ('generalization', 'related_to_core', 'Whisper models'), ('robustness', 'related_to_core', 'Whisper models'), ('hyperparameters', 'related_to_core', 'Whisper models'), ('Whisper models', 'is_core_idea', 'true'), ('chunk_42', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_43...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"names of speakers\", \"is_core_idea\", \"true\"), (\"chunk_43\", \"is_core_chunk\", \"true\"), (\"chunk_43\", \"mentions\", \"names of speakers\"), (\"transcripts\", \"related_to_core\", \"names of speakers\"), (\"pre-training dataset\", \"related_to_core\", \"names of speakers\"), (\"model\", \"related_to_core\", \"names of speakers\"), (\"Large model\", \"related_to_core\", \"names of speakers\"), (\"V2\", \"related_to_core\", \"names of speakers\"), (\"epochs\", \"related_to_core\", \"names of speakers\"), (\"SpecAugment\", \"related_to_core\", \"names of speakers\"), (\"Park et al.\", \"related_to_core\", \"names of speakers\"), (\"Stochastic Depth\", \"related_to_core\", \"names of speakers\"), (\"Huang et al.\", \"related_to_core\", \"names of speakers\"), (\"chunk_43\", \"mentions\", \"transcripts\"), (\"chunk_43\", \"mentions\", \"pre-training dataset\"), (\"chunk_43\", \"mentions\", \"model\"), (\"chunk_43\", \"mentions\", \"Large model\"), (\"chunk_43\", \"mentions\", \"V2\"), (\"chunk_43\", \"mentions\", \"epochs\"), (\"chunk_43\", \"mentions\", \"SpecAugment\"), (\"chunk_43\", \"mentions\", \"Park et al.\"), (\"chunk_43\", \"mentions\", \"Stochastic Depth\"), (\"chunk_43\", \"mentions\", \"Huang et al.\")]\n",
            "✅ Extracted: [('names of speakers', 'is_core_idea', 'true'), ('chunk_43', 'is_core_chunk', 'true'), ('chunk_43', 'mentions', 'names of speakers'), ('transcripts', 'related_to_core', 'names of speakers'), ('pre-training dataset', 'related_to_core', 'names of speakers'), ('model', 'related_to_core', 'names of speakers'), ('Large model', 'related_to_core', 'names of speakers'), ('V2', 'related_to_core', 'names of speakers'), ('epochs', 'related_to_core', 'names of speakers'), ('SpecAugment', 'related_to_core', 'names of speakers'), ('Park et al.', 'related_to_core', 'names of speakers'), ('Stochastic Depth', 'related_to_core', 'names of speakers'), ('Huang et al.', 'related_to_core', 'names of speakers'), ('chunk_43', 'mentions', 'transcripts'), ('chunk_43', 'mentions', 'pre-training dataset'), ('chunk_43', 'mentions', 'model'), ('chunk_43', 'mentions', 'Large model'), ('chunk_43', 'mentions', 'V2'), ('chunk_43', 'mentions', 'epochs'), ('chunk_43', 'mentions', 'SpecAugment'), ('chunk_43', 'mentions', 'Park et al.'), ('chunk_43', 'mentions', 'Stochastic Depth'), ('chunk_43', 'mentions', 'Huang et al.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_44...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"BPE Dropout\", \"is_a\", \"regularization\"), (\"chunk_44\", \"mentions\", \"BPE Dropout\"), (\"chunk_44\", \"mentions\", \"regularization\")]\n",
            "✅ Extracted: [('BPE Dropout', 'is_a', 'regularization'), ('chunk_44', 'mentions', 'BPE Dropout'), ('chunk_44', 'mentions', 'regularization')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_45...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_45\", \"is_core_chunk\", \"true\"), (\"Model Layers\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Width\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Heads\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Parameters\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Tiny\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Base\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Small\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Medium\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Large\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Whisper model family\", \"related_to_core\", \"Robust Speech Recognition\"), (\"audio context\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Whisper models\", \"related_to_core\", \"Robust Speech Recognition\"), (\"speaker annotations\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Zero-shot Evaluation\", \"related_to_core\", \"Robust Speech Recognition\"), (\"chunk_45\", \"mentions\", \"Robust Speech Recognition\"), (\"chunk_45\", \"mentions\", \"Model Layers\"), (\"chunk_45\", \"mentions\", \"Width\"), (\"chunk_45\", \"mentions\", \"Heads\"), (\"chunk_45\", \"mentions\", \"Parameters\"), (\"chunk_45\", \"mentions\", \"Tiny\"), (\"chunk_45\", \"mentions\", \"Base\"), (\"chunk_45\", \"mentions\", \"Small\"), (\"chunk_45\", \"mentions\", \"Medium\"), (\"chunk_45\", \"mentions\", \"Large\"), (\"chunk_45\", \"mentions\", \"Whisper model family\"), (\"chunk_45\", \"mentions\", \"audio context\"), (\"chunk_45\", \"mentions\", \"Whisper models\"), (\"chunk_45\", \"mentions\", \"speaker annotations\"), (\"chunk_45\", \"mentions\", \"Zero-shot Evaluation\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'is_core_idea', 'true'), ('chunk_45', 'is_core_chunk', 'true'), ('Model Layers', 'related_to_core', 'Robust Speech Recognition'), ('Width', 'related_to_core', 'Robust Speech Recognition'), ('Heads', 'related_to_core', 'Robust Speech Recognition'), ('Parameters', 'related_to_core', 'Robust Speech Recognition'), ('Tiny', 'related_to_core', 'Robust Speech Recognition'), ('Base', 'related_to_core', 'Robust Speech Recognition'), ('Small', 'related_to_core', 'Robust Speech Recognition'), ('Medium', 'related_to_core', 'Robust Speech Recognition'), ('Large', 'related_to_core', 'Robust Speech Recognition'), ('Whisper model family', 'related_to_core', 'Robust Speech Recognition'), ('audio context', 'related_to_core', 'Robust Speech Recognition'), ('Whisper models', 'related_to_core', 'Robust Speech Recognition'), ('speaker annotations', 'related_to_core', 'Robust Speech Recognition'), ('Zero-shot Evaluation', 'related_to_core', 'Robust Speech Recognition'), ('chunk_45', 'mentions', 'Robust Speech Recognition'), ('chunk_45', 'mentions', 'Model Layers'), ('chunk_45', 'mentions', 'Width'), ('chunk_45', 'mentions', 'Heads'), ('chunk_45', 'mentions', 'Parameters'), ('chunk_45', 'mentions', 'Tiny'), ('chunk_45', 'mentions', 'Base'), ('chunk_45', 'mentions', 'Small'), ('chunk_45', 'mentions', 'Medium'), ('chunk_45', 'mentions', 'Large'), ('chunk_45', 'mentions', 'Whisper model family'), ('chunk_45', 'mentions', 'audio context'), ('chunk_45', 'mentions', 'Whisper models'), ('chunk_45', 'mentions', 'speaker annotations'), ('chunk_45', 'mentions', 'Zero-shot Evaluation')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_46...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_46\", \"is_core_chunk\", \"true\"), (\"Experiments\", \"related_to_core\", \"Whisper\"), (\"Zero-shot Evaluation\", \"related_to_core\", \"Whisper\"), (\"speech processing system\", \"related_to_core\", \"Whisper\"), (\"dataset\", \"related_to_core\", \"Whisper\"), (\"ﬁne-tuning\", \"related_to_core\", \"Whisper\"), (\"distributions\", \"related_to_core\", \"Whisper\"), (\"speech processing datasets\", \"related_to_core\", \"Whisper\"), (\"domains\", \"related_to_core\", \"Whisper\"), (\"tasks\", \"related_to_core\", \"Whisper\"), (\"languages\", \"related_to_core\", \"Whisper\"), (\"Experiments\", \"mentions\", \"Experiments\"), (\"Zero-shot Evaluation\", \"mentions\", \"Zero-shot Evaluation\"), (\"Whisper\", \"mentions\", \"Whisper\"), (\"speech processing system\", \"mentions\", \"speech processing system\"), (\"dataset\", \"mentions\", \"dataset\"), (\"ﬁne-tuning\", \"mentions\", \"ﬁne-tuning\"), (\"distributions\", \"mentions\", \"distributions\"), (\"speech processing datasets\", \"mentions\", \"speech processing datasets\"), (\"domains\", \"mentions\", \"domains\"), (\"tasks\", \"mentions\", \"tasks\"), (\"languages\", \"mentions\", \"languages\"), (\"chunk_46\", \"mentions\", \"Experiments\"), (\"chunk_46\", \"mentions\", \"Zero-shot Evaluation\"), (\"chunk_46\", \"mentions\", \"Whisper\"), (\"chunk_46\", \"mentions\", \"speech processing system\"), (\"chunk_46\", \"mentions\", \"dataset\"), (\"chunk_46\", \"mentions\", \"ﬁne-tuning\"), (\"chunk_46\", \"mentions\", \"distributions\"), (\"chunk_46\", \"mentions\", \"speech processing datasets\"), (\"chunk_46\", \"mentions\", \"domains\"), (\"chunk_46\", \"mentions\", \"tasks\"), (\"chunk_46\", \"mentions\", \"languages\")]\n",
            "✅ Extracted: [('Whisper', 'is_core_idea', 'true'), ('chunk_46', 'is_core_chunk', 'true'), ('Experiments', 'related_to_core', 'Whisper'), ('Zero-shot Evaluation', 'related_to_core', 'Whisper'), ('speech processing system', 'related_to_core', 'Whisper'), ('dataset', 'related_to_core', 'Whisper'), ('ﬁne-tuning', 'related_to_core', 'Whisper'), ('distributions', 'related_to_core', 'Whisper'), ('speech processing datasets', 'related_to_core', 'Whisper'), ('domains', 'related_to_core', 'Whisper'), ('tasks', 'related_to_core', 'Whisper'), ('languages', 'related_to_core', 'Whisper'), ('Experiments', 'mentions', 'Experiments'), ('Zero-shot Evaluation', 'mentions', 'Zero-shot Evaluation'), ('Whisper', 'mentions', 'Whisper'), ('speech processing system', 'mentions', 'speech processing system'), ('dataset', 'mentions', 'dataset'), ('ﬁne-tuning', 'mentions', 'ﬁne-tuning'), ('distributions', 'mentions', 'distributions'), ('speech processing datasets', 'mentions', 'speech processing datasets'), ('domains', 'mentions', 'domains'), ('tasks', 'mentions', 'tasks'), ('languages', 'mentions', 'languages'), ('chunk_46', 'mentions', 'Experiments'), ('chunk_46', 'mentions', 'Zero-shot Evaluation'), ('chunk_46', 'mentions', 'Whisper'), ('chunk_46', 'mentions', 'speech processing system'), ('chunk_46', 'mentions', 'dataset'), ('chunk_46', 'mentions', 'ﬁne-tuning'), ('chunk_46', 'mentions', 'distributions'), ('chunk_46', 'mentions', 'speech processing datasets'), ('chunk_46', 'mentions', 'domains'), ('chunk_46', 'mentions', 'tasks'), ('chunk_46', 'mentions', 'languages')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_47...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"evaluation protocol\", \"mentions\", \"datasets\"), (\"chunk_47\", \"mentions\", \"evaluation protocol\"), (\"train and test split\", \"mentions\", \"train\"), (\"chunk_47\", \"mentions\", \"train and test split\"), (\"train and test split\", \"mentions\", \"test\"), (\"Whisper\", \"mentions\", \"datasets\"), (\"chunk_47\", \"mentions\", \"Whisper\"), (\"training data\", \"mentions\", \"datasets\"), (\"chunk_47\", \"mentions\", \"training data\"), (\"Speech recognition research\", \"mentions\", \"word error rate\"), (\"chunk_47\", \"mentions\", \"Speech recognition research\"), (\"word error rate\", \"mentions\", \"string edit distance\"), (\"chunk_47\", \"mentions\", \"word error rate\"), (\"word error rate\", \"is_core_idea\", \"true\"), (\"chunk_47\", \"is_core_chunk\", \"true\"), (\"datasets\", \"related_to_core\", \"word error rate\"), (\"train and test split\", \"related_to_core\", \"word error rate\"), (\"Whisper\", \"related_to_core\", \"word error rate\"), (\"training data\", \"related_to_core\", \"word error rate\"), (\"string edit distance\", \"related_to_core\", \"word error rate\"), (\"Speech recognition research\", \"related_to_core\", \"word error rate\")]\n",
            "✅ Extracted: [('evaluation protocol', 'mentions', 'datasets'), ('chunk_47', 'mentions', 'evaluation protocol'), ('train and test split', 'mentions', 'train'), ('chunk_47', 'mentions', 'train and test split'), ('train and test split', 'mentions', 'test'), ('Whisper', 'mentions', 'datasets'), ('chunk_47', 'mentions', 'Whisper'), ('training data', 'mentions', 'datasets'), ('chunk_47', 'mentions', 'training data'), ('Speech recognition research', 'mentions', 'word error rate'), ('chunk_47', 'mentions', 'Speech recognition research'), ('word error rate', 'mentions', 'string edit distance'), ('chunk_47', 'mentions', 'word error rate'), ('word error rate', 'is_core_idea', 'true'), ('chunk_47', 'is_core_chunk', 'true'), ('datasets', 'related_to_core', 'word error rate'), ('train and test split', 'related_to_core', 'word error rate'), ('Whisper', 'related_to_core', 'word error rate'), ('training data', 'related_to_core', 'word error rate'), ('string edit distance', 'related_to_core', 'word error rate'), ('Speech recognition research', 'related_to_core', 'word error rate')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_48...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"reference transcript\", \"mentions\", \"reference transcript\"), (\"transcript style\", \"mentions\", \"transcript style\"), (\"systems\", \"mentions\", \"systems\"), (\"transcripts\", \"mentions\", \"transcripts\"), (\"humans\", \"mentions\", \"humans\"), (\"WER\", \"mentions\", \"WER\"), (\"formatting differences\", \"mentions\", \"formatting differences\"), (\"transcribers\", \"mentions\", \"transcribers\"), (\"zero-shot models\", \"mentions\", \"zero-shot models\"), (\"Whisper\", \"mentions\", \"Whisper\"), (\"datasets\", \"mentions\", \"datasets\"), (\"transcript formats\", \"mentions\", \"transcript formats\"), (\"development\", \"mentions\", \"development\"), (\"reference transcript\", \"including\", \"transcript style\"), (\"systems\", \"output\", \"transcripts\"), (\"transcripts\", \"judged as correct by\", \"humans\"), (\"WER\", \"due to\", \"formatting differences\"), (\"zero-shot models\", \"like\", \"Whisper\"), (\"Whisper\", \"do not observe\", \"datasets\"), (\"datasets\", \"of\", \"transcript formats\"), (\"chunk_48\", \"mentions\", \"reference transcript\"), (\"chunk_48\", \"mentions\", \"transcript style\"), (\"chunk_48\", \"mentions\", \"systems\"), (\"chunk_48\", \"mentions\", \"transcripts\"), (\"chunk_48\", \"mentions\", \"humans\"), (\"chunk_48\", \"mentions\", \"WER\"), (\"chunk_48\", \"mentions\", \"formatting differences\"), (\"chunk_48\", \"mentions\", \"transcribers\"), (\"chunk_48\", \"mentions\", \"zero-shot models\"), (\"chunk_48\", \"mentions\", \"Whisper\"), (\"chunk_48\", \"mentions\", \"datasets\"), (\"chunk_48\", \"mentions\", \"transcript formats\"), (\"chunk_48\", \"mentions\", \"development\"), (\"WER\", \"is_core_idea\", \"true\"), (\"chunk_48\", \"is_core_chunk\", \"true\"), (\"reference transcript\", \"related_to_core\", \"WER\"), (\"transcript style\", \"related_to_core\", \"WER\"), (\"systems\", \"related_to_core\", \"WER\"), (\"transcripts\", \"related_to_core\", \"WER\"), (\"humans\", \"related_to_core\", \"WER\"), (\"formatting differences\", \"related_to_core\", \"WER\"), (\"transcribers\", \"related_to_core\", \"WER\"), (\"zero-shot models\", \"related_to_core\", \"WER\"), (\"Whisper\", \"related_to_core\", \"WER\"), (\"datasets\", \"related_to_core\", \"WER\"), (\"transcript formats\", \"related_to_core\", \"WER\"), (\"development\", \"related_to_core\", \"WER\")]\n",
            "✅ Extracted: [('reference transcript', 'mentions', 'reference transcript'), ('transcript style', 'mentions', 'transcript style'), ('systems', 'mentions', 'systems'), ('transcripts', 'mentions', 'transcripts'), ('humans', 'mentions', 'humans'), ('WER', 'mentions', 'WER'), ('formatting differences', 'mentions', 'formatting differences'), ('transcribers', 'mentions', 'transcribers'), ('zero-shot models', 'mentions', 'zero-shot models'), ('Whisper', 'mentions', 'Whisper'), ('datasets', 'mentions', 'datasets'), ('transcript formats', 'mentions', 'transcript formats'), ('development', 'mentions', 'development'), ('reference transcript', 'including', 'transcript style'), ('systems', 'output', 'transcripts'), ('transcripts', 'judged as correct by', 'humans'), ('WER', 'due to', 'formatting differences'), ('zero-shot models', 'like', 'Whisper'), ('Whisper', 'do not observe', 'datasets'), ('datasets', 'of', 'transcript formats'), ('chunk_48', 'mentions', 'reference transcript'), ('chunk_48', 'mentions', 'transcript style'), ('chunk_48', 'mentions', 'systems'), ('chunk_48', 'mentions', 'transcripts'), ('chunk_48', 'mentions', 'humans'), ('chunk_48', 'mentions', 'WER'), ('chunk_48', 'mentions', 'formatting differences'), ('chunk_48', 'mentions', 'transcribers'), ('chunk_48', 'mentions', 'zero-shot models'), ('chunk_48', 'mentions', 'Whisper'), ('chunk_48', 'mentions', 'datasets'), ('chunk_48', 'mentions', 'transcript formats'), ('chunk_48', 'mentions', 'development'), ('WER', 'is_core_idea', 'true'), ('chunk_48', 'is_core_chunk', 'true'), ('reference transcript', 'related_to_core', 'WER'), ('transcript style', 'related_to_core', 'WER'), ('systems', 'related_to_core', 'WER'), ('transcripts', 'related_to_core', 'WER'), ('humans', 'related_to_core', 'WER'), ('formatting differences', 'related_to_core', 'WER'), ('transcribers', 'related_to_core', 'WER'), ('zero-shot models', 'related_to_core', 'WER'), ('Whisper', 'related_to_core', 'WER'), ('datasets', 'related_to_core', 'WER'), ('transcript formats', 'related_to_core', 'WER'), ('development', 'related_to_core', 'WER')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_49...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"human judgement\", \"is_core_idea\", \"true\"), (\"chunk_49\", \"is_core_chunk\", \"true\"), (\"chunk_49\", \"mentions\", \"human judgement\"), (\"speech recognition\", \"related_to_core\", \"human judgement\"), (\"WER calculation\", \"related_to_core\", \"human judgement\"), (\"text\", \"related_to_core\", \"human judgement\"), (\"text normalizer\", \"related_to_core\", \"human judgement\"), (\"WER\", \"related_to_core\", \"human judgement\"), (\"speech recognition\", \"is_a\", \"method\"), (\"WER\", \"is_a\", \"naive WER\"), (\"chunk_49\", \"mentions\", \"speech recognition\"), (\"chunk_49\", \"mentions\", \"WER calculation\"), (\"chunk_49\", \"mentions\", \"text\"), (\"chunk_49\", \"mentions\", \"text normalizer\"), (\"chunk_49\", \"mentions\", \"WER\")]\n",
            "✅ Extracted: [('human judgement', 'is_core_idea', 'true'), ('chunk_49', 'is_core_chunk', 'true'), ('chunk_49', 'mentions', 'human judgement'), ('speech recognition', 'related_to_core', 'human judgement'), ('WER calculation', 'related_to_core', 'human judgement'), ('text', 'related_to_core', 'human judgement'), ('text normalizer', 'related_to_core', 'human judgement'), ('WER', 'related_to_core', 'human judgement'), ('speech recognition', 'is_a', 'method'), ('WER', 'is_a', 'naive WER'), ('chunk_49', 'mentions', 'speech recognition'), ('chunk_49', 'mentions', 'WER calculation'), ('chunk_49', 'mentions', 'text'), ('chunk_49', 'mentions', 'text normalizer'), ('chunk_49', 'mentions', 'WER')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_50...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"penalized Whisper models\", \"mentions\", \"penalized Whisper models\"), (\"chunk_50\", \"mentions\", \"penalized Whisper models\"), (\"datasets\", \"mentions\", \"datasets\"), (\"chunk_50\", \"mentions\", \"datasets\"), (\"WER\", \"mentions\", \"WER\"), (\"chunk_50\", \"mentions\", \"WER\"), (\"reference transcripts\", \"mentions\", \"reference transcripts\"), (\"chunk_50\", \"mentions\", \"reference transcripts\"), (\"whitespace\", \"mentions\", \"whitespace\"), (\"chunk_50\", \"mentions\", \"whitespace\"), (\"transcription style\", \"mentions\", \"transcription style\"), (\"chunk_50\", \"mentions\", \"transcription style\"), (\"Whisper models\", \"mentions\", \"Whisper models\"), (\"chunk_50\", \"mentions\", \"Whisper models\"), (\"text nor-\", \"mentions\", \"text nor-\"), (\"chunk_50\", \"mentions\", \"text nor-\"), (\"WER\", \"drops_of\", \"50 percent\"), (\"reference transcripts\", \"seperating\", \"contractions\"), (\"reference transcripts\", \"seperating\", \"words\"), (\"penalized Whisper models\", \"is_core_idea\", \"true\"), (\"chunk_50\", \"is_core_chunk\", \"true\"), (\"datasets\", \"related_to_core\", \"penalized Whisper models\"), (\"WER\", \"related_to_core\", \"penalized Whisper models\"), (\"reference transcripts\", \"related_to_core\", \"penalized Whisper models\"), (\"whitespace\", \"related_to_core\", \"penalized Whisper models\"), (\"transcription style\", \"related_to_core\", \"penalized Whisper models\"), (\"Whisper models\", \"related_to_core\", \"penalized Whisper models\"), (\"text nor-\", \"related_to_core\", \"penalized Whisper models\")]\n",
            "✅ Extracted: [('penalized Whisper models', 'mentions', 'penalized Whisper models'), ('chunk_50', 'mentions', 'penalized Whisper models'), ('datasets', 'mentions', 'datasets'), ('chunk_50', 'mentions', 'datasets'), ('WER', 'mentions', 'WER'), ('chunk_50', 'mentions', 'WER'), ('reference transcripts', 'mentions', 'reference transcripts'), ('chunk_50', 'mentions', 'reference transcripts'), ('whitespace', 'mentions', 'whitespace'), ('chunk_50', 'mentions', 'whitespace'), ('transcription style', 'mentions', 'transcription style'), ('chunk_50', 'mentions', 'transcription style'), ('Whisper models', 'mentions', 'Whisper models'), ('chunk_50', 'mentions', 'Whisper models'), ('text nor-', 'mentions', 'text nor-'), ('chunk_50', 'mentions', 'text nor-'), ('WER', 'drops_of', '50 percent'), ('reference transcripts', 'seperating', 'contractions'), ('reference transcripts', 'seperating', 'words'), ('penalized Whisper models', 'is_core_idea', 'true'), ('chunk_50', 'is_core_chunk', 'true'), ('datasets', 'related_to_core', 'penalized Whisper models'), ('WER', 'related_to_core', 'penalized Whisper models'), ('reference transcripts', 'related_to_core', 'penalized Whisper models'), ('whitespace', 'related_to_core', 'penalized Whisper models'), ('transcription style', 'related_to_core', 'penalized Whisper models'), ('Whisper models', 'related_to_core', 'penalized Whisper models'), ('text nor-', 'related_to_core', 'penalized Whisper models')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_51...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"speech recognition systems\", \"related_to_core\", \"English Speech Recognition\"), (\"English Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_51\", \"is_core_chunk\", \"true\"), (\"LibriSpeech\", \"related_to_core\", \"English Speech Recognition\"), (\"Deep Speech 2\", \"related_to_core\", \"English Speech Recognition\"), (\"speech recognition system\", \"related_to_core\", \"English Speech Recognition\"), (\"speech recognition systems\", \"mentions\", \"speech recognition systems\"), (\"English Speech Recognition\", \"mentions\", \"English Speech Recognition\"), (\"Deep Speech 2\", \"mentions\", \"Deep Speech 2\"), (\"speech recognition system\", \"mentions\", \"speech recognition system\"), (\"LibriSpeech\", \"mentions\", \"LibriSpeech\"), (\"speech recognition system\", \"predicate\", \"matched\"), (\"speech recognition system\", \"object\", \"human-level performance\"), (\"chunk_51\", \"mentions\", \"speech recognition systems\"), (\"chunk_51\", \"mentions\", \"English Speech Recognition\"), (\"chunk_51\", \"mentions\", \"Deep Speech 2\"), (\"chunk_51\", \"mentions\", \"speech recognition system\"), (\"chunk_51\", \"mentions\", \"LibriSpeech\")]\n",
            "✅ Extracted: [('speech recognition systems', 'related_to_core', 'English Speech Recognition'), ('English Speech Recognition', 'is_core_idea', 'true'), ('chunk_51', 'is_core_chunk', 'true'), ('LibriSpeech', 'related_to_core', 'English Speech Recognition'), ('Deep Speech 2', 'related_to_core', 'English Speech Recognition'), ('speech recognition system', 'related_to_core', 'English Speech Recognition'), ('speech recognition systems', 'mentions', 'speech recognition systems'), ('English Speech Recognition', 'mentions', 'English Speech Recognition'), ('Deep Speech 2', 'mentions', 'Deep Speech 2'), ('speech recognition system', 'mentions', 'speech recognition system'), ('LibriSpeech', 'mentions', 'LibriSpeech'), ('speech recognition system', 'predicate', 'matched'), ('speech recognition system', 'object', 'human-level performance'), ('chunk_51', 'mentions', 'speech recognition systems'), ('chunk_51', 'mentions', 'English Speech Recognition'), ('chunk_51', 'mentions', 'Deep Speech 2'), ('chunk_51', 'mentions', 'speech recognition system'), ('chunk_51', 'mentions', 'LibriSpeech')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_52...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"clean read speech\", \"related_to_core\", \"speech recognition models\"), (\"LibriSpeech\", \"related_to_core\", \"speech recognition models\"), (\"WER\", \"related_to_core\", \"speech recognition models\"), (\"speech recognition models\", \"is_core_idea\", \"true\"), (\"chunk_52\", \"is_core_chunk\", \"true\"), (\"clean read speech\", \"mentions\", \"speech\"), (\"domain adaptation\", \"mentions\", \"domain\"), (\"WER\", \"mentions\", \"WER\"), (\"LibriSpeech\", \"mentions\", \"LibriSpeech\"), (\"speech recognition models\", \"mentions\", \"speech recognition models\"), (\"human-level error rate\", \"mentions\", \"human-level error rate\"), (\"human error\", \"mentions\", \"human error\"), (\"speech recognition models\", \"trained on\", \"LibriSpeech\"), (\"chunk_52\", \"mentions\", \"clean read speech\"), (\"chunk_52\", \"mentions\", \"domain adaptation\"), (\"chunk_52\", \"mentions\", \"WER\"), (\"chunk_52\", \"mentions\", \"LibriSpeech\"), (\"chunk_52\", \"mentions\", \"speech recognition models\"), (\"chunk_52\", \"mentions\", \"human-level error rate\"), (\"chunk_52\", \"mentions\", \"human error\"), (\"human-level error rate\", \"related_to_core\", \"speech recognition models\"), (\"human error\", \"related_to_core\", \"speech recognition models\")]\n",
            "✅ Extracted: [('clean read speech', 'related_to_core', 'speech recognition models'), ('LibriSpeech', 'related_to_core', 'speech recognition models'), ('WER', 'related_to_core', 'speech recognition models'), ('speech recognition models', 'is_core_idea', 'true'), ('chunk_52', 'is_core_chunk', 'true'), ('clean read speech', 'mentions', 'speech'), ('domain adaptation', 'mentions', 'domain'), ('WER', 'mentions', 'WER'), ('LibriSpeech', 'mentions', 'LibriSpeech'), ('speech recognition models', 'mentions', 'speech recognition models'), ('human-level error rate', 'mentions', 'human-level error rate'), ('human error', 'mentions', 'human error'), ('speech recognition models', 'trained on', 'LibriSpeech'), ('chunk_52', 'mentions', 'clean read speech'), ('chunk_52', 'mentions', 'domain adaptation'), ('chunk_52', 'mentions', 'WER'), ('chunk_52', 'mentions', 'LibriSpeech'), ('chunk_52', 'mentions', 'speech recognition models'), ('chunk_52', 'mentions', 'human-level error rate'), ('chunk_52', 'mentions', 'human error'), ('human-level error rate', 'related_to_core', 'speech recognition models'), ('human error', 'related_to_core', 'speech recognition models')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_53...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"rates\", \"mentions\", \"rates\"), (\"settings\", \"mentions\", \"settings\"), (\"performance\", \"mentions\", \"performance\"), (\"distribution\", \"mentions\", \"distribution\"), (\"machine behavior\", \"mentions\", \"machine behavior\"), (\"capabilities\", \"mentions\", \"capabilities\"), (\"human performance\", \"mentions\", \"human performance\"), (\"machine performance\", \"mentions\", \"machine performance\"), (\"test set\", \"mentions\", \"test set\"), (\"humans\", \"mentions\", \"humans\"), (\"machines\", \"mentions\", \"machines\"), (\"test\", \"mentions\", \"test\"), (\"chunk_53\", \"mentions\", \"rates\"), (\"chunk_53\", \"mentions\", \"settings\"), (\"chunk_53\", \"mentions\", \"performance\"), (\"chunk_53\", \"mentions\", \"distribution\"), (\"chunk_53\", \"mentions\", \"machine behavior\"), (\"chunk_53\", \"mentions\", \"capabilities\"), (\"chunk_53\", \"mentions\", \"human performance\"), (\"chunk_53\", \"mentions\", \"machine performance\"), (\"chunk_53\", \"mentions\", \"test set\"), (\"chunk_53\", \"mentions\", \"humans\"), (\"chunk_53\", \"mentions\", \"machines\"), (\"chunk_53\", \"mentions\", \"test\"), (\"performance\", \"is_core_idea\", \"true\"), (\"chunk_53\", \"is_core_chunk\", \"true\"), (\"rates\", \"related_to_core\", \"performance\"), (\"settings\", \"related_to_core\", \"performance\"), (\"distribution\", \"related_to_core\", \"performance\"), (\"machine behavior\", \"related_to_core\", \"performance\"), (\"capabilities\", \"related_to_core\", \"performance\"), (\"human performance\", \"related_to_core\", \"performance\"), (\"machine performance\", \"related_to_core\", \"performance\"), (\"test set\", \"related_to_core\", \"performance\"), (\"humans\", \"related_to_core\", \"performance\"), (\"machines\", \"related_to_core\", \"performance\"), (\"test\", \"related_to_core\", \"performance\")]\n",
            "✅ Extracted: [('rates', 'mentions', 'rates'), ('settings', 'mentions', 'settings'), ('performance', 'mentions', 'performance'), ('distribution', 'mentions', 'distribution'), ('machine behavior', 'mentions', 'machine behavior'), ('capabilities', 'mentions', 'capabilities'), ('human performance', 'mentions', 'human performance'), ('machine performance', 'mentions', 'machine performance'), ('test set', 'mentions', 'test set'), ('humans', 'mentions', 'humans'), ('machines', 'mentions', 'machines'), ('test', 'mentions', 'test'), ('chunk_53', 'mentions', 'rates'), ('chunk_53', 'mentions', 'settings'), ('chunk_53', 'mentions', 'performance'), ('chunk_53', 'mentions', 'distribution'), ('chunk_53', 'mentions', 'machine behavior'), ('chunk_53', 'mentions', 'capabilities'), ('chunk_53', 'mentions', 'human performance'), ('chunk_53', 'mentions', 'machine performance'), ('chunk_53', 'mentions', 'test set'), ('chunk_53', 'mentions', 'humans'), ('chunk_53', 'mentions', 'machines'), ('chunk_53', 'mentions', 'test'), ('performance', 'is_core_idea', 'true'), ('chunk_53', 'is_core_chunk', 'true'), ('rates', 'related_to_core', 'performance'), ('settings', 'related_to_core', 'performance'), ('distribution', 'related_to_core', 'performance'), ('machine behavior', 'related_to_core', 'performance'), ('capabilities', 'related_to_core', 'performance'), ('human performance', 'related_to_core', 'performance'), ('machine performance', 'related_to_core', 'performance'), ('test set', 'related_to_core', 'performance'), ('humans', 'related_to_core', 'performance'), ('machines', 'related_to_core', 'performance'), ('test', 'related_to_core', 'performance')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_54...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"skills\", \"is_core_idea\", \"true\"), (\"chunk_54\", \"is_core_chunk\", \"true\"), (\"skills\", \"related_to_core\", \"skills\"), (\"testing\", \"related_to_core\", \"skills\"), (\"Humans\", \"related_to_core\", \"skills\"), (\"task\", \"related_to_core\", \"skills\"), (\"data distribution\", \"related_to_core\", \"skills\"), (\"human performance\", \"related_to_core\", \"skills\"), (\"out-of-distribution generalization\", \"related_to_core\", \"skills\"), (\"machine learning models\", \"related_to_core\", \"skills\"), (\"supervision\", \"related_to_core\", \"skills\"), (\"evaluation distribution\", \"related_to_core\", \"skills\"), (\"machine performance\", \"related_to_core\", \"skills\"), (\"chunk_54\", \"mentions\", \"skills\"), (\"chunk_54\", \"mentions\", \"testing\"), (\"chunk_54\", \"mentions\", \"Humans\"), (\"chunk_54\", \"mentions\", \"task\"), (\"chunk_54\", \"mentions\", \"data distribution\"), (\"chunk_54\", \"mentions\", \"human performance\"), (\"chunk_54\", \"mentions\", \"out-of-distribution generalization\"), (\"chunk_54\", \"mentions\", \"machine learning models\"), (\"chunk_54\", \"mentions\", \"supervision\"), (\"chunk_54\", \"mentions\", \"evaluation distribution\"), (\"chunk_54\", \"mentions\", \"machine performance\")]\n",
            "✅ Extracted: [('skills', 'is_core_idea', 'true'), ('chunk_54', 'is_core_chunk', 'true'), ('skills', 'related_to_core', 'skills'), ('testing', 'related_to_core', 'skills'), ('Humans', 'related_to_core', 'skills'), ('task', 'related_to_core', 'skills'), ('data distribution', 'related_to_core', 'skills'), ('human performance', 'related_to_core', 'skills'), ('out-of-distribution generalization', 'related_to_core', 'skills'), ('machine learning models', 'related_to_core', 'skills'), ('supervision', 'related_to_core', 'skills'), ('evaluation distribution', 'related_to_core', 'skills'), ('machine performance', 'related_to_core', 'skills'), ('chunk_54', 'mentions', 'skills'), ('chunk_54', 'mentions', 'testing'), ('chunk_54', 'mentions', 'Humans'), ('chunk_54', 'mentions', 'task'), ('chunk_54', 'mentions', 'data distribution'), ('chunk_54', 'mentions', 'human performance'), ('chunk_54', 'mentions', 'out-of-distribution generalization'), ('chunk_54', 'mentions', 'machine learning models'), ('chunk_54', 'mentions', 'supervision'), ('chunk_54', 'mentions', 'evaluation distribution'), ('chunk_54', 'mentions', 'machine performance')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_55...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"in-distribution generalization\", \"is_a\", \"measure\"), (\"chunk_55\", \"mentions\", \"in-distribution generalization\"), (\"humans\", \"evaluated_on\", \"test data\"), (\"machines\", \"evaluated_on\", \"test data\"), (\"test data\", \"used_for\", \"evaluation\"), (\"chunk_55\", \"mentions\", \"humans\"), (\"chunk_55\", \"mentions\", \"machines\"), (\"chunk_55\", \"mentions\", \"test data\"), (\"train data\", \"affects\", \"abilities\"), (\"chunk_55\", \"mentions\", \"train data\"), (\"Whisper models\", \"trained_on\", \"distribution of audio\"), (\"Whisper models\", \"evaluated_in\", \"zero-shot setting\"), (\"chunk_55\", \"mentions\", \"Whisper models\"), (\"distribution of audio\", \"is\", \"broad and diverse\"), (\"chunk_55\", \"mentions\", \"distribution of audio\"), (\"zero-shot setting\", \"is_a\", \"setting\"), (\"chunk_55\", \"mentions\", \"zero-shot setting\"), (\"human behavior\", \"matched_by\", \"Whisper models\"), (\"chunk_55\", \"mentions\", \"human behavior\"), (\"existing systems\", \"compared_to\", \"Whisper models\"), (\"chunk_55\", \"mentions\", \"existing systems\"), (\"in-distribution generalization\", \"is_core_idea\", \"true\"), (\"chunk_55\", \"is_core_chunk\", \"true\"), (\"humans\", \"related_to_core\", \"in-distribution generalization\"), (\"machines\", \"related_to_core\", \"in-distribution generalization\"), (\"test data\", \"related_to_core\", \"in-distribution generalization\"), (\"train data\", \"related_to_core\", \"in-distribution generalization\"), (\"Whisper models\", \"related_to_core\", \"in-distribution generalization\"), (\"distribution of audio\", \"related_to_core\", \"in-distribution generalization\"), (\"zero-shot setting\", \"related_to_core\", \"in-distribution generalization\"), (\"human behavior\", \"related_to_core\", \"in-distribution generalization\"), (\"existing systems\", \"related_to_core\", \"in-distribution generalization\")]\n",
            "✅ Extracted: [('in-distribution generalization', 'is_a', 'measure'), ('chunk_55', 'mentions', 'in-distribution generalization'), ('humans', 'evaluated_on', 'test data'), ('machines', 'evaluated_on', 'test data'), ('test data', 'used_for', 'evaluation'), ('chunk_55', 'mentions', 'humans'), ('chunk_55', 'mentions', 'machines'), ('chunk_55', 'mentions', 'test data'), ('train data', 'affects', 'abilities'), ('chunk_55', 'mentions', 'train data'), ('Whisper models', 'trained_on', 'distribution of audio'), ('Whisper models', 'evaluated_in', 'zero-shot setting'), ('chunk_55', 'mentions', 'Whisper models'), ('distribution of audio', 'is', 'broad and diverse'), ('chunk_55', 'mentions', 'distribution of audio'), ('zero-shot setting', 'is_a', 'setting'), ('chunk_55', 'mentions', 'zero-shot setting'), ('human behavior', 'matched_by', 'Whisper models'), ('chunk_55', 'mentions', 'human behavior'), ('existing systems', 'compared_to', 'Whisper models'), ('chunk_55', 'mentions', 'existing systems'), ('in-distribution generalization', 'is_core_idea', 'true'), ('chunk_55', 'is_core_chunk', 'true'), ('humans', 'related_to_core', 'in-distribution generalization'), ('machines', 'related_to_core', 'in-distribution generalization'), ('test data', 'related_to_core', 'in-distribution generalization'), ('train data', 'related_to_core', 'in-distribution generalization'), ('Whisper models', 'related_to_core', 'in-distribution generalization'), ('distribution of audio', 'related_to_core', 'in-distribution generalization'), ('zero-shot setting', 'related_to_core', 'in-distribution generalization'), ('human behavior', 'related_to_core', 'in-distribution generalization'), ('existing systems', 'related_to_core', 'in-distribution generalization')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_56...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Whisper models\", \"mentions\", \"human performance\"), (\"Whisper models\", \"mentions\", \"machine learning models\"), (\"Whisper models\", \"mentions\", \"standard ﬁne-tuned\"), (\"human performance\", \"related_to_core\", \"Whisper models\"), (\"machine learning models\", \"related_to_core\", \"Whisper models\"), (\"standard ﬁne-tuned\", \"related_to_core\", \"Whisper models\"), (\"Whisper models\", \"is_core_idea\", \"true\"), (\"chunk_56\", \"is_core_chunk\", \"true\"), (\"chunk_56\", \"mentions\", \"Whisper models\"), (\"chunk_56\", \"mentions\", \"human performance\"), (\"chunk_56\", \"mentions\", \"standard ﬁne-tuned\"), (\"chunk_56\", \"mentions\", \"machine learning models\"), (\"Whisper models\", \"compare_with\", \"human performance\"), (\"Whisper models\", \"compare_with\", \"machine learning models\")]\n",
            "✅ Extracted: [('Whisper models', 'mentions', 'human performance'), ('Whisper models', 'mentions', 'machine learning models'), ('Whisper models', 'mentions', 'standard ﬁne-tuned'), ('human performance', 'related_to_core', 'Whisper models'), ('machine learning models', 'related_to_core', 'Whisper models'), ('standard ﬁne-tuned', 'related_to_core', 'Whisper models'), ('Whisper models', 'is_core_idea', 'true'), ('chunk_56', 'is_core_chunk', 'true'), ('chunk_56', 'mentions', 'Whisper models'), ('chunk_56', 'mentions', 'human performance'), ('chunk_56', 'mentions', 'standard ﬁne-tuned'), ('chunk_56', 'mentions', 'machine learning models'), ('Whisper models', 'compare_with', 'human performance'), ('Whisper models', 'compare_with', 'machine learning models')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_57...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_57\", \"is_core_chunk\", \"true\"), (\"Speech Recognition\", \"related_to_core\", \"Large-Scale Weak Supervision\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"Speech Recognition\"), (\"WER\", \"related_to_core\", \"Speech Recognition\"), (\"LibriSpeech dev-clean\", \"related_to_core\", \"Speech Recognition\"), (\"Common Voice\", \"related_to_core\", \"Speech Recognition\"), (\"CHiME-6\", \"related_to_core\", \"Speech Recognition\"), (\"TED-LIUM\", \"related_to_core\", \"Speech Recognition\"), (\"Supervised LibriSpeech models\", \"related_to_core\", \"Speech Recognition\"), (\"Zero-shot Whisper models\", \"related_to_core\", \"Speech Recognition\"), (\"Human\", \"related_to_core\", \"Speech Recognition\"), (\"LibriSpeech\", \"related_to_core\", \"Speech Recognition\"), (\"Speech Recognition\", \"related_to_core\", \"robustness\"), (\"robustness\", \"related_to_core\", \"Speech Recognition\"), (\"chunk_57\", \"mentions\", \"Speech Recognition\"), (\"chunk_57\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_57\", \"mentions\", \"WER\"), (\"chunk_57\", \"mentions\", \"LibriSpeech dev-clean\"), (\"chunk_57\", \"mentions\", \"Common Voice\"), (\"chunk_57\", \"mentions\", \"CHiME-6\"), (\"chunk_57\", \"mentions\", \"TED-LIUM\"), (\"chunk_57\", \"mentions\", \"Supervised LibriSpeech models\"), (\"chunk_57\", \"mentions\", \"Zero-shot Whisper models\"), (\"chunk_57\", \"mentions\", \"Human\"), (\"chunk_57\", \"mentions\", \"LibriSpeech\"), (\"chunk_57\", \"mentions\", \"robustness\")]\n",
            "✅ Extracted: [('Speech Recognition', 'is_core_idea', 'true'), ('chunk_57', 'is_core_chunk', 'true'), ('Speech Recognition', 'related_to_core', 'Large-Scale Weak Supervision'), ('Large-Scale Weak Supervision', 'related_to_core', 'Speech Recognition'), ('WER', 'related_to_core', 'Speech Recognition'), ('LibriSpeech dev-clean', 'related_to_core', 'Speech Recognition'), ('Common Voice', 'related_to_core', 'Speech Recognition'), ('CHiME-6', 'related_to_core', 'Speech Recognition'), ('TED-LIUM', 'related_to_core', 'Speech Recognition'), ('Supervised LibriSpeech models', 'related_to_core', 'Speech Recognition'), ('Zero-shot Whisper models', 'related_to_core', 'Speech Recognition'), ('Human', 'related_to_core', 'Speech Recognition'), ('LibriSpeech', 'related_to_core', 'Speech Recognition'), ('Speech Recognition', 'related_to_core', 'robustness'), ('robustness', 'related_to_core', 'Speech Recognition'), ('chunk_57', 'mentions', 'Speech Recognition'), ('chunk_57', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_57', 'mentions', 'WER'), ('chunk_57', 'mentions', 'LibriSpeech dev-clean'), ('chunk_57', 'mentions', 'Common Voice'), ('chunk_57', 'mentions', 'CHiME-6'), ('chunk_57', 'mentions', 'TED-LIUM'), ('chunk_57', 'mentions', 'Supervised LibriSpeech models'), ('chunk_57', 'mentions', 'Zero-shot Whisper models'), ('chunk_57', 'mentions', 'Human'), ('chunk_57', 'mentions', 'LibriSpeech'), ('chunk_57', 'mentions', 'robustness')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_58...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"human\", \"has_errors\", \"errors\"), (\"datasets\", \"demonstrates\", \"brittleness\"), (\"datasets\", \"demonstrates\", \"lack of robustness\"), (\"robustness frontier\", \"of\", \"zero-shot Whisper models\"), (\"zero-shot Whisper models\", \"includes\", \"conﬁdence interval\"), (\"robustness\", \"is\", \"average performance\"), (\"distributions/datasets\", \"related_to\", \"robustness\"), (\"effective robustness\", \"introduced_by\", \"Taori et al. (2020)\"), (\"effective robustness\", \"measures\", \"difference\"), (\"chunk_58\", \"mentions\", \"human\"), (\"chunk_58\", \"mentions\", \"datasets\"), (\"chunk_58\", \"mentions\", \"robustness\"), (\"chunk_58\", \"mentions\", \"zero-shot Whisper models\"), (\"chunk_58\", \"mentions\", \"robustness frontier\"), (\"chunk_58\", \"mentions\", \"conﬁdence interval\"), (\"chunk_58\", \"mentions\", \"effective robustness\"), (\"chunk_58\", \"mentions\", \"distributions/datasets\"), (\"robustness\", \"is_core_idea\", \"true\"), (\"chunk_58\", \"is_core_chunk\", \"true\"), (\"human\", \"related_to_core\", \"robustness\"), (\"datasets\", \"related_to_core\", \"robustness\"), (\"zero-shot Whisper models\", \"related_to_core\", \"robustness\"), (\"robustness frontier\", \"related_to_core\", \"robustness\"), (\"conﬁdence interval\", \"related_to_core\", \"robustness\"), (\"effective robustness\", \"related_to_core\", \"robustness\"), (\"distributions/datasets\", \"related_to_core\", \"robustness\")]\n",
            "✅ Extracted: [('human', 'has_errors', 'errors'), ('datasets', 'demonstrates', 'brittleness'), ('datasets', 'demonstrates', 'lack of robustness'), ('robustness frontier', 'of', 'zero-shot Whisper models'), ('zero-shot Whisper models', 'includes', 'conﬁdence interval'), ('robustness', 'is', 'average performance'), ('distributions/datasets', 'related_to', 'robustness'), ('effective robustness', 'introduced_by', 'Taori et al. (2020)'), ('effective robustness', 'measures', 'difference'), ('chunk_58', 'mentions', 'human'), ('chunk_58', 'mentions', 'datasets'), ('chunk_58', 'mentions', 'robustness'), ('chunk_58', 'mentions', 'zero-shot Whisper models'), ('chunk_58', 'mentions', 'robustness frontier'), ('chunk_58', 'mentions', 'conﬁdence interval'), ('chunk_58', 'mentions', 'effective robustness'), ('chunk_58', 'mentions', 'distributions/datasets'), ('robustness', 'is_core_idea', 'true'), ('chunk_58', 'is_core_chunk', 'true'), ('human', 'related_to_core', 'robustness'), ('datasets', 'related_to_core', 'robustness'), ('zero-shot Whisper models', 'related_to_core', 'robustness'), ('robustness frontier', 'related_to_core', 'robustness'), ('conﬁdence interval', 'related_to_core', 'robustness'), ('effective robustness', 'related_to_core', 'robustness'), ('distributions/datasets', 'related_to_core', 'robustness')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_59...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"reference dataset\", \"is_core_idea\", \"true\"), (\"chunk_59\", \"is_core_chunk\", \"true\"), (\"chunk_59\", \"mentions\", \"reference dataset\"), (\"out-of-distribution datasets\", \"related_to_core\", \"reference dataset\"), (\"performance\", \"related_to_core\", \"reference dataset\"), (\"model\", \"related_to_core\", \"reference dataset\"), (\"effective robustness\", \"related_to_core\", \"reference dataset\"), (\"LibriSpeech\", \"related_to_core\", \"reference dataset\"), (\"speech recognition research\", \"related_to_core\", \"reference dataset\"), (\"chunk_59\", \"mentions\", \"out-of-distribution datasets\"), (\"reference dataset\", \"predicate\", \"in-distribution\"), (\"chunk_59\", \"mentions\", \"performance\"), (\"chunk_59\", \"mentions\", \"model\"), (\"chunk_59\", \"mentions\", \"effective robustness\"), (\"model\", \"has_property\", \"high effective robustness\"), (\"chunk_59\", \"mentions\", \"LibriSpeech\"), (\"LibriSpeech\", \"role\", \"reference dataset\"), (\"chunk_59\", \"mentions\", \"speech recognition research\")]\n",
            "✅ Extracted: [('reference dataset', 'is_core_idea', 'true'), ('chunk_59', 'is_core_chunk', 'true'), ('chunk_59', 'mentions', 'reference dataset'), ('out-of-distribution datasets', 'related_to_core', 'reference dataset'), ('performance', 'related_to_core', 'reference dataset'), ('model', 'related_to_core', 'reference dataset'), ('effective robustness', 'related_to_core', 'reference dataset'), ('LibriSpeech', 'related_to_core', 'reference dataset'), ('speech recognition research', 'related_to_core', 'reference dataset'), ('chunk_59', 'mentions', 'out-of-distribution datasets'), ('reference dataset', 'predicate', 'in-distribution'), ('chunk_59', 'mentions', 'performance'), ('chunk_59', 'mentions', 'model'), ('chunk_59', 'mentions', 'effective robustness'), ('model', 'has_property', 'high effective robustness'), ('chunk_59', 'mentions', 'LibriSpeech'), ('LibriSpeech', 'role', 'reference dataset'), ('chunk_59', 'mentions', 'speech recognition research')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_60...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"released models\", \"related_to_core\", \"Whisper model\"), (\"robustness behaviors\", \"related_to_core\", \"Whisper model\"), (\"speech recognition datasets\", \"related_to_core\", \"Whisper model\"), (\"out-of-distribution behaviors\", \"related_to_core\", \"Whisper model\"), (\"zero-shot Whisper model\", \"is_core_idea\", \"true\"), (\"LibriSpeech clean-test WER\", \"related_to_core\", \"Whisper model\"), (\"supervised baseline\", \"related_to_core\", \"Whisper model\"), (\"chunk_60\", \"mentions\", \"released models\"), (\"chunk_60\", \"mentions\", \"robustness behaviors\"), (\"chunk_60\", \"mentions\", \"speech recognition datasets\"), (\"chunk_60\", \"mentions\", \"out-of-distribution behaviors\"), (\"chunk_60\", \"mentions\", \"zero-shot Whisper model\"), (\"chunk_60\", \"mentions\", \"LibriSpeech clean-test WER\"), (\"chunk_60\", \"mentions\", \"supervised baseline\"), (\"chunk_60\", \"is_core_chunk\", \"true\"), (\"zero-shot Whisper model\", \"is_a\", \"Whisper model\")]\n",
            "✅ Extracted: [('released models', 'related_to_core', 'Whisper model'), ('robustness behaviors', 'related_to_core', 'Whisper model'), ('speech recognition datasets', 'related_to_core', 'Whisper model'), ('out-of-distribution behaviors', 'related_to_core', 'Whisper model'), ('zero-shot Whisper model', 'is_core_idea', 'true'), ('LibriSpeech clean-test WER', 'related_to_core', 'Whisper model'), ('supervised baseline', 'related_to_core', 'Whisper model'), ('chunk_60', 'mentions', 'released models'), ('chunk_60', 'mentions', 'robustness behaviors'), ('chunk_60', 'mentions', 'speech recognition datasets'), ('chunk_60', 'mentions', 'out-of-distribution behaviors'), ('chunk_60', 'mentions', 'zero-shot Whisper model'), ('chunk_60', 'mentions', 'LibriSpeech clean-test WER'), ('chunk_60', 'mentions', 'supervised baseline'), ('chunk_60', 'is_core_chunk', 'true'), ('zero-shot Whisper model', 'is_a', 'Whisper model')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_61...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"zero-shot Whisper models\", \"has_property\", \"different robustness properties\"), (\"zero-shot Whisper models\", \"out-perform\", \"LibriSpeech models\"), (\"LibriSpeech models\", \"is_type\", \"supervised\"), (\"wav2vec 2.0\", \"is_related_to\", \"Whisper RER\"), (\"Dataset Large (no LM)\", \"is_related_to\", \"Large V2 (%)\"), (\"LibriSpeech Clean\", \"is_a\", \"Dataset\"), (\"Artie\", \"is_a\", \"Dataset\"), (\"Common V oice\", \"is_a\", \"Dataset\"), (\"Fleurs En\", \"is_a\", \"Dataset\"), (\"Tedlium\", \"is_a\", \"Dataset\"), (\"CHiME6\", \"is_a\", \"Dataset\"), (\"V oxPopuli En\", \"is_a\", \"Dataset\"), (\"CORAAL\", \"is_a\", \"Dataset\"), (\"chunk_61\", \"mentions\", \"zero-shot Whisper models\"), (\"chunk_61\", \"mentions\", \"LibriSpeech models\"), (\"chunk_61\", \"mentions\", \"wav2vec 2.0\"), (\"chunk_61\", \"mentions\", \"Dataset Large (no LM)\"), (\"chunk_61\", \"mentions\", \"Large V2 (%)\"), (\"chunk_61\", \"mentions\", \"LibriSpeech Clean\"), (\"chunk_61\", \"mentions\", \"Artie\"), (\"chunk_61\", \"mentions\", \"Common V oice\"), (\"chunk_61\", \"mentions\", \"Fleurs En\"), (\"chunk_61\", \"mentions\", \"Tedlium\"), (\"chunk_61\", \"mentions\", \"CHiME6\"), (\"chunk_61\", \"mentions\", \"V oxPopuli En\"), (\"chunk_61\", \"mentions\", \"CORAAL\"), (\"zero-shot Whisper models\", \"is_core_idea\", \"true\"), (\"chunk_61\", \"is_core_chunk\", \"true\"), (\"LibriSpeech models\", \"related_to_core\", \"zero-shot Whisper models\"), (\"wav2vec 2.0\", \"related_to_core\", \"zero-shot Whisper models\"), (\"Dataset Large (no LM)\", \"related_to_core\", \"zero-shot Whisper models\"), (\"Large V2 (%)\", \"related_to_core\", \"zero-shot Whisper models\"), (\"LibriSpeech Clean\", \"related_to_core\", \"zero-shot Whisper models\"), (\"Artie\", \"related_to_core\", \"zero-shot Whisper models\"), (\"Common V oice\", \"related_to_core\", \"zero-shot Whisper models\"), (\"Fleurs En\", \"related_to_core\", \"zero-shot Whisper models\"), (\"Tedlium\", \"related_to_core\", \"zero-shot Whisper models\"), (\"CHiME6\", \"related_to_core\", \"zero-shot Whisper models\"), (\"V oxPopuli En\", \"related_to_core\", \"zero-shot Whisper models\"), (\"CORAAL\", \"related_to_core\", \"zero-shot Whisper models\")]\n",
            "✅ Extracted: [('zero-shot Whisper models', 'has_property', 'different robustness properties'), ('zero-shot Whisper models', 'out-perform', 'LibriSpeech models'), ('LibriSpeech models', 'is_type', 'supervised'), ('wav2vec 2.0', 'is_related_to', 'Whisper RER'), ('Dataset Large (no LM)', 'is_related_to', 'Large V2 (%)'), ('LibriSpeech Clean', 'is_a', 'Dataset'), ('Artie', 'is_a', 'Dataset'), ('Common V oice', 'is_a', 'Dataset'), ('Fleurs En', 'is_a', 'Dataset'), ('Tedlium', 'is_a', 'Dataset'), ('CHiME6', 'is_a', 'Dataset'), ('V oxPopuli En', 'is_a', 'Dataset'), ('CORAAL', 'is_a', 'Dataset'), ('chunk_61', 'mentions', 'zero-shot Whisper models'), ('chunk_61', 'mentions', 'LibriSpeech models'), ('chunk_61', 'mentions', 'wav2vec 2.0'), ('chunk_61', 'mentions', 'Dataset Large (no LM)'), ('chunk_61', 'mentions', 'Large V2 (%)'), ('chunk_61', 'mentions', 'LibriSpeech Clean'), ('chunk_61', 'mentions', 'Artie'), ('chunk_61', 'mentions', 'Common V oice'), ('chunk_61', 'mentions', 'Fleurs En'), ('chunk_61', 'mentions', 'Tedlium'), ('chunk_61', 'mentions', 'CHiME6'), ('chunk_61', 'mentions', 'V oxPopuli En'), ('chunk_61', 'mentions', 'CORAAL'), ('zero-shot Whisper models', 'is_core_idea', 'true'), ('chunk_61', 'is_core_chunk', 'true'), ('LibriSpeech models', 'related_to_core', 'zero-shot Whisper models'), ('wav2vec 2.0', 'related_to_core', 'zero-shot Whisper models'), ('Dataset Large (no LM)', 'related_to_core', 'zero-shot Whisper models'), ('Large V2 (%)', 'related_to_core', 'zero-shot Whisper models'), ('LibriSpeech Clean', 'related_to_core', 'zero-shot Whisper models'), ('Artie', 'related_to_core', 'zero-shot Whisper models'), ('Common V oice', 'related_to_core', 'zero-shot Whisper models'), ('Fleurs En', 'related_to_core', 'zero-shot Whisper models'), ('Tedlium', 'related_to_core', 'zero-shot Whisper models'), ('CHiME6', 'related_to_core', 'zero-shot Whisper models'), ('V oxPopuli En', 'related_to_core', 'zero-shot Whisper models'), ('CORAAL', 'related_to_core', 'zero-shot Whisper models')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_62...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"V oxPopuli\", \"is_core_idea\", \"true\"), (\"chunk_62\", \"is_core_chunk\", \"true\"), (\"chunk_62\", \"mentions\", \"V oxPopuli\"), (\"CORAAL\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"CORAAL\"), (\"AMI IHM\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"AMI IHM\"), (\"Switchboard\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"Switchboard\"), (\"CallHome\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"CallHome\"), (\"WSJ\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"WSJ\"), (\"AMI SDM1\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"AMI SDM1\"), (\"LibriSpeech\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"LibriSpeech\"), (\"LibriSpeech Other\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"LibriSpeech Other\"), (\"Average\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"Average\"), (\"datasets\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"datasets\"), (\"models\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"models\"), (\"zero-shot Whisper model\", \"related_to_core\", \"V oxPopuli\"), (\"chunk_62\", \"mentions\", \"zero-shot Whisper model\")]\n",
            "✅ Extracted: [('V oxPopuli', 'is_core_idea', 'true'), ('chunk_62', 'is_core_chunk', 'true'), ('chunk_62', 'mentions', 'V oxPopuli'), ('CORAAL', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'CORAAL'), ('AMI IHM', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'AMI IHM'), ('Switchboard', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'Switchboard'), ('CallHome', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'CallHome'), ('WSJ', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'WSJ'), ('AMI SDM1', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'AMI SDM1'), ('LibriSpeech', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'LibriSpeech'), ('LibriSpeech Other', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'LibriSpeech Other'), ('Average', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'Average'), ('datasets', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'datasets'), ('models', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'models'), ('zero-shot Whisper model', 'related_to_core', 'V oxPopuli'), ('chunk_62', 'mentions', 'zero-shot Whisper model')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_63...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"performance\", \"mentions\", \"performance\"), (\"chunk_63\", \"mentions\", \"performance\"), (\"errors\", \"mentions\", \"errors\"), (\"chunk_63\", \"mentions\", \"errors\"), (\"word error rate\", \"mentions\", \"word error rate\"), (\"chunk_63\", \"mentions\", \"word error rate\"), (\"WER\", \"mentions\", \"WER\"), (\"chunk_63\", \"mentions\", \"WER\"), (\"text normalizer\", \"mentions\", \"text normalizer\"), (\"chunk_63\", \"mentions\", \"text normalizer\"), (\"zero-shot Whisper model\", \"mentions\", \"zero-shot Whisper model\"), (\"chunk_63\", \"mentions\", \"zero-shot Whisper model\"), (\"parameters\", \"mentions\", \"parameters\"), (\"chunk_63\", \"mentions\", \"parameters\"), (\"LibriSpeech test-clean\", \"mentions\", \"LibriSpeech test-clean\"), (\"chunk_63\", \"mentions\", \"LibriSpeech test-clean\"), (\"LibriSpeech model\", \"mentions\", \"LibriSpeech model\"), (\"chunk_63\", \"mentions\", \"LibriSpeech model\"), (\"datasets\", \"mentions\", \"datasets\"), (\"chunk_63\", \"mentions\", \"datasets\"), (\"human\", \"mentions\", \"human\"), (\"chunk_63\", \"mentions\", \"human\"), (\"zero-shot Whisper models\", \"mentions\", \"zero-shot Whisper models\"), (\"chunk_63\", \"mentions\", \"zero-shot Whisper models\"), (\"performance\", \"related_to_core\", \"zero-shot Whisper models\"), (\"errors\", \"related_to_core\", \"zero-shot Whisper models\"), (\"word error rate\", \"related_to_core\", \"zero-shot Whisper models\"), (\"WER\", \"related_to_core\", \"zero-shot Whisper models\"), (\"text normalizer\", \"related_to_core\", \"zero-shot Whisper models\"), (\"parameters\", \"related_to_core\", \"zero-shot Whisper models\"), (\"LibriSpeech test-clean\", \"related_to_core\", \"zero-shot Whisper models\"), (\"LibriSpeech model\", \"related_to_core\", \"zero-shot Whisper models\"), (\"datasets\", \"related_to_core\", \"zero-shot Whisper models\"), (\"human\", \"related_to_core\", \"zero-shot Whisper models\"), (\"zero-shot Whisper models\", \"is_core_idea\", \"true\"), (\"chunk_63\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('performance', 'mentions', 'performance'), ('chunk_63', 'mentions', 'performance'), ('errors', 'mentions', 'errors'), ('chunk_63', 'mentions', 'errors'), ('word error rate', 'mentions', 'word error rate'), ('chunk_63', 'mentions', 'word error rate'), ('WER', 'mentions', 'WER'), ('chunk_63', 'mentions', 'WER'), ('text normalizer', 'mentions', 'text normalizer'), ('chunk_63', 'mentions', 'text normalizer'), ('zero-shot Whisper model', 'mentions', 'zero-shot Whisper model'), ('chunk_63', 'mentions', 'zero-shot Whisper model'), ('parameters', 'mentions', 'parameters'), ('chunk_63', 'mentions', 'parameters'), ('LibriSpeech test-clean', 'mentions', 'LibriSpeech test-clean'), ('chunk_63', 'mentions', 'LibriSpeech test-clean'), ('LibriSpeech model', 'mentions', 'LibriSpeech model'), ('chunk_63', 'mentions', 'LibriSpeech model'), ('datasets', 'mentions', 'datasets'), ('chunk_63', 'mentions', 'datasets'), ('human', 'mentions', 'human'), ('chunk_63', 'mentions', 'human'), ('zero-shot Whisper models', 'mentions', 'zero-shot Whisper models'), ('chunk_63', 'mentions', 'zero-shot Whisper models'), ('performance', 'related_to_core', 'zero-shot Whisper models'), ('errors', 'related_to_core', 'zero-shot Whisper models'), ('word error rate', 'related_to_core', 'zero-shot Whisper models'), ('WER', 'related_to_core', 'zero-shot Whisper models'), ('text normalizer', 'related_to_core', 'zero-shot Whisper models'), ('parameters', 'related_to_core', 'zero-shot Whisper models'), ('LibriSpeech test-clean', 'related_to_core', 'zero-shot Whisper models'), ('LibriSpeech model', 'related_to_core', 'zero-shot Whisper models'), ('datasets', 'related_to_core', 'zero-shot Whisper models'), ('human', 'related_to_core', 'zero-shot Whisper models'), ('zero-shot Whisper models', 'is_core_idea', 'true'), ('chunk_63', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_64...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"robustness\", \"is_core_idea\", \"true\"), (\"chunk_64\", \"is_core_chunk\", \"true\"), (\"chunk_64\", \"mentions\", \"robustness\"), (\"Table 2\", \"related_to_core\", \"robustness\"), (\"Whisper model\", \"related_to_core\", \"robustness\"), (\"LibriSpeech model\", \"related_to_core\", \"robustness\"), (\"LibriSpeech test-clean\", \"related_to_core\", \"robustness\"), (\"reference distribution\", \"related_to_core\", \"robustness\"), (\"error reduction\", \"related_to_core\", \"robustness\"), (\"speech recognition datasets\", \"related_to_core\", \"robustness\"), (\"zero-shot\", \"related_to_core\", \"robustness\"), (\"out-of-\", \"related_to_core\", \"robustness\"), (\"chunk_64\", \"mentions\", \"Table 2\"), (\"chunk_64\", \"mentions\", \"Whisper model\"), (\"chunk_64\", \"mentions\", \"LibriSpeech model\"), (\"chunk_64\", \"mentions\", \"LibriSpeech test-clean\"), (\"chunk_64\", \"mentions\", \"reference distribution\"), (\"chunk_64\", \"mentions\", \"error reduction\"), (\"chunk_64\", \"mentions\", \"speech recognition datasets\"), (\"chunk_64\", \"mentions\", \"zero-shot\"), (\"chunk_64\", \"mentions\", \"out-of-\"), (\"Whisper model\", \"performance_compared_to\", \"LibriSpeech model\"), (\"Whisper model\", \"achieves\", \"error reduction\"), (\"error reduction\", \"evaluated_on\", \"speech recognition datasets\")]\n",
            "✅ Extracted: [('robustness', 'is_core_idea', 'true'), ('chunk_64', 'is_core_chunk', 'true'), ('chunk_64', 'mentions', 'robustness'), ('Table 2', 'related_to_core', 'robustness'), ('Whisper model', 'related_to_core', 'robustness'), ('LibriSpeech model', 'related_to_core', 'robustness'), ('LibriSpeech test-clean', 'related_to_core', 'robustness'), ('reference distribution', 'related_to_core', 'robustness'), ('error reduction', 'related_to_core', 'robustness'), ('speech recognition datasets', 'related_to_core', 'robustness'), ('zero-shot', 'related_to_core', 'robustness'), ('out-of-', 'related_to_core', 'robustness'), ('chunk_64', 'mentions', 'Table 2'), ('chunk_64', 'mentions', 'Whisper model'), ('chunk_64', 'mentions', 'LibriSpeech model'), ('chunk_64', 'mentions', 'LibriSpeech test-clean'), ('chunk_64', 'mentions', 'reference distribution'), ('chunk_64', 'mentions', 'error reduction'), ('chunk_64', 'mentions', 'speech recognition datasets'), ('chunk_64', 'mentions', 'zero-shot'), ('chunk_64', 'mentions', 'out-of-'), ('Whisper model', 'performance_compared_to', 'LibriSpeech model'), ('Whisper model', 'achieves', 'error reduction'), ('error reduction', 'evaluated_on', 'speech recognition datasets')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_65...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"distribution evaluations\", \"mentions\", \"distribution evaluations\"), (\"chunk_65\", \"mentions\", \"distribution evaluations\"), (\"models\", \"mentions\", \"models\"), (\"chunk_65\", \"mentions\", \"models\"), (\"human performance\", \"mentions\", \"human performance\"), (\"chunk_65\", \"mentions\", \"human performance\"), (\"machine learning systems\", \"mentions\", \"machine learning systems\"), (\"chunk_65\", \"mentions\", \"machine learning systems\"), (\"Multi-lingual Speech Recognition\", \"mentions\", \"Multi-lingual Speech Recognition\"), (\"chunk_65\", \"mentions\", \"Multi-lingual Speech Recognition\"), (\"multilingual speech recognition\", \"mentions\", \"multilingual speech recognition\"), (\"chunk_65\", \"mentions\", \"multilingual speech recognition\"), (\"Multilingual LibriSpeech\", \"mentions\", \"Multilingual LibriSpeech\"), (\"chunk_65\", \"mentions\", \"Multilingual LibriSpeech\"), (\"VoxPopuli\", \"mentions\", \"VoxPopuli\"), (\"chunk_65\", \"mentions\", \"VoxPopuli\"), (\"models\", \"related_to_core\", \"distribution evaluations\"), (\"human performance\", \"related_to_core\", \"distribution evaluations\"), (\"machine learning systems\", \"related_to_core\", \"distribution evaluations\"), (\"Multi-lingual Speech Recognition\", \"related_to_core\", \"distribution evaluations\"), (\"multilingual speech recognition\", \"related_to_core\", \"distribution evaluations\"), (\"Multilingual LibriSpeech\", \"related_to_core\", \"distribution evaluations\"), (\"VoxPopuli\", \"related_to_core\", \"distribution evaluations\"), (\"distribution evaluations\", \"is_core_idea\", \"true\"), (\"chunk_65\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('distribution evaluations', 'mentions', 'distribution evaluations'), ('chunk_65', 'mentions', 'distribution evaluations'), ('models', 'mentions', 'models'), ('chunk_65', 'mentions', 'models'), ('human performance', 'mentions', 'human performance'), ('chunk_65', 'mentions', 'human performance'), ('machine learning systems', 'mentions', 'machine learning systems'), ('chunk_65', 'mentions', 'machine learning systems'), ('Multi-lingual Speech Recognition', 'mentions', 'Multi-lingual Speech Recognition'), ('chunk_65', 'mentions', 'Multi-lingual Speech Recognition'), ('multilingual speech recognition', 'mentions', 'multilingual speech recognition'), ('chunk_65', 'mentions', 'multilingual speech recognition'), ('Multilingual LibriSpeech', 'mentions', 'Multilingual LibriSpeech'), ('chunk_65', 'mentions', 'Multilingual LibriSpeech'), ('VoxPopuli', 'mentions', 'VoxPopuli'), ('chunk_65', 'mentions', 'VoxPopuli'), ('models', 'related_to_core', 'distribution evaluations'), ('human performance', 'related_to_core', 'distribution evaluations'), ('machine learning systems', 'related_to_core', 'distribution evaluations'), ('Multi-lingual Speech Recognition', 'related_to_core', 'distribution evaluations'), ('multilingual speech recognition', 'related_to_core', 'distribution evaluations'), ('Multilingual LibriSpeech', 'related_to_core', 'distribution evaluations'), ('VoxPopuli', 'related_to_core', 'distribution evaluations'), ('distribution evaluations', 'is_core_idea', 'true'), ('chunk_65', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_66...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"VoxPopuli\", \"is_a\", \"method\"), (\"chunk_66\", \"mentions\", \"VoxPopuli\"), (\"Whisper\", \"is_a\", \"method\"), (\"chunk_66\", \"mentions\", \"Whisper\"), (\"Multilingual LibriSpeech\", \"is_a\", \"dataset\"), (\"chunk_66\", \"mentions\", \"Multilingual LibriSpeech\"), (\"XLS-R\", \"is_a\", \"method\"), (\"chunk_66\", \"mentions\", \"XLS-R\"), (\"mSLAM\", \"is_a\", \"method\"), (\"chunk_66\", \"mentions\", \"mSLAM\"), (\"Whisper\", \"performs_well_on\", \"Multilingual LibriSpeech\"), (\"Whisper\", \"outperforms\", \"XLS-R\"), (\"Whisper\", \"outperforms\", \"mSLAM\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_66\", \"is_core_chunk\", \"true\"), (\"VoxPopuli\", \"related_to_core\", \"Whisper\"), (\"Multilingual LibriSpeech\", \"related_to_core\", \"Whisper\"), (\"XLS-R\", \"related_to_core\", \"Whisper\"), (\"mSLAM\", \"related_to_core\", \"Whisper\")]\n",
            "✅ Extracted: [('VoxPopuli', 'is_a', 'method'), ('chunk_66', 'mentions', 'VoxPopuli'), ('Whisper', 'is_a', 'method'), ('chunk_66', 'mentions', 'Whisper'), ('Multilingual LibriSpeech', 'is_a', 'dataset'), ('chunk_66', 'mentions', 'Multilingual LibriSpeech'), ('XLS-R', 'is_a', 'method'), ('chunk_66', 'mentions', 'XLS-R'), ('mSLAM', 'is_a', 'method'), ('chunk_66', 'mentions', 'mSLAM'), ('Whisper', 'performs_well_on', 'Multilingual LibriSpeech'), ('Whisper', 'outperforms', 'XLS-R'), ('Whisper', 'outperforms', 'mSLAM'), ('Whisper', 'is_core_idea', 'true'), ('chunk_66', 'is_core_chunk', 'true'), ('VoxPopuli', 'related_to_core', 'Whisper'), ('Multilingual LibriSpeech', 'related_to_core', 'Whisper'), ('XLS-R', 'related_to_core', 'Whisper'), ('mSLAM', 'related_to_core', 'Whisper')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_67...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"related_to_core\", \"Speech Recognition\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"Speech Recognition\"), (\"Word Error Rate\", \"related_to_core\", \"Speech Recognition\"), (\"pre-training supervision\", \"related_to_core\", \"Speech Recognition\"), (\"downstream speech recognition performance\", \"related_to_core\", \"Speech Recognition\"), (\"Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_67\", \"is_core_chunk\", \"true\"), (\"chunk_67\", \"mentions\", \"Robust Speech Recognition\"), (\"chunk_67\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_67\", \"mentions\", \"Word Error Rate\"), (\"chunk_67\", \"mentions\", \"pre-training supervision\"), (\"chunk_67\", \"mentions\", \"downstream speech recognition performance\"), (\"chunk_67\", \"mentions\", \"Speech Recognition\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'related_to_core', 'Speech Recognition'), ('Large-Scale Weak Supervision', 'related_to_core', 'Speech Recognition'), ('Word Error Rate', 'related_to_core', 'Speech Recognition'), ('pre-training supervision', 'related_to_core', 'Speech Recognition'), ('downstream speech recognition performance', 'related_to_core', 'Speech Recognition'), ('Speech Recognition', 'is_core_idea', 'true'), ('chunk_67', 'is_core_chunk', 'true'), ('chunk_67', 'mentions', 'Robust Speech Recognition'), ('chunk_67', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_67', 'mentions', 'Word Error Rate'), ('chunk_67', 'mentions', 'pre-training supervision'), ('chunk_67', 'mentions', 'downstream speech recognition performance'), ('chunk_67', 'mentions', 'Speech Recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_68...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"pre-training speech recognition data\", \"is_core_idea\", \"true\"), (\"chunk_68\", \"is_core_chunk\", \"true\"), (\"pre-training speech recognition data\", \"mentions\", \"pre-training speech recognition data\"), (\"chunk_68\", \"mentions\", \"language\"), (\"language\", \"related_to_core\", \"pre-training speech recognition data\"), (\"language\", \"mentions\", \"language\"), (\"chunk_68\", \"mentions\", \"zero-shot performance\"), (\"zero-shot performance\", \"related_to_core\", \"pre-training speech recognition data\"), (\"zero-shot performance\", \"mentions\", \"zero-shot performance\"), (\"chunk_68\", \"mentions\", \"Fleurs\"), (\"Fleurs\", \"related_to_core\", \"pre-training speech recognition data\"), (\"Fleurs\", \"mentions\", \"Fleurs\"), (\"chunk_68\", \"mentions\", \"Model MLS V oxPopuli\"), (\"Model MLS V oxPopuli\", \"related_to_core\", \"pre-training speech recognition data\"), (\"Model MLS V oxPopuli\", \"mentions\", \"Model MLS V oxPopuli\"), (\"chunk_68\", \"mentions\", \"VP-10K\"), (\"VP-10K\", \"related_to_core\", \"pre-training speech recognition data\"), (\"VP-10K\", \"mentions\", \"VP-10K\"), (\"chunk_68\", \"mentions\", \"XLS-R (1B)\"), (\"XLS-R (1B)\", \"related_to_core\", \"pre-training speech recognition data\"), (\"XLS-R (1B)\", \"mentions\", \"XLS-R (1B)\"), (\"chunk_68\", \"mentions\", \"mSLAM-CTC (2B)\"), (\"mSLAM-CTC (2B)\", \"related_to_core\", \"pre-training speech recognition data\"), (\"mSLAM-CTC (2B)\", \"mentions\", \"mSLAM-CTC (2B)\"), (\"chunk_68\", \"mentions\", \"Maestro\"), (\"Maestro\", \"related_to_core\", \"pre-training speech recognition data\"), (\"Maestro\", \"mentions\", \"Maestro\"), (\"chunk_68\", \"mentions\", \"Zero-Shot Whisper\"), (\"Zero-Shot Whisper\", \"related_to_core\", \"pre-training speech recognition data\"), (\"Zero-Shot Whisper\", \"mentions\", \"Zero-Shot Whisper\"), (\"chunk_68\", \"mentions\", \"Multilingual speech recognition performance\"), (\"Multilingual speech recognition performance\", \"related_to_core\", \"pre-training speech recognition data\"), (\"Multilingual speech recognition performance\", \"mentions\", \"Multilingual speech recognition performance\"), (\"chunk_68\", \"mentions\", \"Multilingual LibriSpeech\"), (\"Multilingual LibriSpeech\", \"related_to_core\", \"pre-training speech recognition data\"), (\"Multilingual LibriSpeech\", \"mentions\", \"Multilingual LibriSpeech\"), (\"chunk_68\", \"mentions\", \"V oxPopuli\"), (\"V oxPopuli\", \"related_to_core\", \"pre-training speech recognition data\"), (\"V oxPopuli\", \"mentions\", \"V oxPopuli\")]\n",
            "✅ Extracted: [('pre-training speech recognition data', 'is_core_idea', 'true'), ('chunk_68', 'is_core_chunk', 'true'), ('pre-training speech recognition data', 'mentions', 'pre-training speech recognition data'), ('chunk_68', 'mentions', 'language'), ('language', 'related_to_core', 'pre-training speech recognition data'), ('language', 'mentions', 'language'), ('chunk_68', 'mentions', 'zero-shot performance'), ('zero-shot performance', 'related_to_core', 'pre-training speech recognition data'), ('zero-shot performance', 'mentions', 'zero-shot performance'), ('chunk_68', 'mentions', 'Fleurs'), ('Fleurs', 'related_to_core', 'pre-training speech recognition data'), ('Fleurs', 'mentions', 'Fleurs'), ('chunk_68', 'mentions', 'Model MLS V oxPopuli'), ('Model MLS V oxPopuli', 'related_to_core', 'pre-training speech recognition data'), ('Model MLS V oxPopuli', 'mentions', 'Model MLS V oxPopuli'), ('chunk_68', 'mentions', 'VP-10K'), ('VP-10K', 'related_to_core', 'pre-training speech recognition data'), ('VP-10K', 'mentions', 'VP-10K'), ('chunk_68', 'mentions', 'XLS-R (1B)'), ('XLS-R (1B)', 'related_to_core', 'pre-training speech recognition data'), ('XLS-R (1B)', 'mentions', 'XLS-R (1B)'), ('chunk_68', 'mentions', 'mSLAM-CTC (2B)'), ('mSLAM-CTC (2B)', 'related_to_core', 'pre-training speech recognition data'), ('mSLAM-CTC (2B)', 'mentions', 'mSLAM-CTC (2B)'), ('chunk_68', 'mentions', 'Maestro'), ('Maestro', 'related_to_core', 'pre-training speech recognition data'), ('Maestro', 'mentions', 'Maestro'), ('chunk_68', 'mentions', 'Zero-Shot Whisper'), ('Zero-Shot Whisper', 'related_to_core', 'pre-training speech recognition data'), ('Zero-Shot Whisper', 'mentions', 'Zero-Shot Whisper'), ('chunk_68', 'mentions', 'Multilingual speech recognition performance'), ('Multilingual speech recognition performance', 'related_to_core', 'pre-training speech recognition data'), ('Multilingual speech recognition performance', 'mentions', 'Multilingual speech recognition performance'), ('chunk_68', 'mentions', 'Multilingual LibriSpeech'), ('Multilingual LibriSpeech', 'related_to_core', 'pre-training speech recognition data'), ('Multilingual LibriSpeech', 'mentions', 'Multilingual LibriSpeech'), ('chunk_68', 'mentions', 'V oxPopuli'), ('V oxPopuli', 'related_to_core', 'pre-training speech recognition data'), ('V oxPopuli', 'mentions', 'V oxPopuli')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_69...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"mSLAM\", \"on\", \"VoxPopuli\"), (\"chunk_69\", \"mentions\", \"mSLAM\"), (\"chunk_69\", \"mentions\", \"VoxPopuli\"), (\"Maestro\", \"in\", \"zero-shot setting\"), (\"chunk_69\", \"mentions\", \"Maestro\"), (\"chunk_69\", \"mentions\", \"zero-shot setting\"), (\"text standardizer\", \"prevents\", \"direct comparison\"), (\"chunk_69\", \"mentions\", \"text standardizer\"), (\"chunk_69\", \"mentions\", \"direct comparison\"), (\"SOTA performance\", \"related_to\", \"direct comparison\"), (\"chunk_69\", \"mentions\", \"SOTA performance\"), (\"Whisper\", \"underperforms\", \"prior work\"), (\"chunk_69\", \"mentions\", \"Whisper\"), (\"chunk_69\", \"mentions\", \"prior work\"), (\"Whisper\", \"beats\", \"VP-10K+FT baseline\"), (\"chunk_69\", \"mentions\", \"VP-10K+FT baseline\"), (\"Whisper models\", \"on\", \"VoxPopuli\"), (\"chunk_69\", \"mentions\", \"Whisper models\"), (\"VoxPopuli\", \"is_core_idea\", \"true\"), (\"chunk_69\", \"is_core_chunk\", \"true\"), (\"mSLAM\", \"related_to_core\", \"VoxPopuli\"), (\"Maestro\", \"related_to_core\", \"VoxPopuli\"), (\"zero-shot setting\", \"related_to_core\", \"VoxPopuli\"), (\"text standardizer\", \"related_to_core\", \"VoxPopuli\"), (\"direct comparison\", \"related_to_core\", \"VoxPopuli\"), (\"SOTA performance\", \"related_to_core\", \"VoxPopuli\"), (\"Whisper\", \"related_to_core\", \"VoxPopuli\"), (\"prior work\", \"related_to_core\", \"VoxPopuli\"), (\"VP-10K+FT baseline\", \"related_to_core\", \"VoxPopuli\")]\n",
            "✅ Extracted: [('mSLAM', 'on', 'VoxPopuli'), ('chunk_69', 'mentions', 'mSLAM'), ('chunk_69', 'mentions', 'VoxPopuli'), ('Maestro', 'in', 'zero-shot setting'), ('chunk_69', 'mentions', 'Maestro'), ('chunk_69', 'mentions', 'zero-shot setting'), ('text standardizer', 'prevents', 'direct comparison'), ('chunk_69', 'mentions', 'text standardizer'), ('chunk_69', 'mentions', 'direct comparison'), ('SOTA performance', 'related_to', 'direct comparison'), ('chunk_69', 'mentions', 'SOTA performance'), ('Whisper', 'underperforms', 'prior work'), ('chunk_69', 'mentions', 'Whisper'), ('chunk_69', 'mentions', 'prior work'), ('Whisper', 'beats', 'VP-10K+FT baseline'), ('chunk_69', 'mentions', 'VP-10K+FT baseline'), ('Whisper models', 'on', 'VoxPopuli'), ('chunk_69', 'mentions', 'Whisper models'), ('VoxPopuli', 'is_core_idea', 'true'), ('chunk_69', 'is_core_chunk', 'true'), ('mSLAM', 'related_to_core', 'VoxPopuli'), ('Maestro', 'related_to_core', 'VoxPopuli'), ('zero-shot setting', 'related_to_core', 'VoxPopuli'), ('text standardizer', 'related_to_core', 'VoxPopuli'), ('direct comparison', 'related_to_core', 'VoxPopuli'), ('SOTA performance', 'related_to_core', 'VoxPopuli'), ('Whisper', 'related_to_core', 'VoxPopuli'), ('prior work', 'related_to_core', 'VoxPopuli'), ('VP-10K+FT baseline', 'related_to_core', 'VoxPopuli')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_70...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"unsupervised pre-training data\", \"mentions\", \"data\"), (\"MLS\", \"mentions\", \"MLS\"), (\"supervised data\", \"mentions\", \"data\"), (\"fine-tuning\", \"mentions\", \"fine-tuning\"), (\"MLS\", \"has_training_data\", \"10 hours\"), (\"language\", \"mentions\", \"language\"), (\"training data\", \"mentions\", \"data\"), (\"language\", \"mentions\", \"language\"), (\"VoxPopuli\", \"mentions\", \"VoxPopuli\"), (\"benchmarks\", \"mentions\", \"benchmarks\"), (\"languages\", \"mentions\", \"languages\"), (\"chunk_70\", \"mentions\", \"unsupervised pre-training data\"), (\"chunk_70\", \"mentions\", \"MLS\"), (\"chunk_70\", \"mentions\", \"supervised data\"), (\"chunk_70\", \"mentions\", \"fine-tuning\"), (\"chunk_70\", \"mentions\", \"language\"), (\"chunk_70\", \"mentions\", \"training data\"), (\"chunk_70\", \"mentions\", \"VoxPopuli\"), (\"chunk_70\", \"mentions\", \"benchmarks\"), (\"chunk_70\", \"mentions\", \"languages\"), (\"VoxPopuli\", \"is_core_idea\", \"true\"), (\"chunk_70\", \"is_core_chunk\", \"true\"), (\"unsupervised pre-training data\", \"related_to_core\", \"VoxPopuli\"), (\"MLS\", \"related_to_core\", \"VoxPopuli\"), (\"supervised data\", \"related_to_core\", \"VoxPopuli\"), (\"fine-tuning\", \"related_to_core\", \"VoxPopuli\"), (\"language\", \"related_to_core\", \"VoxPopuli\"), (\"training data\", \"related_to_core\", \"VoxPopuli\"), (\"benchmarks\", \"related_to_core\", \"VoxPopuli\"), (\"languages\", \"related_to_core\", \"VoxPopuli\")]\n",
            "✅ Extracted: [('unsupervised pre-training data', 'mentions', 'data'), ('MLS', 'mentions', 'MLS'), ('supervised data', 'mentions', 'data'), ('fine-tuning', 'mentions', 'fine-tuning'), ('MLS', 'has_training_data', '10 hours'), ('language', 'mentions', 'language'), ('training data', 'mentions', 'data'), ('language', 'mentions', 'language'), ('VoxPopuli', 'mentions', 'VoxPopuli'), ('benchmarks', 'mentions', 'benchmarks'), ('languages', 'mentions', 'languages'), ('chunk_70', 'mentions', 'unsupervised pre-training data'), ('chunk_70', 'mentions', 'MLS'), ('chunk_70', 'mentions', 'supervised data'), ('chunk_70', 'mentions', 'fine-tuning'), ('chunk_70', 'mentions', 'language'), ('chunk_70', 'mentions', 'training data'), ('chunk_70', 'mentions', 'VoxPopuli'), ('chunk_70', 'mentions', 'benchmarks'), ('chunk_70', 'mentions', 'languages'), ('VoxPopuli', 'is_core_idea', 'true'), ('chunk_70', 'is_core_chunk', 'true'), ('unsupervised pre-training data', 'related_to_core', 'VoxPopuli'), ('MLS', 'related_to_core', 'VoxPopuli'), ('supervised data', 'related_to_core', 'VoxPopuli'), ('fine-tuning', 'related_to_core', 'VoxPopuli'), ('language', 'related_to_core', 'VoxPopuli'), ('training data', 'related_to_core', 'VoxPopuli'), ('benchmarks', 'related_to_core', 'VoxPopuli'), ('languages', 'related_to_core', 'VoxPopuli')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_71...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"BLEU\", \"mentions\", \"BLEU\"), (\"chunk_71\", \"mentions\", \"BLEU\"), (\"r2\", \"mentions\", \"r2\"), (\"chunk_71\", \"mentions\", \"r2\"), (\"HR\", \"mentions\", \"HR\"), (\"chunk_71\", \"mentions\", \"HR\"), (\"AM\", \"mentions\", \"AM\"), (\"chunk_71\", \"mentions\", \"AM\"), (\"NL\", \"mentions\", \"NL\"), (\"chunk_71\", \"mentions\", \"NL\"), (\"MY\", \"mentions\", \"MY\"), (\"chunk_71\", \"mentions\", \"MY\"), (\"SW\", \"mentions\", \"SW\"), (\"chunk_71\", \"mentions\", \"SW\"), (\"EL\", \"mentions\", \"EL\"), (\"chunk_71\", \"mentions\", \"EL\"), (\"NE\", \"mentions\", \"NE\"), (\"chunk_71\", \"mentions\", \"NE\"), (\"TH\", \"mentions\", \"TH\"), (\"chunk_71\", \"mentions\", \"TH\"), (\"KN\", \"mentions\", \"KN\"), (\"chunk_71\", \"mentions\", \"KN\"), (\"PA\", \"mentions\", \"PA\"), (\"chunk_71\", \"mentions\", \"PA\"), (\"DA\", \"mentions\", \"DA\"), (\"chunk_71\", \"mentions\", \"DA\"), (\"AR\", \"mentions\", \"AR\"), (\"chunk_71\", \"mentions\", \"AR\"), (\"MI\", \"mentions\", \"MI\"), (\"chunk_71\", \"mentions\", \"MI\"), (\"BG\", \"mentions\", \"BG\"), (\"chunk_71\", \"mentions\", \"BG\"), (\"ML\", \"mentions\", \"ML\"), (\"chunk_71\", \"mentions\", \"ML\"), (\"MR\", \"mentions\", \"MR\"), (\"chunk_71\", \"mentions\", \"MR\"), (\"TE\", \"mentions\", \"TE\"), (\"chunk_71\", \"mentions\", \"TE\"), (\"SV\", \"mentions\", \"SV\"), (\"chunk_71\", \"mentions\", \"SV\"), (\"IT\", \"mentions\", \"IT\"), (\"chunk_71\", \"mentions\", \"IT\"), (\"FIL\", \"mentions\", \"FIL\"), (\"chunk_71\", \"mentions\", \"FIL\"), (\"GL\", \"mentions\", \"GL\"), (\"chunk_71\", \"mentions\", \"GL\"), (\"RO\", \"mentions\", \"RO\"), (\"chunk_71\", \"mentions\", \"RO\"), (\"UK\", \"mentions\", \"UK\"), (\"chunk_71\", \"mentions\", \"UK\"), (\"FA\", \"mentions\", \"FA\"), (\"chunk_71\", \"mentions\", \"FA\"), (\"UZ\", \"mentions\", \"UZ\"), (\"chunk_71\", \"mentions\", \"UZ\"), (\"BE\", \"mentions\", \"BE\"), (\"chunk_71\", \"mentions\", \"BE\"), (\"KM\", \"mentions\", \"KM\"), (\"chunk_71\", \"mentions\", \"KM\"), (\"TG\", \"mentions\", \"TG\"), (\"chunk_71\", \"mentions\", \"TG\"), (\"AS\", \"mentions\", \"AS\"), (\"chunk_71\", \"mentions\", \"AS\"), (\"ET\", \"mentions\", \"ET\"), (\"chunk_71\", \"mentions\", \"ET\"), (\"OC\", \"mentions\", \"OC\"), (\"chunk_71\", \"mentions\", \"OC\"), (\"CA\", \"mentions\", \"CA\"), (\"chunk_71\", \"mentions\", \"CA\"), (\"IS\", \"mentions\", \"IS\"), (\"chunk_71\", \"mentions\", \"IS\"), (\"KK\", \"mentions\", \"KK\"), (\"chunk_71\", \"mentions\", \"KK\"), (\"HE\", \"mentions\", \"HE\"), (\"chunk_71\", \"mentions\", \"HE\"), (\"FRAF\", \"mentions\", \"FRAF\"), (\"chunk_71\", \"mentions\", \"FRAF\"), (\"VI\", \"mentions\", \"VI\"), (\"chunk_71\", \"mentions\", \"VI\"), (\"HA\", \"mentions\", \"HA\"), (\"chunk_71\", \"mentions\", \"HA\"), (\"MT\", \"mentions\", \"MT\"), (\"chunk_71\", \"mentions\", \"MT\"), (\"LO\", \"mentions\", \"LO\"), (\"chunk_71\", \"mentions\", \"LO\"), (\"BN\", \"mentions\", \"BN\"), (\"chunk_71\", \"mentions\", \"BN\"), (\"PT\", \"mentions\", \"PT\"), (\"chunk_71\", \"mentions\", \"PT\"), (\"HU\", \"mentions\", \"HU\"), (\"chunk_71\", \"mentions\", \"HU\"), (\"FI\", \"mentions\", \"FI\"), (\"chunk_71\", \"mentions\", \"FI\"), (\"KO\", \"mentions\", \"KO\"), (\"chunk_71\", \"mentions\", \"KO\"), (\"SD\", \"mentions\", \"SD\"), (\"chunk_71\", \"mentions\", \"SD\"), (\"ID\", \"mentions\", \"ID\"), (\"chunk_71\", \"mentions\", \"ID\"), (\"UR\", \"mentions\", \"UR\"), (\"chunk_71\", \"mentions\", \"UR\"), (\"LN\", \"mentions\", \"LN\"), (\"chunk_71\", \"mentions\", \"LN\"), (\"LV\", \"mentions\", \"LV\"), (\"chunk_71\", \"mentions\", \"LV\"), (\"AZ\", \"mentions\", \"AZ\"), (\"chunk_71\", \"mentions\", \"AZ\"), (\"YO\", \"mentions\", \"YO\"), (\"chunk_71\", \"mentions\", \"YO\"), (\"LB\", \"mentions\", \"LB\"), (\"chunk_71\", \"mentions\", \"LB\"), (\"CY\", \"mentions\", \"CY\"), (\"chunk_71\", \"mentions\", \"CY\"), (\"HY\", \"mentions\", \"HY\"), (\"chunk_71\", \"mentions\", \"HY\"), (\"PL\", \"mentions\", \"PL\"), (\"chunk_71\", \"mentions\", \"PL\"), (\"LT\", \"mentions\", \"LT\"), (\"chunk_71\", \"mentions\", \"LT\"), (\"DE\", \"mentions\", \"DE\"), (\"chunk_71\", \"mentions\", \"DE\"), (\"KA\", \"mentions\", \"KA\"), (\"chunk_71\", \"mentions\", \"KA\"), (\"RU\", \"mentions\", \"RU\"), (\"chunk_71\", \"mentions\", \"RU\"), (\"MK\", \"mentions\", \"MK\"), (\"chunk_71\", \"mentions\", \"MK\"), (\"MS\", \"mentions\", \"MS\"), (\"chunk_71\", \"mentions\", \"MS\"), (\"SR\", \"mentions\", \"SR\"), (\"chunk_71\", \"mentions\", \"SR\"), (\"ES\", \"mentions\", \"ES\"), (\"chunk_71\", \"mentions\", \"ES\"), (\"ZH\", \"mentions\", \"ZH\"), (\"chunk_71\", \"mentions\", \"ZH\"), (\"JA\", \"mentions\", \"JA\"), (\"chunk_71\", \"mentions\", \"JA\"), (\"NBBS\", \"mentions\", \"NBBS\"), (\"chunk_71\", \"mentions\", \"NBBS\"), (\"MN\", \"mentions\", \"MN\"), (\"chunk_71\", \"mentions\", \"MN\"), (\"SN\", \"mentions\", \"SN\"), (\"chunk_71\", \"mentions\", \"SN\"), (\"TR\", \"mentions\", \"TR\"), (\"chunk_71\", \"mentions\", \"TR\"), (\"PS\", \"mentions\", \"PS\"), (\"chunk_71\", \"mentions\", \"PS\"), (\"SK\", \"mentions\", \"SK\"), (\"chunk_71\", \"mentions\", \"SK\"), (\"SO\", \"mentions\", \"SO\"), (\"chunk_71\", \"mentions\", \"SO\"), (\"CS\", \"mentions\", \"CS\"), (\"chunk_71\", \"mentions\", \"CS\"), (\"SL\", \"mentions\", \"SL\"), (\"chunk_71\", \"mentions\", \"SL\"), (\"HI\", \"mentions\", \"HI\"), (\"chunk_71\", \"mentions\", \"HI\"), (\"GU\", \"mentions\", \"GU\"), (\"chunk_71\", \"mentions\", \"GU\"), (\"TA\", \"mentions\", \"TA\"), (\"chunk_71\", \"mentions\", \"TA\"), (\"pre-training supervision amount\", \"mentions\", \"pre-training supervision amount\"), (\"chunk_71\", \"mentions\", \"pre-training supervision amount\"), (\"downstream translation performance\", \"mentions\", \"downstream translation performance\"), (\"chunk_71\", \"mentions\", \"downstream translation performance\"), (\"pre-training translation data\", \"mentions\", \"pre-training translation data\"), (\"chunk_71\", \"mentions\", \"pre-training translation data\"), (\"language\", \"mentions\", \"language\"), (\"chunk_71\", \"mentions\", \"language\"), (\"downstream translation performance\", \"related_to_core\", \"pre-training supervision amount\"), (\"pre-training translation data\", \"related_to_core\", \"pre-training supervision amount\"), (\"language\", \"related_to_core\", \"pre-training supervision amount\"), (\"TA\", \"related_to_core\", \"pre-training supervision amount\"), (\"GU\", \"related_to_core\", \"pre-training supervision amount\"), (\"HI\", \"related_to_core\", \"pre-training supervision amount\"), (\"SL\", \"related_to_core\", \"pre-training supervision amount\"), (\"CS\", \"related_to_core\", \"pre-training supervision amount\"), (\"SO\", \"related_to_core\", \"pre-training supervision amount\"), (\"SK\", \"related_to_core\", \"pre-training supervision amount\"), (\"PS\", \"related_to_core\", \"pre-training supervision amount\"), (\"TR\", \"related_to_core\", \"pre-training supervision amount\"), (\"SN\", \"related_to_core\", \"pre-training supervision amount\"), (\"MN\", \"related_to_core\", \"pre-training supervision amount\"), (\"NBBS\", \"related_to_core\", \"pre-training supervision amount\"), (\"JA\", \"related_to_core\", \"pre-training supervision amount\"), (\"ZH\", \"related_to_core\", \"pre-training supervision amount\"), (\"ES\", \"related_to_core\", \"pre-training supervision amount\"), (\"SR\", \"related_to_core\", \"pre-training supervision amount\"), (\"MS\", \"related_to_core\", \"pre-training supervision amount\"), (\"MK\", \"related_to_core\", \"pre-training supervision amount\"), (\"RU\", \"related_to_core\", \"pre-training supervision amount\"), (\"KA\", \"related_to_core\", \"pre-training supervision amount\"), (\"DE\", \"related_to_core\", \"pre-training supervision amount\"), (\"LT\", \"related_to_core\", \"pre-training supervision amount\"), (\"PL\", \"related_to_core\", \"pre-training supervision amount\"), (\"HY\", \"related_to_core\", \"pre-training supervision amount\"), (\"CY\", \"related_to_core\", \"pre-training supervision amount\"), (\"LB\", \"related_to_core\", \"pre-training supervision amount\"), (\"YO\", \"related_to_core\", \"pre-training supervision amount\"), (\"AZ\", \"related_to_core\", \"pre-training supervision amount\"), (\"LV\", \"related_to_core\", \"pre-training supervision amount\"), (\"LN\", \"related_to_core\", \"pre-training supervision amount\"), (\"UR\", \"related_to_core\", \"pre-training supervision amount\"), (\"ID\", \"related_to_core\", \"pre-training supervision amount\"), (\"SD\", \"related_to_core\", \"pre-training supervision amount\"), (\"KO\", \"related_to_core\", \"pre-training supervision amount\"), (\"FI\", \"related_to_core\", \"pre-training supervision amount\"), (\"HU\", \"related_to_core\", \"pre-training supervision amount\"), (\"PT\", \"related_to_core\", \"pre-training supervision amount\"), (\"BN\", \"related_to_core\", \"pre-training supervision amount\"), (\"LO\", \"related_to_core\", \"pre-training supervision amount\"), (\"MT\", \"related_to_core\", \"pre-training supervision amount\"), (\"HA\", \"related_to_core\", \"pre-training supervision amount\"), (\"VI\", \"related_to_core\", \"pre-training supervision amount\"), (\"FRAF\", \"related_to_core\", \"pre-training supervision amount\"), (\"HE\", \"related_to_core\", \"pre-training supervision amount\"), (\"KK\", \"related_to_core\", \"pre-training supervision amount\"), (\"IS\", \"related_to_core\", \"pre-training supervision amount\"), (\"CA\", \"related_to_core\", \"pre-training supervision amount\"), (\"OC\", \"related_to_core\", \"pre-training supervision amount\"), (\"ET\", \"related_to_core\", \"pre-training supervision amount\"), (\"AS\", \"related_to_core\", \"pre-training supervision amount\"), (\"TG\", \"related_to_core\", \"pre-training supervision amount\"), (\"KM\", \"related_to_core\", \"pre-training supervision amount\"), (\"BE\", \"related_to_core\", \"pre-training supervision amount\"), (\"UZ\", \"related_to_core\", \"pre-training supervision amount\"), (\"FA\", \"related_to_core\", \"pre-training supervision amount\"), (\"UK\", \"related_to_core\", \"pre-training supervision amount\"), (\"RO\", \"related_to_core\", \"pre-training supervision amount\"), (\"GL\", \"related_to_core\", \"pre-training supervision amount\"), (\"FIL\", \"related_to_core\", \"pre-training supervision amount\"), (\"IT\", \"related_to_core\", \"pre-training supervision amount\"), (\"SV\", \"related_to_core\", \"pre-training supervision amount\"), (\"TE\", \"related_to_core\", \"pre-training supervision amount\"), (\"MR\", \"related_to_core\", \"pre-training supervision amount\"), (\"ML\", \"related_to_core\", \"pre-training supervision amount\"), (\"BG\", \"related_to_core\", \"pre-training supervision amount\"), (\"MI\", \"related_to_core\", \"pre-training supervision amount\"), (\"AR\", \"related_to_core\", \"pre-training supervision amount\"), (\"DA\", \"related_to_core\", \"pre-training supervision amount\"), (\"PA\", \"related_to_core\", \"pre-training supervision amount\"), (\"KN\", \"related_to_core\", \"pre-training supervision amount\"), (\"TH\", \"related_to_core\", \"pre-training supervision amount\"), (\"NE\", \"related_to_core\", \"pre-training supervision amount\"), (\"EL\", \"related_to_core\", \"pre-training supervision amount\"), (\"SW\", \"related_to_core\", \"pre-training supervision amount\"), (\"MY\", \"related_to_core\", \"pre-training supervision amount\"), (\"NL\", \"related_to_core\", \"pre-training supervision amount\"), (\"AM\", \"related_to_core\", \"pre-training supervision amount\"), (\"HR\", \"related_to_core\", \"pre-training supervision amount\"), (\"r2\", \"related_to_core\", \"pre-training supervision amount\"), (\"BLEU\", \"related_to_core\", \"pre-training supervision amount\"), (\"pre-training supervision amount\", \"is_core_idea\", \"true\"), (\"chunk_71\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('BLEU', 'mentions', 'BLEU'), ('chunk_71', 'mentions', 'BLEU'), ('r2', 'mentions', 'r2'), ('chunk_71', 'mentions', 'r2'), ('HR', 'mentions', 'HR'), ('chunk_71', 'mentions', 'HR'), ('AM', 'mentions', 'AM'), ('chunk_71', 'mentions', 'AM'), ('NL', 'mentions', 'NL'), ('chunk_71', 'mentions', 'NL'), ('MY', 'mentions', 'MY'), ('chunk_71', 'mentions', 'MY'), ('SW', 'mentions', 'SW'), ('chunk_71', 'mentions', 'SW'), ('EL', 'mentions', 'EL'), ('chunk_71', 'mentions', 'EL'), ('NE', 'mentions', 'NE'), ('chunk_71', 'mentions', 'NE'), ('TH', 'mentions', 'TH'), ('chunk_71', 'mentions', 'TH'), ('KN', 'mentions', 'KN'), ('chunk_71', 'mentions', 'KN'), ('PA', 'mentions', 'PA'), ('chunk_71', 'mentions', 'PA'), ('DA', 'mentions', 'DA'), ('chunk_71', 'mentions', 'DA'), ('AR', 'mentions', 'AR'), ('chunk_71', 'mentions', 'AR'), ('MI', 'mentions', 'MI'), ('chunk_71', 'mentions', 'MI'), ('BG', 'mentions', 'BG'), ('chunk_71', 'mentions', 'BG'), ('ML', 'mentions', 'ML'), ('chunk_71', 'mentions', 'ML'), ('MR', 'mentions', 'MR'), ('chunk_71', 'mentions', 'MR'), ('TE', 'mentions', 'TE'), ('chunk_71', 'mentions', 'TE'), ('SV', 'mentions', 'SV'), ('chunk_71', 'mentions', 'SV'), ('IT', 'mentions', 'IT'), ('chunk_71', 'mentions', 'IT'), ('FIL', 'mentions', 'FIL'), ('chunk_71', 'mentions', 'FIL'), ('GL', 'mentions', 'GL'), ('chunk_71', 'mentions', 'GL'), ('RO', 'mentions', 'RO'), ('chunk_71', 'mentions', 'RO'), ('UK', 'mentions', 'UK'), ('chunk_71', 'mentions', 'UK'), ('FA', 'mentions', 'FA'), ('chunk_71', 'mentions', 'FA'), ('UZ', 'mentions', 'UZ'), ('chunk_71', 'mentions', 'UZ'), ('BE', 'mentions', 'BE'), ('chunk_71', 'mentions', 'BE'), ('KM', 'mentions', 'KM'), ('chunk_71', 'mentions', 'KM'), ('TG', 'mentions', 'TG'), ('chunk_71', 'mentions', 'TG'), ('AS', 'mentions', 'AS'), ('chunk_71', 'mentions', 'AS'), ('ET', 'mentions', 'ET'), ('chunk_71', 'mentions', 'ET'), ('OC', 'mentions', 'OC'), ('chunk_71', 'mentions', 'OC'), ('CA', 'mentions', 'CA'), ('chunk_71', 'mentions', 'CA'), ('IS', 'mentions', 'IS'), ('chunk_71', 'mentions', 'IS'), ('KK', 'mentions', 'KK'), ('chunk_71', 'mentions', 'KK'), ('HE', 'mentions', 'HE'), ('chunk_71', 'mentions', 'HE'), ('FRAF', 'mentions', 'FRAF'), ('chunk_71', 'mentions', 'FRAF'), ('VI', 'mentions', 'VI'), ('chunk_71', 'mentions', 'VI'), ('HA', 'mentions', 'HA'), ('chunk_71', 'mentions', 'HA'), ('MT', 'mentions', 'MT'), ('chunk_71', 'mentions', 'MT'), ('LO', 'mentions', 'LO'), ('chunk_71', 'mentions', 'LO'), ('BN', 'mentions', 'BN'), ('chunk_71', 'mentions', 'BN'), ('PT', 'mentions', 'PT'), ('chunk_71', 'mentions', 'PT'), ('HU', 'mentions', 'HU'), ('chunk_71', 'mentions', 'HU'), ('FI', 'mentions', 'FI'), ('chunk_71', 'mentions', 'FI'), ('KO', 'mentions', 'KO'), ('chunk_71', 'mentions', 'KO'), ('SD', 'mentions', 'SD'), ('chunk_71', 'mentions', 'SD'), ('ID', 'mentions', 'ID'), ('chunk_71', 'mentions', 'ID'), ('UR', 'mentions', 'UR'), ('chunk_71', 'mentions', 'UR'), ('LN', 'mentions', 'LN'), ('chunk_71', 'mentions', 'LN'), ('LV', 'mentions', 'LV'), ('chunk_71', 'mentions', 'LV'), ('AZ', 'mentions', 'AZ'), ('chunk_71', 'mentions', 'AZ'), ('YO', 'mentions', 'YO'), ('chunk_71', 'mentions', 'YO'), ('LB', 'mentions', 'LB'), ('chunk_71', 'mentions', 'LB'), ('CY', 'mentions', 'CY'), ('chunk_71', 'mentions', 'CY'), ('HY', 'mentions', 'HY'), ('chunk_71', 'mentions', 'HY'), ('PL', 'mentions', 'PL'), ('chunk_71', 'mentions', 'PL'), ('LT', 'mentions', 'LT'), ('chunk_71', 'mentions', 'LT'), ('DE', 'mentions', 'DE'), ('chunk_71', 'mentions', 'DE'), ('KA', 'mentions', 'KA'), ('chunk_71', 'mentions', 'KA'), ('RU', 'mentions', 'RU'), ('chunk_71', 'mentions', 'RU'), ('MK', 'mentions', 'MK'), ('chunk_71', 'mentions', 'MK'), ('MS', 'mentions', 'MS'), ('chunk_71', 'mentions', 'MS'), ('SR', 'mentions', 'SR'), ('chunk_71', 'mentions', 'SR'), ('ES', 'mentions', 'ES'), ('chunk_71', 'mentions', 'ES'), ('ZH', 'mentions', 'ZH'), ('chunk_71', 'mentions', 'ZH'), ('JA', 'mentions', 'JA'), ('chunk_71', 'mentions', 'JA'), ('NBBS', 'mentions', 'NBBS'), ('chunk_71', 'mentions', 'NBBS'), ('MN', 'mentions', 'MN'), ('chunk_71', 'mentions', 'MN'), ('SN', 'mentions', 'SN'), ('chunk_71', 'mentions', 'SN'), ('TR', 'mentions', 'TR'), ('chunk_71', 'mentions', 'TR'), ('PS', 'mentions', 'PS'), ('chunk_71', 'mentions', 'PS'), ('SK', 'mentions', 'SK'), ('chunk_71', 'mentions', 'SK'), ('SO', 'mentions', 'SO'), ('chunk_71', 'mentions', 'SO'), ('CS', 'mentions', 'CS'), ('chunk_71', 'mentions', 'CS'), ('SL', 'mentions', 'SL'), ('chunk_71', 'mentions', 'SL'), ('HI', 'mentions', 'HI'), ('chunk_71', 'mentions', 'HI'), ('GU', 'mentions', 'GU'), ('chunk_71', 'mentions', 'GU'), ('TA', 'mentions', 'TA'), ('chunk_71', 'mentions', 'TA'), ('pre-training supervision amount', 'mentions', 'pre-training supervision amount'), ('chunk_71', 'mentions', 'pre-training supervision amount'), ('downstream translation performance', 'mentions', 'downstream translation performance'), ('chunk_71', 'mentions', 'downstream translation performance'), ('pre-training translation data', 'mentions', 'pre-training translation data'), ('chunk_71', 'mentions', 'pre-training translation data'), ('language', 'mentions', 'language'), ('chunk_71', 'mentions', 'language'), ('downstream translation performance', 'related_to_core', 'pre-training supervision amount'), ('pre-training translation data', 'related_to_core', 'pre-training supervision amount'), ('language', 'related_to_core', 'pre-training supervision amount'), ('TA', 'related_to_core', 'pre-training supervision amount'), ('GU', 'related_to_core', 'pre-training supervision amount'), ('HI', 'related_to_core', 'pre-training supervision amount'), ('SL', 'related_to_core', 'pre-training supervision amount'), ('CS', 'related_to_core', 'pre-training supervision amount'), ('SO', 'related_to_core', 'pre-training supervision amount'), ('SK', 'related_to_core', 'pre-training supervision amount'), ('PS', 'related_to_core', 'pre-training supervision amount'), ('TR', 'related_to_core', 'pre-training supervision amount'), ('SN', 'related_to_core', 'pre-training supervision amount'), ('MN', 'related_to_core', 'pre-training supervision amount'), ('NBBS', 'related_to_core', 'pre-training supervision amount'), ('JA', 'related_to_core', 'pre-training supervision amount'), ('ZH', 'related_to_core', 'pre-training supervision amount'), ('ES', 'related_to_core', 'pre-training supervision amount'), ('SR', 'related_to_core', 'pre-training supervision amount'), ('MS', 'related_to_core', 'pre-training supervision amount'), ('MK', 'related_to_core', 'pre-training supervision amount'), ('RU', 'related_to_core', 'pre-training supervision amount'), ('KA', 'related_to_core', 'pre-training supervision amount'), ('DE', 'related_to_core', 'pre-training supervision amount'), ('LT', 'related_to_core', 'pre-training supervision amount'), ('PL', 'related_to_core', 'pre-training supervision amount'), ('HY', 'related_to_core', 'pre-training supervision amount'), ('CY', 'related_to_core', 'pre-training supervision amount'), ('LB', 'related_to_core', 'pre-training supervision amount'), ('YO', 'related_to_core', 'pre-training supervision amount'), ('AZ', 'related_to_core', 'pre-training supervision amount'), ('LV', 'related_to_core', 'pre-training supervision amount'), ('LN', 'related_to_core', 'pre-training supervision amount'), ('UR', 'related_to_core', 'pre-training supervision amount'), ('ID', 'related_to_core', 'pre-training supervision amount'), ('SD', 'related_to_core', 'pre-training supervision amount'), ('KO', 'related_to_core', 'pre-training supervision amount'), ('FI', 'related_to_core', 'pre-training supervision amount'), ('HU', 'related_to_core', 'pre-training supervision amount'), ('PT', 'related_to_core', 'pre-training supervision amount'), ('BN', 'related_to_core', 'pre-training supervision amount'), ('LO', 'related_to_core', 'pre-training supervision amount'), ('MT', 'related_to_core', 'pre-training supervision amount'), ('HA', 'related_to_core', 'pre-training supervision amount'), ('VI', 'related_to_core', 'pre-training supervision amount'), ('FRAF', 'related_to_core', 'pre-training supervision amount'), ('HE', 'related_to_core', 'pre-training supervision amount'), ('KK', 'related_to_core', 'pre-training supervision amount'), ('IS', 'related_to_core', 'pre-training supervision amount'), ('CA', 'related_to_core', 'pre-training supervision amount'), ('OC', 'related_to_core', 'pre-training supervision amount'), ('ET', 'related_to_core', 'pre-training supervision amount'), ('AS', 'related_to_core', 'pre-training supervision amount'), ('TG', 'related_to_core', 'pre-training supervision amount'), ('KM', 'related_to_core', 'pre-training supervision amount'), ('BE', 'related_to_core', 'pre-training supervision amount'), ('UZ', 'related_to_core', 'pre-training supervision amount'), ('FA', 'related_to_core', 'pre-training supervision amount'), ('UK', 'related_to_core', 'pre-training supervision amount'), ('RO', 'related_to_core', 'pre-training supervision amount'), ('GL', 'related_to_core', 'pre-training supervision amount'), ('FIL', 'related_to_core', 'pre-training supervision amount'), ('IT', 'related_to_core', 'pre-training supervision amount'), ('SV', 'related_to_core', 'pre-training supervision amount'), ('TE', 'related_to_core', 'pre-training supervision amount'), ('MR', 'related_to_core', 'pre-training supervision amount'), ('ML', 'related_to_core', 'pre-training supervision amount'), ('BG', 'related_to_core', 'pre-training supervision amount'), ('MI', 'related_to_core', 'pre-training supervision amount'), ('AR', 'related_to_core', 'pre-training supervision amount'), ('DA', 'related_to_core', 'pre-training supervision amount'), ('PA', 'related_to_core', 'pre-training supervision amount'), ('KN', 'related_to_core', 'pre-training supervision amount'), ('TH', 'related_to_core', 'pre-training supervision amount'), ('NE', 'related_to_core', 'pre-training supervision amount'), ('EL', 'related_to_core', 'pre-training supervision amount'), ('SW', 'related_to_core', 'pre-training supervision amount'), ('MY', 'related_to_core', 'pre-training supervision amount'), ('NL', 'related_to_core', 'pre-training supervision amount'), ('AM', 'related_to_core', 'pre-training supervision amount'), ('HR', 'related_to_core', 'pre-training supervision amount'), ('r2', 'related_to_core', 'pre-training supervision amount'), ('BLEU', 'related_to_core', 'pre-training supervision amount'), ('pre-training supervision amount', 'is_core_idea', 'true'), ('chunk_71', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_72...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Whisper\", \"zero-shot performance\", \"language\"), (\"language\", \"is_in\", \"Fleurs\"), (\"Indo-European language family\", \"is_a\", \"language family\"), (\"high-resource languages\", \"is_a\", \"language\"), (\"benchmarks\", \"provide\", \"coverage\"), (\"Whisper models\", \"has\", \"multi-lingual capabilities\"), (\"speech recognition\", \"is_in\", \"75 languages\"), (\"Whisper\", \"performance\", \"Fleurs dataset\"), (\"chunk_72\", \"mentions\", \"Whisper\"), (\"chunk_72\", \"mentions\", \"language\"), (\"chunk_72\", \"mentions\", \"Fleurs\"), (\"chunk_72\", \"mentions\", \"Indo-European language family\"), (\"chunk_72\", \"mentions\", \"high-resource languages\"), (\"chunk_72\", \"mentions\", \"benchmarks\"), (\"chunk_72\", \"mentions\", \"Whisper models\"), (\"chunk_72\", \"mentions\", \"speech recognition\"), (\"chunk_72\", \"mentions\", \"75 languages\"), (\"chunk_72\", \"mentions\", \"Fleurs dataset\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_72\", \"is_core_chunk\", \"true\"), (\"language\", \"related_to_core\", \"Whisper\"), (\"Fleurs\", \"related_to_core\", \"Whisper\"), (\"Indo-European language family\", \"related_to_core\", \"Whisper\"), (\"high-resource languages\", \"related_to_core\", \"Whisper\"), (\"benchmarks\", \"related_to_core\", \"Whisper\"), (\"Whisper models\", \"related_to_core\", \"Whisper\"), (\"speech recognition\", \"related_to_core\", \"Whisper\"), (\"75 languages\", \"related_to_core\", \"Whisper\"), (\"Fleurs dataset\", \"related_to_core\", \"Whisper\")]\n",
            "✅ Extracted: [('Whisper', 'zero-shot performance', 'language'), ('language', 'is_in', 'Fleurs'), ('Indo-European language family', 'is_a', 'language family'), ('high-resource languages', 'is_a', 'language'), ('benchmarks', 'provide', 'coverage'), ('Whisper models', 'has', 'multi-lingual capabilities'), ('speech recognition', 'is_in', '75 languages'), ('Whisper', 'performance', 'Fleurs dataset'), ('chunk_72', 'mentions', 'Whisper'), ('chunk_72', 'mentions', 'language'), ('chunk_72', 'mentions', 'Fleurs'), ('chunk_72', 'mentions', 'Indo-European language family'), ('chunk_72', 'mentions', 'high-resource languages'), ('chunk_72', 'mentions', 'benchmarks'), ('chunk_72', 'mentions', 'Whisper models'), ('chunk_72', 'mentions', 'speech recognition'), ('chunk_72', 'mentions', '75 languages'), ('chunk_72', 'mentions', 'Fleurs dataset'), ('Whisper', 'is_core_idea', 'true'), ('chunk_72', 'is_core_chunk', 'true'), ('language', 'related_to_core', 'Whisper'), ('Fleurs', 'related_to_core', 'Whisper'), ('Indo-European language family', 'related_to_core', 'Whisper'), ('high-resource languages', 'related_to_core', 'Whisper'), ('benchmarks', 'related_to_core', 'Whisper'), ('Whisper models', 'related_to_core', 'Whisper'), ('speech recognition', 'related_to_core', 'Whisper'), ('75 languages', 'related_to_core', 'Whisper'), ('Fleurs dataset', 'related_to_core', 'Whisper')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_73...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"training data\", \"related_to_core\", \"zero-shot performance\"), (\"language\", \"related_to_core\", \"zero-shot performance\"), (\"zero-shot performance\", \"is_core_idea\", \"true\"), (\"word error rate\", \"related_to_core\", \"zero-shot performance\"), (\"training data\", \"relation\", \"zero-shot performance\"), (\"language\", \"relation\", \"zero-shot performance\"), (\"Figure 3\", \"related_to_core\", \"zero-shot performance\"), (\"squared correlation coefﬁcient\", \"related_to_core\", \"zero-shot performance\"), (\"word error rate\", \"relation\", \"training data\"), (\"language\", \"relation\", \"training data\"), (\"regression coefﬁcient\", \"related_to_core\", \"zero-shot performance\"), (\"linear ﬁt\", \"related_to_core\", \"zero-shot performance\"), (\"chunk_73\", \"mentions\", \"training data\"), (\"chunk_73\", \"mentions\", \"language\"), (\"chunk_73\", \"mentions\", \"zero-shot performance\"), (\"chunk_73\", \"mentions\", \"Figure 3\"), (\"chunk_73\", \"mentions\", \"squared correlation coefﬁcient\"), (\"chunk_73\", \"mentions\", \"word error rate\"), (\"chunk_73\", \"mentions\", \"regression coefﬁcient\"), (\"chunk_73\", \"mentions\", \"linear ﬁt\"), (\"chunk_73\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('training data', 'related_to_core', 'zero-shot performance'), ('language', 'related_to_core', 'zero-shot performance'), ('zero-shot performance', 'is_core_idea', 'true'), ('word error rate', 'related_to_core', 'zero-shot performance'), ('training data', 'relation', 'zero-shot performance'), ('language', 'relation', 'zero-shot performance'), ('Figure 3', 'related_to_core', 'zero-shot performance'), ('squared correlation coefﬁcient', 'related_to_core', 'zero-shot performance'), ('word error rate', 'relation', 'training data'), ('language', 'relation', 'training data'), ('regression coefﬁcient', 'related_to_core', 'zero-shot performance'), ('linear ﬁt', 'related_to_core', 'zero-shot performance'), ('chunk_73', 'mentions', 'training data'), ('chunk_73', 'mentions', 'language'), ('chunk_73', 'mentions', 'zero-shot performance'), ('chunk_73', 'mentions', 'Figure 3'), ('chunk_73', 'mentions', 'squared correlation coefﬁcient'), ('chunk_73', 'mentions', 'word error rate'), ('chunk_73', 'mentions', 'regression coefﬁcient'), ('chunk_73', 'mentions', 'linear ﬁt'), ('chunk_73', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_74...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"WER\", \"halves_with\", \"16×increase in training data\"), (\"chunk_74\", \"mentions\", \"WER\"), (\"chunk_74\", \"mentions\", \"training data\"), (\"chunk_74\", \"mentions\", \"outliers\"), (\"chunk_74\", \"mentions\", \"performance\"), (\"chunk_74\", \"mentions\", \"languages\"), (\"chunk_74\", \"mentions\", \"scripts\"), (\"chunk_74\", \"mentions\", \"Indo-European languages\"), (\"chunk_74\", \"mentions\", \"Hebrew\"), (\"chunk_74\", \"mentions\", \"Telugu\"), (\"chunk_74\", \"mentions\", \"Chinese\"), (\"chunk_74\", \"mentions\", \"Korean\"), (\"chunk_74\", \"mentions\", \"linguistic distance\"), (\"outliers\", \"have\", \"worse than expected performance\"), (\"languages\", \"have\", \"unique scripts\"), (\"languages\", \"are\", \"distantly related to Indo-European languages\"), (\"Hebrew\", \"is_a\", \"language\"), (\"Telugu\", \"is_a\", \"language\"), (\"Chinese\", \"is_a\", \"language\"), (\"Korean\", \"is_a\", \"language\"), (\"languages\", \"cause\", \"lack of transfer due to linguistic distance\"), (\"WER\", \"is_core_idea\", \"true\"), (\"chunk_74\", \"is_core_chunk\", \"true\"), (\"training data\", \"related_to_core\", \"WER\"), (\"outliers\", \"related_to_core\", \"WER\"), (\"performance\", \"related_to_core\", \"WER\"), (\"languages\", \"related_to_core\", \"WER\"), (\"scripts\", \"related_to_core\", \"WER\"), (\"Indo-European languages\", \"related_to_core\", \"WER\"), (\"Hebrew\", \"related_to_core\", \"WER\"), (\"Telugu\", \"related_to_core\", \"WER\"), (\"Chinese\", \"related_to_core\", \"WER\"), (\"Korean\", \"related_to_core\", \"WER\"), (\"linguistic distance\", \"related_to_core\", \"WER\")]\n",
            "✅ Extracted: [('WER', 'halves_with', '16×increase in training data'), ('chunk_74', 'mentions', 'WER'), ('chunk_74', 'mentions', 'training data'), ('chunk_74', 'mentions', 'outliers'), ('chunk_74', 'mentions', 'performance'), ('chunk_74', 'mentions', 'languages'), ('chunk_74', 'mentions', 'scripts'), ('chunk_74', 'mentions', 'Indo-European languages'), ('chunk_74', 'mentions', 'Hebrew'), ('chunk_74', 'mentions', 'Telugu'), ('chunk_74', 'mentions', 'Chinese'), ('chunk_74', 'mentions', 'Korean'), ('chunk_74', 'mentions', 'linguistic distance'), ('outliers', 'have', 'worse than expected performance'), ('languages', 'have', 'unique scripts'), ('languages', 'are', 'distantly related to Indo-European languages'), ('Hebrew', 'is_a', 'language'), ('Telugu', 'is_a', 'language'), ('Chinese', 'is_a', 'language'), ('Korean', 'is_a', 'language'), ('languages', 'cause', 'lack of transfer due to linguistic distance'), ('WER', 'is_core_idea', 'true'), ('chunk_74', 'is_core_chunk', 'true'), ('training data', 'related_to_core', 'WER'), ('outliers', 'related_to_core', 'WER'), ('performance', 'related_to_core', 'WER'), ('languages', 'related_to_core', 'WER'), ('scripts', 'related_to_core', 'WER'), ('Indo-European languages', 'related_to_core', 'WER'), ('Hebrew', 'related_to_core', 'WER'), ('Telugu', 'related_to_core', 'WER'), ('Chinese', 'related_to_core', 'WER'), ('Korean', 'related_to_core', 'WER'), ('linguistic distance', 'related_to_core', 'WER')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_75...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"byte level BPE tokenizer\", \"mentions\", \"languages\"), (\"byte level BPE tokenizer\", \"mentions\", \"data quality\"), (\"languages\", \"related_to_core\", \"byte level BPE tokenizer\"), (\"data quality\", \"related_to_core\", \"byte level BPE tokenizer\"), (\"byte level BPE tokenizer\", \"is_core_idea\", \"true\"), (\"chunk_75\", \"is_core_chunk\", \"true\"), (\"chunk_75\", \"mentions\", \"byte level BPE tokenizer\"), (\"chunk_75\", \"mentions\", \"languages\"), (\"chunk_75\", \"mentions\", \"data quality\")]\n",
            "✅ Extracted: [('byte level BPE tokenizer', 'mentions', 'languages'), ('byte level BPE tokenizer', 'mentions', 'data quality'), ('languages', 'related_to_core', 'byte level BPE tokenizer'), ('data quality', 'related_to_core', 'byte level BPE tokenizer'), ('byte level BPE tokenizer', 'is_core_idea', 'true'), ('chunk_75', 'is_core_chunk', 'true'), ('chunk_75', 'mentions', 'byte level BPE tokenizer'), ('chunk_75', 'mentions', 'languages'), ('chunk_75', 'mentions', 'data quality')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_76...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_76\", \"is_core_chunk\", \"true\"), (\"Robust Speech Recognition\", \"mentions\", \"Robust Speech Recognition\"), (\"chunk_76\", \"mentions\", \"English\"), (\"chunk_76\", \"mentions\", \"XMEF-X\"), (\"chunk_76\", \"mentions\", \"XLS-R (2B)\"), (\"chunk_76\", \"mentions\", \"mSLAM-CTC (2B)\"), (\"chunk_76\", \"mentions\", \"Maestro\"), (\"chunk_76\", \"mentions\", \"Zero-Shot Whisper\"), (\"chunk_76\", \"mentions\", \"Speech translation\"), (\"chunk_76\", \"mentions\", \"CoV oST2\"), (\"XMEF-X\", \"related_to_core\", \"Robust Speech Recognition\"), (\"XLS-R (2B)\", \"related_to_core\", \"Robust Speech Recognition\"), (\"mSLAM-CTC (2B)\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Maestro\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Zero-Shot Whisper\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Speech translation\", \"related_to_core\", \"Robust Speech Recognition\"), (\"CoV oST2\", \"related_to_core\", \"Robust Speech Recognition\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'is_core_idea', 'true'), ('chunk_76', 'is_core_chunk', 'true'), ('Robust Speech Recognition', 'mentions', 'Robust Speech Recognition'), ('chunk_76', 'mentions', 'English'), ('chunk_76', 'mentions', 'XMEF-X'), ('chunk_76', 'mentions', 'XLS-R (2B)'), ('chunk_76', 'mentions', 'mSLAM-CTC (2B)'), ('chunk_76', 'mentions', 'Maestro'), ('chunk_76', 'mentions', 'Zero-Shot Whisper'), ('chunk_76', 'mentions', 'Speech translation'), ('chunk_76', 'mentions', 'CoV oST2'), ('XMEF-X', 'related_to_core', 'Robust Speech Recognition'), ('XLS-R (2B)', 'related_to_core', 'Robust Speech Recognition'), ('mSLAM-CTC (2B)', 'related_to_core', 'Robust Speech Recognition'), ('Maestro', 'related_to_core', 'Robust Speech Recognition'), ('Zero-Shot Whisper', 'related_to_core', 'Robust Speech Recognition'), ('Speech translation', 'related_to_core', 'Robust Speech Recognition'), ('CoV oST2', 'related_to_core', 'Robust Speech Recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_77...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"supervised work\", \"is_core_idea\", \"true\"), (\"chunk_77\", \"is_core_chunk\", \"true\"), (\"Language ID Fleurs\", \"related_to_core\", \"supervised work\"), (\"w2v-bert-51 (0.6B)\", \"related_to_core\", \"supervised work\"), (\"mSLAM-CTC (2B)\", \"related_to_core\", \"supervised work\"), (\"Zero-shot Whisper\", \"related_to_core\", \"supervised work\"), (\"language identiﬁcation\", \"related_to_core\", \"supervised work\"), (\"Fleurs languages\", \"related_to_core\", \"supervised work\"), (\"Translation\", \"related_to_core\", \"supervised work\"), (\"Whisper models\", \"related_to_core\", \"supervised work\"), (\"chunk_77\", \"mentions\", \"supervised work\"), (\"chunk_77\", \"mentions\", \"Language ID Fleurs\"), (\"chunk_77\", \"mentions\", \"w2v-bert-51 (0.6B)\"), (\"chunk_77\", \"mentions\", \"mSLAM-CTC (2B)\"), (\"chunk_77\", \"mentions\", \"Zero-shot Whisper\"), (\"chunk_77\", \"mentions\", \"language identiﬁcation\"), (\"chunk_77\", \"mentions\", \"Fleurs languages\"), (\"chunk_77\", \"mentions\", \"Translation\"), (\"chunk_77\", \"mentions\", \"Whisper models\")]\n",
            "✅ Extracted: [('supervised work', 'is_core_idea', 'true'), ('chunk_77', 'is_core_chunk', 'true'), ('Language ID Fleurs', 'related_to_core', 'supervised work'), ('w2v-bert-51 (0.6B)', 'related_to_core', 'supervised work'), ('mSLAM-CTC (2B)', 'related_to_core', 'supervised work'), ('Zero-shot Whisper', 'related_to_core', 'supervised work'), ('language identiﬁcation', 'related_to_core', 'supervised work'), ('Fleurs languages', 'related_to_core', 'supervised work'), ('Translation', 'related_to_core', 'supervised work'), ('Whisper models', 'related_to_core', 'supervised work'), ('chunk_77', 'mentions', 'supervised work'), ('chunk_77', 'mentions', 'Language ID Fleurs'), ('chunk_77', 'mentions', 'w2v-bert-51 (0.6B)'), ('chunk_77', 'mentions', 'mSLAM-CTC (2B)'), ('chunk_77', 'mentions', 'Zero-shot Whisper'), ('chunk_77', 'mentions', 'language identiﬁcation'), ('chunk_77', 'mentions', 'Fleurs languages'), ('chunk_77', 'mentions', 'Translation'), ('chunk_77', 'mentions', 'Whisper models')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_78...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"X→en subset\", \"part_of\", \"CoV oST2\"), (\"chunk_78\", \"mentions\", \"X→en subset\"), (\"chunk_78\", \"mentions\", \"CoV oST2\"), (\"chunk_78\", \"mentions\", \"Maestro\"), (\"chunk_78\", \"mentions\", \"mSLAM\"), (\"chunk_78\", \"mentions\", \"XLS-R\"), (\"chunk_78\", \"mentions\", \"BLEU\"), (\"chunk_78\", \"mentions\", \"X→en translation data\"), (\"chunk_78\", \"mentions\", \"training data\"), (\"Maestro\", \"related_to_core\", \"BLEU\"), (\"mSLAM\", \"related_to_core\", \"BLEU\"), (\"XLS-R\", \"related_to_core\", \"BLEU\"), (\"X→en subset\", \"related_to_core\", \"BLEU\"), (\"CoV oST2\", \"related_to_core\", \"BLEU\"), (\"X→en translation data\", \"related_to_core\", \"BLEU\"), (\"training data\", \"related_to_core\", \"BLEU\"), (\"BLEU\", \"is_core_idea\", \"true\"), (\"chunk_78\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('X→en subset', 'part_of', 'CoV oST2'), ('chunk_78', 'mentions', 'X→en subset'), ('chunk_78', 'mentions', 'CoV oST2'), ('chunk_78', 'mentions', 'Maestro'), ('chunk_78', 'mentions', 'mSLAM'), ('chunk_78', 'mentions', 'XLS-R'), ('chunk_78', 'mentions', 'BLEU'), ('chunk_78', 'mentions', 'X→en translation data'), ('chunk_78', 'mentions', 'training data'), ('Maestro', 'related_to_core', 'BLEU'), ('mSLAM', 'related_to_core', 'BLEU'), ('XLS-R', 'related_to_core', 'BLEU'), ('X→en subset', 'related_to_core', 'BLEU'), ('CoV oST2', 'related_to_core', 'BLEU'), ('X→en translation data', 'related_to_core', 'BLEU'), ('training data', 'related_to_core', 'BLEU'), ('BLEU', 'is_core_idea', 'true'), ('chunk_78', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_79...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"X→en translation\", \"in\", \"CoV oST2\"), (\"chunk_79\", \"mentions\", \"X→en translation\"), (\"chunk_79\", \"mentions\", \"CoV oST2\"), (\"Whisper evaluation\", \"is\", \"zero-shot\"), (\"chunk_79\", \"mentions\", \"Whisper evaluation\"), (\"Whisper evaluation\", \"does well on\", \"CoV oST2\"), (\"mSLAM\", \"improved by\", \"BLEU\"), (\"chunk_79\", \"mentions\", \"mSLAM\"), (\"chunk_79\", \"mentions\", \"BLEU\"), (\"Whisper model\", \"does not improve over\", \"Maestro\"), (\"Whisper model\", \"does not improve over\", \"mSLAM\"), (\"chunk_79\", \"mentions\", \"Whisper model\"), (\"chunk_79\", \"mentions\", \"Maestro\"), (\"analysis\", \"on\", \"set of languages\"), (\"chunk_79\", \"mentions\", \"analysis\"), (\"chunk_79\", \"mentions\", \"set of languages\"), (\"Fleurs\", \"is\", \"speech recognition dataset\"), (\"Fleurs\", \"as\", \"translation dataset\"), (\"chunk_79\", \"mentions\", \"Fleurs\"), (\"speech recognition dataset\", \"as\", \"translation dataset\"), (\"chunk_79\", \"mentions\", \"speech recognition dataset\"), (\"translation dataset\", \"related_to_core\", \"X→en translation\"), (\"CoV oST2\", \"related_to_core\", \"X→en translation\"), (\"Whisper evaluation\", \"related_to_core\", \"X→en translation\"), (\"mSLAM\", \"related_to_core\", \"X→en translation\"), (\"BLEU\", \"related_to_core\", \"X→en translation\"), (\"Whisper model\", \"related_to_core\", \"X→en translation\"), (\"Maestro\", \"related_to_core\", \"X→en translation\"), (\"analysis\", \"related_to_core\", \"X→en translation\"), (\"set of languages\", \"related_to_core\", \"X→en translation\"), (\"Fleurs\", \"related_to_core\", \"X→en translation\"), (\"speech recognition dataset\", \"related_to_core\", \"X→en translation\"), (\"X→en translation\", \"is_core_idea\", \"true\"), (\"chunk_79\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('X→en translation', 'in', 'CoV oST2'), ('chunk_79', 'mentions', 'X→en translation'), ('chunk_79', 'mentions', 'CoV oST2'), ('Whisper evaluation', 'is', 'zero-shot'), ('chunk_79', 'mentions', 'Whisper evaluation'), ('Whisper evaluation', 'does well on', 'CoV oST2'), ('mSLAM', 'improved by', 'BLEU'), ('chunk_79', 'mentions', 'mSLAM'), ('chunk_79', 'mentions', 'BLEU'), ('Whisper model', 'does not improve over', 'Maestro'), ('Whisper model', 'does not improve over', 'mSLAM'), ('chunk_79', 'mentions', 'Whisper model'), ('chunk_79', 'mentions', 'Maestro'), ('analysis', 'on', 'set of languages'), ('chunk_79', 'mentions', 'analysis'), ('chunk_79', 'mentions', 'set of languages'), ('Fleurs', 'is', 'speech recognition dataset'), ('Fleurs', 'as', 'translation dataset'), ('chunk_79', 'mentions', 'Fleurs'), ('speech recognition dataset', 'as', 'translation dataset'), ('chunk_79', 'mentions', 'speech recognition dataset'), ('translation dataset', 'related_to_core', 'X→en translation'), ('CoV oST2', 'related_to_core', 'X→en translation'), ('Whisper evaluation', 'related_to_core', 'X→en translation'), ('mSLAM', 'related_to_core', 'X→en translation'), ('BLEU', 'related_to_core', 'X→en translation'), ('Whisper model', 'related_to_core', 'X→en translation'), ('Maestro', 'related_to_core', 'X→en translation'), ('analysis', 'related_to_core', 'X→en translation'), ('set of languages', 'related_to_core', 'X→en translation'), ('Fleurs', 'related_to_core', 'X→en translation'), ('speech recognition dataset', 'related_to_core', 'X→en translation'), ('X→en translation', 'is_core_idea', 'true'), ('chunk_79', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_80...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"English\", \"is_core_idea\", \"true\"), (\"chunk_80\", \"is_core_chunk\", \"true\"), (\"chunk_80\", \"mentions\", \"English\"), (\"language\", \"related_to_core\", \"English\"), (\"language\", \"related_to_core\", \"English\"), (\"reference translations\", \"related_to_core\", \"English\"), (\"Figure 4\", \"related_to_core\", \"English\"), (\"correlation\", \"related_to_core\", \"English\"), (\"translation training data\", \"related_to_core\", \"English\"), (\"language\", \"related_to_core\", \"English\"), (\"zero-shot BLEU score\", \"related_to_core\", \"English\"), (\"Fleurs\", \"related_to_core\", \"English\"), (\"training data\", \"related_to_core\", \"English\"), (\"squared correlation coefﬁcient\", \"related_to_core\", \"English\"), (\"speech recognition\", \"related_to_core\", \"English\"), (\"signal-to-noise ratio\", \"related_to_core\", \"English\"), (\"English\", \"type\", \"language\"), (\"translation training data\", \"predicate\", \"amount of\"), (\"zero-shot BLEU score\", \"predicate\", \"resulting\"), (\"squared correlation coefﬁcient\", \"predicate\", \"lower than\"), (\"chunk_80\", \"mentions\", \"language\"), (\"chunk_80\", \"mentions\", \"reference translations\"), (\"chunk_80\", \"mentions\", \"Figure 4\"), (\"chunk_80\", \"mentions\", \"correlation\"), (\"chunk_80\", \"mentions\", \"translation training data\"), (\"chunk_80\", \"mentions\", \"zero-shot BLEU score\"), (\"chunk_80\", \"mentions\", \"Fleurs\"), (\"chunk_80\", \"mentions\", \"training data\"), (\"chunk_80\", \"mentions\", \"squared correlation coefﬁcient\"), (\"chunk_80\", \"mentions\", \"speech recognition\"), (\"chunk_80\", \"mentions\", \"signal-to-noise ratio\"), (\"language\", \"type\", \"concept\"), (\"reference translations\", \"type\", \"concept\"), (\"Figure 4\", \"type\", \"figure\"), (\"correlation\", \"type\", \"statistical measure\"), (\"translation training data\", \"type\", \"dataset\"), (\"zero-shot BLEU score\", \"type\", \"metric\"), (\"Fleurs\", \"type\", \"dataset\"), (\"training data\", \"type\", \"dataset\"), (\"squared correlation coefﬁcient\", \"type\", \"statistical measure\"), (\"speech recognition\", \"type\", \"task\"), (\"signal-to-noise ratio\", \"type\", \"metric\")]\n",
            "✅ Extracted: [('English', 'is_core_idea', 'true'), ('chunk_80', 'is_core_chunk', 'true'), ('chunk_80', 'mentions', 'English'), ('language', 'related_to_core', 'English'), ('language', 'related_to_core', 'English'), ('reference translations', 'related_to_core', 'English'), ('Figure 4', 'related_to_core', 'English'), ('correlation', 'related_to_core', 'English'), ('translation training data', 'related_to_core', 'English'), ('language', 'related_to_core', 'English'), ('zero-shot BLEU score', 'related_to_core', 'English'), ('Fleurs', 'related_to_core', 'English'), ('training data', 'related_to_core', 'English'), ('squared correlation coefﬁcient', 'related_to_core', 'English'), ('speech recognition', 'related_to_core', 'English'), ('signal-to-noise ratio', 'related_to_core', 'English'), ('English', 'type', 'language'), ('translation training data', 'predicate', 'amount of'), ('zero-shot BLEU score', 'predicate', 'resulting'), ('squared correlation coefﬁcient', 'predicate', 'lower than'), ('chunk_80', 'mentions', 'language'), ('chunk_80', 'mentions', 'reference translations'), ('chunk_80', 'mentions', 'Figure 4'), ('chunk_80', 'mentions', 'correlation'), ('chunk_80', 'mentions', 'translation training data'), ('chunk_80', 'mentions', 'zero-shot BLEU score'), ('chunk_80', 'mentions', 'Fleurs'), ('chunk_80', 'mentions', 'training data'), ('chunk_80', 'mentions', 'squared correlation coefﬁcient'), ('chunk_80', 'mentions', 'speech recognition'), ('chunk_80', 'mentions', 'signal-to-noise ratio'), ('language', 'type', 'concept'), ('reference translations', 'type', 'concept'), ('Figure 4', 'type', 'figure'), ('correlation', 'type', 'statistical measure'), ('translation training data', 'type', 'dataset'), ('zero-shot BLEU score', 'type', 'metric'), ('Fleurs', 'type', 'dataset'), ('training data', 'type', 'dataset'), ('squared correlation coefﬁcient', 'type', 'statistical measure'), ('speech recognition', 'type', 'task'), ('signal-to-noise ratio', 'type', 'metric')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_81...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"signal-to-noise ratio (dB)\", \"is_core_idea\", \"true\"), (\"chunk_81\", \"is_core_chunk\", \"true\"), (\"WER on LibriSpeech test-clean (%)\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"white noise\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"pub noise\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"unispeech-sat-base-100h-libri-ft\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"wav2vec2-base-100h\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"wav2vec2-base-960h\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"wav2vec2-large-960h\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"wav2vec2-large-robust-ft-libri-960h\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"wav2vec2-large-960h-lv60-self\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"asr-crdnn-rnnlm-librispeech\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"asr-transformer-transformerlm-librispeech\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"hubert-large-ls960-ft\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"hubert-xlarge-ls960-ft\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"s2t-medium-librispeech-asr\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"s2t-large-librispeech-asr\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"stt_en_conformer_ctc_large\", \"related_to_core\", \"signal-to-noise ratio (dB)\"), (\"chunk_81\", \"mentions\", \"signal-to-noise ratio (dB)\"), (\"chunk_81\", \"mentions\", \"WER on LibriSpeech test-clean (%)\"), (\"chunk_81\", \"mentions\", \"white noise\"), (\"chunk_81\", \"mentions\", \"pub noise\"), (\"chunk_81\", \"mentions\", \"unispeech-sat-base-100h-libri-ft\"), (\"chunk_81\", \"mentions\", \"wav2vec2-base-100h\"), (\"chunk_81\", \"mentions\", \"wav2vec2-base-960h\"), (\"chunk_81\", \"mentions\", \"wav2vec2-large-960h\"), (\"chunk_81\", \"mentions\", \"wav2vec2-large-robust-ft-libri-960h\"), (\"chunk_81\", \"mentions\", \"wav2vec2-large-960h-lv60-self\"), (\"chunk_81\", \"mentions\", \"asr-crdnn-rnnlm-librispeech\"), (\"chunk_81\", \"mentions\", \"asr-transformer-transformerlm-librispeech\"), (\"chunk_81\", \"mentions\", \"hubert-large-ls960-ft\"), (\"chunk_81\", \"mentions\", \"hubert-xlarge-ls960-ft\"), (\"chunk_81\", \"mentions\", \"s2t-medium-librispeech-asr\"), (\"chunk_81\", \"mentions\", \"s2t-large-librispeech-asr\"), (\"chunk_81\", \"mentions\", \"stt_en_conformer_ctc_large\"), (\"WER on LibriSpeech test-clean (%)\", \"instance_of\", \"metric\"), (\"white noise\", \"instance_of\", \"noise\"), (\"pub noise\", \"instance_of\", \"noise\"), (\"unispeech-sat-base-100h-libri-ft\", \"instance_of\", \"model\"), (\"wav2vec2-base-100h\", \"instance_of\", \"model\"), (\"wav2vec2-base-960h\", \"instance_of\", \"model\"), (\"wav2vec2-large-960h\", \"instance_of\", \"model\"), (\"wav2vec2-large-robust-ft-libri-960h\", \"instance_of\", \"model\"), (\"wav2vec2-large-960h-lv60-self\", \"instance_of\", \"model\"), (\"asr-crdnn-rnnlm-librispeech\", \"instance_of\", \"model\"), (\"asr-transformer-transformerlm-librispeech\", \"instance_of\", \"model\"), (\"hubert-large-ls960-ft\", \"instance_of\", \"model\"), (\"hubert-xlarge-ls960-ft\", \"instance_of\", \"model\"), (\"s2t-medium-librispeech-asr\", \"instance_of\", \"model\"), (\"s2t-large-librispeech-asr\", \"instance_of\", \"model\"), (\"stt_en_conformer_ctc_large\", \"instance_of\", \"model\")]\n",
            "✅ Extracted: [('signal-to-noise ratio (dB)', 'is_core_idea', 'true'), ('chunk_81', 'is_core_chunk', 'true'), ('WER on LibriSpeech test-clean (%)', 'related_to_core', 'signal-to-noise ratio (dB)'), ('white noise', 'related_to_core', 'signal-to-noise ratio (dB)'), ('pub noise', 'related_to_core', 'signal-to-noise ratio (dB)'), ('unispeech-sat-base-100h-libri-ft', 'related_to_core', 'signal-to-noise ratio (dB)'), ('wav2vec2-base-100h', 'related_to_core', 'signal-to-noise ratio (dB)'), ('wav2vec2-base-960h', 'related_to_core', 'signal-to-noise ratio (dB)'), ('wav2vec2-large-960h', 'related_to_core', 'signal-to-noise ratio (dB)'), ('wav2vec2-large-robust-ft-libri-960h', 'related_to_core', 'signal-to-noise ratio (dB)'), ('wav2vec2-large-960h-lv60-self', 'related_to_core', 'signal-to-noise ratio (dB)'), ('asr-crdnn-rnnlm-librispeech', 'related_to_core', 'signal-to-noise ratio (dB)'), ('asr-transformer-transformerlm-librispeech', 'related_to_core', 'signal-to-noise ratio (dB)'), ('hubert-large-ls960-ft', 'related_to_core', 'signal-to-noise ratio (dB)'), ('hubert-xlarge-ls960-ft', 'related_to_core', 'signal-to-noise ratio (dB)'), ('s2t-medium-librispeech-asr', 'related_to_core', 'signal-to-noise ratio (dB)'), ('s2t-large-librispeech-asr', 'related_to_core', 'signal-to-noise ratio (dB)'), ('stt_en_conformer_ctc_large', 'related_to_core', 'signal-to-noise ratio (dB)'), ('chunk_81', 'mentions', 'signal-to-noise ratio (dB)'), ('chunk_81', 'mentions', 'WER on LibriSpeech test-clean (%)'), ('chunk_81', 'mentions', 'white noise'), ('chunk_81', 'mentions', 'pub noise'), ('chunk_81', 'mentions', 'unispeech-sat-base-100h-libri-ft'), ('chunk_81', 'mentions', 'wav2vec2-base-100h'), ('chunk_81', 'mentions', 'wav2vec2-base-960h'), ('chunk_81', 'mentions', 'wav2vec2-large-960h'), ('chunk_81', 'mentions', 'wav2vec2-large-robust-ft-libri-960h'), ('chunk_81', 'mentions', 'wav2vec2-large-960h-lv60-self'), ('chunk_81', 'mentions', 'asr-crdnn-rnnlm-librispeech'), ('chunk_81', 'mentions', 'asr-transformer-transformerlm-librispeech'), ('chunk_81', 'mentions', 'hubert-large-ls960-ft'), ('chunk_81', 'mentions', 'hubert-xlarge-ls960-ft'), ('chunk_81', 'mentions', 's2t-medium-librispeech-asr'), ('chunk_81', 'mentions', 's2t-large-librispeech-asr'), ('chunk_81', 'mentions', 'stt_en_conformer_ctc_large'), ('WER on LibriSpeech test-clean (%)', 'instance_of', 'metric'), ('white noise', 'instance_of', 'noise'), ('pub noise', 'instance_of', 'noise'), ('unispeech-sat-base-100h-libri-ft', 'instance_of', 'model'), ('wav2vec2-base-100h', 'instance_of', 'model'), ('wav2vec2-base-960h', 'instance_of', 'model'), ('wav2vec2-large-960h', 'instance_of', 'model'), ('wav2vec2-large-robust-ft-libri-960h', 'instance_of', 'model'), ('wav2vec2-large-960h-lv60-self', 'instance_of', 'model'), ('asr-crdnn-rnnlm-librispeech', 'instance_of', 'model'), ('asr-transformer-transformerlm-librispeech', 'instance_of', 'model'), ('hubert-large-ls960-ft', 'instance_of', 'model'), ('hubert-xlarge-ls960-ft', 'instance_of', 'model'), ('s2t-medium-librispeech-asr', 'instance_of', 'model'), ('s2t-large-librispeech-asr', 'instance_of', 'model'), ('stt_en_conformer_ctc_large', 'instance_of', 'model')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_82...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"stt_en_conformer_ctc_large\", \"is_core_idea\", \"true\"), (\"chunk_82\", \"is_core_chunk\", \"true\"), (\"stt_en_conformer_ctc_large\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"stt_en_conformer_transducer_xlarge\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"Whisper\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"Figure 5.WER\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"LibriSpeech\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"SNR\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"additive white noise\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"pub noise\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"NVIDIA STT models\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"SNR < 10 dB\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"stt_en_conformer_ctc_large\", \"mentions\", \"stt_en_conformer_ctc_large\"), (\"chunk_82\", \"mentions\", \"stt_en_conformer_ctc_large\"), (\"chunk_82\", \"mentions\", \"stt_en_conformer_transducer_xlarge\"), (\"chunk_82\", \"mentions\", \"Whisper\"), (\"chunk_82\", \"mentions\", \"Figure 5.WER\"), (\"chunk_82\", \"mentions\", \"LibriSpeech\"), (\"chunk_82\", \"mentions\", \"SNR\"), (\"chunk_82\", \"mentions\", \"additive white noise\"), (\"chunk_82\", \"mentions\", \"pub noise\"), (\"chunk_82\", \"mentions\", \"NVIDIA STT models\"), (\"chunk_82\", \"mentions\", \"SNR < 10 dB\"), (\"stt_en_conformer_transducer_xlarge\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"Whisper\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"Figure 5.WER\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"LibriSpeech\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"SNR\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"additive white noise\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"pub noise\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"NVIDIA STT models\", \"related_to_core\", \"stt_en_conformer_ctc_large\"), (\"SNR < 10 dB\", \"related_to_core\", \"stt_en_conformer_ctc_large\")]\n",
            "✅ Extracted: [('stt_en_conformer_ctc_large', 'is_core_idea', 'true'), ('chunk_82', 'is_core_chunk', 'true'), ('stt_en_conformer_ctc_large', 'related_to_core', 'stt_en_conformer_ctc_large'), ('stt_en_conformer_transducer_xlarge', 'related_to_core', 'stt_en_conformer_ctc_large'), ('Whisper', 'related_to_core', 'stt_en_conformer_ctc_large'), ('Figure 5.WER', 'related_to_core', 'stt_en_conformer_ctc_large'), ('LibriSpeech', 'related_to_core', 'stt_en_conformer_ctc_large'), ('SNR', 'related_to_core', 'stt_en_conformer_ctc_large'), ('additive white noise', 'related_to_core', 'stt_en_conformer_ctc_large'), ('pub noise', 'related_to_core', 'stt_en_conformer_ctc_large'), ('NVIDIA STT models', 'related_to_core', 'stt_en_conformer_ctc_large'), ('SNR < 10 dB', 'related_to_core', 'stt_en_conformer_ctc_large'), ('stt_en_conformer_ctc_large', 'mentions', 'stt_en_conformer_ctc_large'), ('chunk_82', 'mentions', 'stt_en_conformer_ctc_large'), ('chunk_82', 'mentions', 'stt_en_conformer_transducer_xlarge'), ('chunk_82', 'mentions', 'Whisper'), ('chunk_82', 'mentions', 'Figure 5.WER'), ('chunk_82', 'mentions', 'LibriSpeech'), ('chunk_82', 'mentions', 'SNR'), ('chunk_82', 'mentions', 'additive white noise'), ('chunk_82', 'mentions', 'pub noise'), ('chunk_82', 'mentions', 'NVIDIA STT models'), ('chunk_82', 'mentions', 'SNR < 10 dB'), ('stt_en_conformer_transducer_xlarge', 'related_to_core', 'stt_en_conformer_ctc_large'), ('Whisper', 'related_to_core', 'stt_en_conformer_ctc_large'), ('Figure 5.WER', 'related_to_core', 'stt_en_conformer_ctc_large'), ('LibriSpeech', 'related_to_core', 'stt_en_conformer_ctc_large'), ('SNR', 'related_to_core', 'stt_en_conformer_ctc_large'), ('additive white noise', 'related_to_core', 'stt_en_conformer_ctc_large'), ('pub noise', 'related_to_core', 'stt_en_conformer_ctc_large'), ('NVIDIA STT models', 'related_to_core', 'stt_en_conformer_ctc_large'), ('SNR < 10 dB', 'related_to_core', 'stt_en_conformer_ctc_large')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_83...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"LibriSpeech\", \"related_to_core\", \"Performance\"), (\"training data\", \"related_to_core\", \"Performance\"), (\"audio language identiﬁcation\", \"related_to_core\", \"Performance\"), (\"Welsh (CY)\", \"related_to_core\", \"Performance\"), (\"BLEU\", \"related_to_core\", \"Performance\"), (\"translation data\", \"related_to_core\", \"Performance\"), (\"Performance\", \"is_core_idea\", \"true\"), (\"chunk_83\", \"is_core_chunk\", \"true\"), (\"chunk_83\", \"mentions\", \"LibriSpeech\"), (\"chunk_83\", \"mentions\", \"training data\"), (\"chunk_83\", \"mentions\", \"audio language identiﬁcation\"), (\"chunk_83\", \"mentions\", \"Welsh (CY)\"), (\"chunk_83\", \"mentions\", \"BLEU\"), (\"chunk_83\", \"mentions\", \"translation data\"), (\"chunk_83\", \"mentions\", \"Performance\")]\n",
            "✅ Extracted: [('LibriSpeech', 'related_to_core', 'Performance'), ('training data', 'related_to_core', 'Performance'), ('audio language identiﬁcation', 'related_to_core', 'Performance'), ('Welsh (CY)', 'related_to_core', 'Performance'), ('BLEU', 'related_to_core', 'Performance'), ('translation data', 'related_to_core', 'Performance'), ('Performance', 'is_core_idea', 'true'), ('chunk_83', 'is_core_chunk', 'true'), ('chunk_83', 'mentions', 'LibriSpeech'), ('chunk_83', 'mentions', 'training data'), ('chunk_83', 'mentions', 'audio language identiﬁcation'), ('chunk_83', 'mentions', 'Welsh (CY)'), ('chunk_83', 'mentions', 'BLEU'), ('chunk_83', 'mentions', 'translation data'), ('chunk_83', 'mentions', 'Performance')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_84...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"spoken languages\", \"mentions\", \"French\"), (\"spoken languages\", \"mentions\", \"Spanish\"), (\"spoken languages\", \"mentions\", \"Russian\"), (\"spoken languages\", \"mentions\", \"Welsh\"), (\"chunk_84\", \"mentions\", \"French\"), (\"chunk_84\", \"mentions\", \"Spanish\"), (\"chunk_84\", \"mentions\", \"Russian\"), (\"chunk_84\", \"mentions\", \"Welsh\"), (\"translation data\", \"is_a\", \"data\"), (\"translation data\", \"is_Welsh\", \"true\"), (\"translation data\", \"mentions\", \"English audio\"), (\"translation data\", \"mentions\", \"English captions\"), (\"translation data\", \"mentions\", \"language identiﬁcation system\"), (\"translation data\", \"mentions\", \"transcription data\"), (\"translation data\", \"mentions\", \"dataset creation rules\"), (\"chunk_84\", \"mentions\", \"translation data\"), (\"English audio\", \"has\", \"English captions\"), (\"English audio\", \"mis-classiﬁed_as\", \"Welsh\"), (\"chunk_84\", \"mentions\", \"English audio\"), (\"English captions\", \"mentions\", \"English audio\"), (\"chunk_84\", \"mentions\", \"English captions\"), (\"language identiﬁcation system\", \"mis-classifies\", \"English audio\"), (\"language identiﬁcation system\", \"mentions\", \"Welsh\"), (\"chunk_84\", \"mentions\", \"language identiﬁcation system\"), (\"transcription data\", \"mentions\", \"translation data\"), (\"chunk_84\", \"mentions\", \"transcription data\"), (\"dataset creation rules\", \"mentions\", \"translation data\"), (\"dataset creation rules\", \"mentions\", \"transcription data\"), (\"chunk_84\", \"mentions\", \"dataset creation rules\"), (\"language identiﬁcation\", \"mentions\", \"Fleurs\"), (\"chunk_84\", \"mentions\", \"language identiﬁcation\"), (\"Fleurs\", \"is_used_to_evaluate\", \"language identiﬁcation\"), (\"chunk_84\", \"mentions\", \"Fleurs\"), (\"language identiﬁcation\", \"is_core_idea\", \"true\"), (\"chunk_84\", \"is_core_chunk\", \"true\"), (\"French\", \"related_to_core\", \"language identiﬁcation\"), (\"Spanish\", \"related_to_core\", \"language identiﬁcation\"), (\"Russian\", \"related_to_core\", \"language identiﬁcation\"), (\"Welsh\", \"related_to_core\", \"language identiﬁcation\"), (\"translation data\", \"related_to_core\", \"language identiﬁcation\"), (\"English audio\", \"related_to_core\", \"language identiﬁcation\"), (\"English captions\", \"related_to_core\", \"language identiﬁcation\"), (\"transcription data\", \"related_to_core\", \"language identiﬁcation\"), (\"dataset creation rules\", \"related_to_core\", \"language identiﬁcation\"), (\"Fleurs\", \"related_to_core\", \"language identiﬁcation\")]\n",
            "✅ Extracted: [('spoken languages', 'mentions', 'French'), ('spoken languages', 'mentions', 'Spanish'), ('spoken languages', 'mentions', 'Russian'), ('spoken languages', 'mentions', 'Welsh'), ('chunk_84', 'mentions', 'French'), ('chunk_84', 'mentions', 'Spanish'), ('chunk_84', 'mentions', 'Russian'), ('chunk_84', 'mentions', 'Welsh'), ('translation data', 'is_a', 'data'), ('translation data', 'is_Welsh', 'true'), ('translation data', 'mentions', 'English audio'), ('translation data', 'mentions', 'English captions'), ('translation data', 'mentions', 'language identiﬁcation system'), ('translation data', 'mentions', 'transcription data'), ('translation data', 'mentions', 'dataset creation rules'), ('chunk_84', 'mentions', 'translation data'), ('English audio', 'has', 'English captions'), ('English audio', 'mis-classiﬁed_as', 'Welsh'), ('chunk_84', 'mentions', 'English audio'), ('English captions', 'mentions', 'English audio'), ('chunk_84', 'mentions', 'English captions'), ('language identiﬁcation system', 'mis-classifies', 'English audio'), ('language identiﬁcation system', 'mentions', 'Welsh'), ('chunk_84', 'mentions', 'language identiﬁcation system'), ('transcription data', 'mentions', 'translation data'), ('chunk_84', 'mentions', 'transcription data'), ('dataset creation rules', 'mentions', 'translation data'), ('dataset creation rules', 'mentions', 'transcription data'), ('chunk_84', 'mentions', 'dataset creation rules'), ('language identiﬁcation', 'mentions', 'Fleurs'), ('chunk_84', 'mentions', 'language identiﬁcation'), ('Fleurs', 'is_used_to_evaluate', 'language identiﬁcation'), ('chunk_84', 'mentions', 'Fleurs'), ('language identiﬁcation', 'is_core_idea', 'true'), ('chunk_84', 'is_core_chunk', 'true'), ('French', 'related_to_core', 'language identiﬁcation'), ('Spanish', 'related_to_core', 'language identiﬁcation'), ('Russian', 'related_to_core', 'language identiﬁcation'), ('Welsh', 'related_to_core', 'language identiﬁcation'), ('translation data', 'related_to_core', 'language identiﬁcation'), ('English audio', 'related_to_core', 'language identiﬁcation'), ('English captions', 'related_to_core', 'language identiﬁcation'), ('transcription data', 'related_to_core', 'language identiﬁcation'), ('dataset creation rules', 'related_to_core', 'language identiﬁcation'), ('Fleurs', 'related_to_core', 'language identiﬁcation')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_85...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"dataset\", \"mentions\", \"dataset\"), (\"chunk_85\", \"mentions\", \"dataset\"), (\"Whisper\", \"mentions\", \"Whisper\"), (\"zero-shot performance\", \"mentions\", \"zero-shot performance\"), (\"prior supervised work\", \"mentions\", \"prior supervised work\"), (\"supervised SOTA\", \"mentions\", \"supervised SOTA\"), (\"language identiﬁcation\", \"mentions\", \"language identiﬁcation\"), (\"Fleurs\", \"mentions\", \"Fleurs\"), (\"Whisper dataset\", \"mentions\", \"Whisper dataset\"), (\"training data\", \"mentions\", \"training data\"), (\"languages\", \"mentions\", \"languages\"), (\"accuracy\", \"mentions\", \"accuracy\"), (\"overlapping languages\", \"mentions\", \"overlapping languages\"), (\"Whisper model\", \"mentions\", \"Whisper model\"), (\"accuracy\", \"mentions\", \"accuracy\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_85\", \"is_core_chunk\", \"true\"), (\"zero-shot performance\", \"related_to_core\", \"Whisper\"), (\"prior supervised work\", \"related_to_core\", \"Whisper\"), (\"supervised SOTA\", \"related_to_core\", \"Whisper\"), (\"language identiﬁcation\", \"related_to_core\", \"Whisper\"), (\"Fleurs\", \"related_to_core\", \"Whisper\"), (\"Whisper dataset\", \"related_to_core\", \"Whisper\"), (\"training data\", \"related_to_core\", \"Whisper\"), (\"languages\", \"related_to_core\", \"Whisper\"), (\"accuracy\", \"related_to_core\", \"Whisper\"), (\"overlapping languages\", \"related_to_core\", \"Whisper\"), (\"Whisper model\", \"related_to_core\", \"Whisper\"), (\"chunk_85\", \"mentions\", \"Whisper model\"), (\"chunk_85\", \"mentions\", \"languages\"), (\"chunk_85\", \"mentions\", \"training data\"), (\"chunk_85\", \"mentions\", \"Whisper dataset\"), (\"chunk_85\", \"mentions\", \"Fleurs\"), (\"chunk_85\", \"mentions\", \"language identiﬁcation\"), (\"chunk_85\", \"mentions\", \"supervised SOTA\"), (\"chunk_85\", \"mentions\", \"prior supervised work\"), (\"chunk_85\", \"mentions\", \"zero-shot performance\"), (\"chunk_85\", \"mentions\", \"accuracy\")]\n",
            "✅ Extracted: [('dataset', 'mentions', 'dataset'), ('chunk_85', 'mentions', 'dataset'), ('Whisper', 'mentions', 'Whisper'), ('zero-shot performance', 'mentions', 'zero-shot performance'), ('prior supervised work', 'mentions', 'prior supervised work'), ('supervised SOTA', 'mentions', 'supervised SOTA'), ('language identiﬁcation', 'mentions', 'language identiﬁcation'), ('Fleurs', 'mentions', 'Fleurs'), ('Whisper dataset', 'mentions', 'Whisper dataset'), ('training data', 'mentions', 'training data'), ('languages', 'mentions', 'languages'), ('accuracy', 'mentions', 'accuracy'), ('overlapping languages', 'mentions', 'overlapping languages'), ('Whisper model', 'mentions', 'Whisper model'), ('accuracy', 'mentions', 'accuracy'), ('Whisper', 'is_core_idea', 'true'), ('chunk_85', 'is_core_chunk', 'true'), ('zero-shot performance', 'related_to_core', 'Whisper'), ('prior supervised work', 'related_to_core', 'Whisper'), ('supervised SOTA', 'related_to_core', 'Whisper'), ('language identiﬁcation', 'related_to_core', 'Whisper'), ('Fleurs', 'related_to_core', 'Whisper'), ('Whisper dataset', 'related_to_core', 'Whisper'), ('training data', 'related_to_core', 'Whisper'), ('languages', 'related_to_core', 'Whisper'), ('accuracy', 'related_to_core', 'Whisper'), ('overlapping languages', 'related_to_core', 'Whisper'), ('Whisper model', 'related_to_core', 'Whisper'), ('chunk_85', 'mentions', 'Whisper model'), ('chunk_85', 'mentions', 'languages'), ('chunk_85', 'mentions', 'training data'), ('chunk_85', 'mentions', 'Whisper dataset'), ('chunk_85', 'mentions', 'Fleurs'), ('chunk_85', 'mentions', 'language identiﬁcation'), ('chunk_85', 'mentions', 'supervised SOTA'), ('chunk_85', 'mentions', 'prior supervised work'), ('chunk_85', 'mentions', 'zero-shot performance'), ('chunk_85', 'mentions', 'accuracy')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_86...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"mentions\", \"Whisper models\"), (\"Robust Speech Recognition\", \"mentions\", \"Additive Noise\"), (\"Robust Speech Recognition\", \"mentions\", \"noise robustness\"), (\"Robust Speech Recognition\", \"mentions\", \"LibriSpeech-trained models\"), (\"Robust Speech Recognition\", \"mentions\", \"WER\"), (\"Robust Speech Recognition\", \"mentions\", \"white noise\"), (\"Robust Speech Recognition\", \"mentions\", \"pub noise\"), (\"Robust Speech Recognition\", \"mentions\", \"Audio Degradation Toolbox\"), (\"Robust Speech Recognition\", \"mentions\", \"audio\"), (\"Robust Speech Recognition\", \"mentions\", \"noisy environment\"), (\"Robust Speech Recognition\", \"mentions\", \"ambient noise\"), (\"Robust Speech Recognition\", \"mentions\", \"chatter\"), (\"Robust Speech Recognition\", \"mentions\", \"models\"), (\"chunk_86\", \"mentions\", \"Whisper models\"), (\"chunk_86\", \"mentions\", \"Additive Noise\"), (\"chunk_86\", \"mentions\", \"noise robustness\"), (\"chunk_86\", \"mentions\", \"LibriSpeech-trained models\"), (\"chunk_86\", \"mentions\", \"WER\"), (\"chunk_86\", \"mentions\", \"white noise\"), (\"chunk_86\", \"mentions\", \"pub noise\"), (\"chunk_86\", \"mentions\", \"Audio Degradation Toolbox\"), (\"chunk_86\", \"mentions\", \"audio\"), (\"chunk_86\", \"mentions\", \"noisy environment\"), (\"chunk_86\", \"mentions\", \"ambient noise\"), (\"chunk_86\", \"mentions\", \"chatter\"), (\"chunk_86\", \"mentions\", \"models\"), (\"Whisper models\", \"related_to_core\", \"noise robustness\"), (\"Additive Noise\", \"related_to_core\", \"noise robustness\"), (\"LibriSpeech-trained models\", \"related_to_core\", \"noise robustness\"), (\"WER\", \"related_to_core\", \"noise robustness\"), (\"white noise\", \"related_to_core\", \"noise robustness\"), (\"pub noise\", \"related_to_core\", \"noise robustness\"), (\"Audio Degradation Toolbox\", \"related_to_core\", \"noise robustness\"), (\"audio\", \"related_to_core\", \"noise robustness\"), (\"noisy environment\", \"related_to_core\", \"noise robustness\"), (\"ambient noise\", \"related_to_core\", \"noise robustness\"), (\"chatter\", \"related_to_core\", \"noise robustness\"), (\"models\", \"related_to_core\", \"noise robustness\"), (\"noise robustness\", \"is_core_idea\", \"true\"), (\"chunk_86\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'mentions', 'Whisper models'), ('Robust Speech Recognition', 'mentions', 'Additive Noise'), ('Robust Speech Recognition', 'mentions', 'noise robustness'), ('Robust Speech Recognition', 'mentions', 'LibriSpeech-trained models'), ('Robust Speech Recognition', 'mentions', 'WER'), ('Robust Speech Recognition', 'mentions', 'white noise'), ('Robust Speech Recognition', 'mentions', 'pub noise'), ('Robust Speech Recognition', 'mentions', 'Audio Degradation Toolbox'), ('Robust Speech Recognition', 'mentions', 'audio'), ('Robust Speech Recognition', 'mentions', 'noisy environment'), ('Robust Speech Recognition', 'mentions', 'ambient noise'), ('Robust Speech Recognition', 'mentions', 'chatter'), ('Robust Speech Recognition', 'mentions', 'models'), ('chunk_86', 'mentions', 'Whisper models'), ('chunk_86', 'mentions', 'Additive Noise'), ('chunk_86', 'mentions', 'noise robustness'), ('chunk_86', 'mentions', 'LibriSpeech-trained models'), ('chunk_86', 'mentions', 'WER'), ('chunk_86', 'mentions', 'white noise'), ('chunk_86', 'mentions', 'pub noise'), ('chunk_86', 'mentions', 'Audio Degradation Toolbox'), ('chunk_86', 'mentions', 'audio'), ('chunk_86', 'mentions', 'noisy environment'), ('chunk_86', 'mentions', 'ambient noise'), ('chunk_86', 'mentions', 'chatter'), ('chunk_86', 'mentions', 'models'), ('Whisper models', 'related_to_core', 'noise robustness'), ('Additive Noise', 'related_to_core', 'noise robustness'), ('LibriSpeech-trained models', 'related_to_core', 'noise robustness'), ('WER', 'related_to_core', 'noise robustness'), ('white noise', 'related_to_core', 'noise robustness'), ('pub noise', 'related_to_core', 'noise robustness'), ('Audio Degradation Toolbox', 'related_to_core', 'noise robustness'), ('audio', 'related_to_core', 'noise robustness'), ('noisy environment', 'related_to_core', 'noise robustness'), ('ambient noise', 'related_to_core', 'noise robustness'), ('chatter', 'related_to_core', 'noise robustness'), ('models', 'related_to_core', 'noise robustness'), ('noise robustness', 'is_core_idea', 'true'), ('chunk_86', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_87...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"LibriSpeech\", \"is_core_idea\", \"true\"), (\"chunk_87\", \"is_core_chunk\", \"true\"), (\"chunk_87\", \"mentions\", \"LibriSpeech\"), (\"NVIDIA STT models\", \"related_to_core\", \"LibriSpeech\"), (\"SpeechStew\", \"related_to_core\", \"LibriSpeech\"), (\"additive noise\", \"related_to_core\", \"LibriSpeech\"), (\"signal-to-noise ratio\", \"related_to_core\", \"LibriSpeech\"), (\"SNR\", \"related_to_core\", \"LibriSpeech\"), (\"signal power\", \"related_to_core\", \"LibriSpeech\"), (\"ASR performance\", \"related_to_core\", \"LibriSpeech\"), (\"chunk_87\", \"mentions\", \"NVIDIA STT models\"), (\"NVIDIA STT models\", \"trained on\", \"mixture dataset\"), (\"mixture dataset\", \"includes\", \"LibriSpeech\"), (\"chunk_87\", \"mentions\", \"SpeechStew\"), (\"chunk_87\", \"mentions\", \"additive noise\"), (\"additive noise\", \"corresponding to\", \"signal-to-noise ratio\"), (\"chunk_87\", \"mentions\", \"signal-to-noise ratio\"), (\"signal-to-noise ratio\", \"abbreviated as\", \"SNR\"), (\"chunk_87\", \"mentions\", \"SNR\"), (\"SNR\", \"calculated based on\", \"signal power\"), (\"chunk_87\", \"mentions\", \"signal power\"), (\"chunk_87\", \"mentions\", \"ASR performance\")]\n",
            "✅ Extracted: [('LibriSpeech', 'is_core_idea', 'true'), ('chunk_87', 'is_core_chunk', 'true'), ('chunk_87', 'mentions', 'LibriSpeech'), ('NVIDIA STT models', 'related_to_core', 'LibriSpeech'), ('SpeechStew', 'related_to_core', 'LibriSpeech'), ('additive noise', 'related_to_core', 'LibriSpeech'), ('signal-to-noise ratio', 'related_to_core', 'LibriSpeech'), ('SNR', 'related_to_core', 'LibriSpeech'), ('signal power', 'related_to_core', 'LibriSpeech'), ('ASR performance', 'related_to_core', 'LibriSpeech'), ('chunk_87', 'mentions', 'NVIDIA STT models'), ('NVIDIA STT models', 'trained on', 'mixture dataset'), ('mixture dataset', 'includes', 'LibriSpeech'), ('chunk_87', 'mentions', 'SpeechStew'), ('chunk_87', 'mentions', 'additive noise'), ('additive noise', 'corresponding to', 'signal-to-noise ratio'), ('chunk_87', 'mentions', 'signal-to-noise ratio'), ('signal-to-noise ratio', 'abbreviated as', 'SNR'), ('chunk_87', 'mentions', 'SNR'), ('SNR', 'calculated based on', 'signal power'), ('chunk_87', 'mentions', 'signal power'), ('chunk_87', 'mentions', 'ASR performance')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_88...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"zero-shot performance\", \"related_to_core\", \"Whisper\"), (\"low noise\", \"related_to_core\", \"Whisper\"), (\"40 dB SNR\", \"related_to_core\", \"Whisper\"), (\"LibriSpeech\", \"related_to_core\", \"Whisper\"), (\"Whisper model\", \"related_to_core\", \"Whisper\"), (\"noise\", \"related_to_core\", \"Whisper\"), (\"additive pub noise\", \"related_to_core\", \"Whisper\"), (\"SNR\", \"related_to_core\", \"Whisper\"), (\"10 dB\", \"related_to_core\", \"Whisper\"), (\"Whisper's robustness\", \"related_to_core\", \"Whisper\"), (\"natural distribution shifts\", \"related_to_core\", \"Whisper\"), (\"pub noise\", \"related_to_core\", \"Whisper\"), (\"Long-form Transcription\", \"related_to_core\", \"Whisper\"), (\"Whisper models\", \"related_to_core\", \"Whisper\"), (\"30-second audio chunks\", \"related_to_core\", \"Whisper\"), (\"chunk_88\", \"mentions\", \"zero-shot performance\"), (\"chunk_88\", \"mentions\", \"low noise\"), (\"chunk_88\", \"mentions\", \"40 dB SNR\"), (\"chunk_88\", \"mentions\", \"LibriSpeech\"), (\"chunk_88\", \"mentions\", \"Whisper model\"), (\"chunk_88\", \"mentions\", \"noise\"), (\"chunk_88\", \"mentions\", \"additive pub noise\"), (\"chunk_88\", \"mentions\", \"SNR\"), (\"chunk_88\", \"mentions\", \"10 dB\"), (\"chunk_88\", \"mentions\", \"Whisper's robustness\"), (\"chunk_88\", \"mentions\", \"natural distribution shifts\"), (\"chunk_88\", \"mentions\", \"pub noise\"), (\"chunk_88\", \"mentions\", \"Long-form Transcription\"), (\"chunk_88\", \"mentions\", \"Whisper models\"), (\"chunk_88\", \"mentions\", \"30-second audio chunks\"), (\"zero-shot performance\", \"performance_under\", \"low noise\"), (\"low noise\", \"measured_in\", \"40 dB SNR\"), (\"Whisper model\", \"robustness_to\", \"noise\"), (\"noise\", \"type\", \"additive pub noise\"), (\"additive pub noise\", \"measured_in\", \"SNR\"), (\"SNR\", \"below\", \"10 dB\"), (\"natural distribution shifts\", \"like\", \"pub noise\"), (\"Whisper models\", \"trained_on\", \"30-second audio chunks\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_88\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('zero-shot performance', 'related_to_core', 'Whisper'), ('low noise', 'related_to_core', 'Whisper'), ('40 dB SNR', 'related_to_core', 'Whisper'), ('LibriSpeech', 'related_to_core', 'Whisper'), ('Whisper model', 'related_to_core', 'Whisper'), ('noise', 'related_to_core', 'Whisper'), ('additive pub noise', 'related_to_core', 'Whisper'), ('SNR', 'related_to_core', 'Whisper'), ('10 dB', 'related_to_core', 'Whisper'), (\"Whisper's robustness\", 'related_to_core', 'Whisper'), ('natural distribution shifts', 'related_to_core', 'Whisper'), ('pub noise', 'related_to_core', 'Whisper'), ('Long-form Transcription', 'related_to_core', 'Whisper'), ('Whisper models', 'related_to_core', 'Whisper'), ('30-second audio chunks', 'related_to_core', 'Whisper'), ('chunk_88', 'mentions', 'zero-shot performance'), ('chunk_88', 'mentions', 'low noise'), ('chunk_88', 'mentions', '40 dB SNR'), ('chunk_88', 'mentions', 'LibriSpeech'), ('chunk_88', 'mentions', 'Whisper model'), ('chunk_88', 'mentions', 'noise'), ('chunk_88', 'mentions', 'additive pub noise'), ('chunk_88', 'mentions', 'SNR'), ('chunk_88', 'mentions', '10 dB'), ('chunk_88', 'mentions', \"Whisper's robustness\"), ('chunk_88', 'mentions', 'natural distribution shifts'), ('chunk_88', 'mentions', 'pub noise'), ('chunk_88', 'mentions', 'Long-form Transcription'), ('chunk_88', 'mentions', 'Whisper models'), ('chunk_88', 'mentions', '30-second audio chunks'), ('zero-shot performance', 'performance_under', 'low noise'), ('low noise', 'measured_in', '40 dB SNR'), ('Whisper model', 'robustness_to', 'noise'), ('noise', 'type', 'additive pub noise'), ('additive pub noise', 'measured_in', 'SNR'), ('SNR', 'below', '10 dB'), ('natural distribution shifts', 'like', 'pub noise'), ('Whisper models', 'trained_on', '30-second audio chunks'), ('Whisper', 'is_core_idea', 'true'), ('chunk_88', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_89...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"audio inputs\", \"related_to_core\", \"transcription\"), (\"academic datasets\", \"related_to_core\", \"transcription\"), (\"utterances\", \"related_to_core\", \"transcription\"), (\"real-world applications\", \"related_to_core\", \"transcription\"), (\"audio\", \"related_to_core\", \"transcription\"), (\"buffered transcription\", \"related_to_core\", \"transcription\"), (\"long audio\", \"related_to_core\", \"transcription\"), (\"30-second segments\", \"related_to_core\", \"transcription\"), (\"timestamps\", \"related_to_core\", \"transcription\"), (\"model\", \"related_to_core\", \"transcription\"), (\"audio inputs\", \"instance of\", \"entity\"), (\"academic datasets\", \"instance of\", \"entity\"), (\"utterances\", \"instance of\", \"entity\"), (\"real-world applications\", \"instance of\", \"entity\"), (\"audio\", \"instance of\", \"entity\"), (\"buffered transcription\", \"instance of\", \"entity\"), (\"long audio\", \"instance of\", \"entity\"), (\"30-second segments\", \"instance of\", \"entity\"), (\"timestamps\", \"instance of\", \"entity\"), (\"model\", \"instance of\", \"entity\"), (\"transcription\", \"is_core_idea\", \"true\"), (\"chunk_89\", \"is_core_chunk\", \"true\"), (\"chunk_89\", \"mentions\", \"audio inputs\"), (\"chunk_89\", \"mentions\", \"academic datasets\"), (\"chunk_89\", \"mentions\", \"utterances\"), (\"chunk_89\", \"mentions\", \"real-world applications\"), (\"chunk_89\", \"mentions\", \"audio\"), (\"chunk_89\", \"mentions\", \"buffered transcription\"), (\"chunk_89\", \"mentions\", \"long audio\"), (\"chunk_89\", \"mentions\", \"30-second segments\"), (\"chunk_89\", \"mentions\", \"timestamps\"), (\"chunk_89\", \"mentions\", \"model\"), (\"chunk_89\", \"mentions\", \"transcription\")]\n",
            "✅ Extracted: [('audio inputs', 'related_to_core', 'transcription'), ('academic datasets', 'related_to_core', 'transcription'), ('utterances', 'related_to_core', 'transcription'), ('real-world applications', 'related_to_core', 'transcription'), ('audio', 'related_to_core', 'transcription'), ('buffered transcription', 'related_to_core', 'transcription'), ('long audio', 'related_to_core', 'transcription'), ('30-second segments', 'related_to_core', 'transcription'), ('timestamps', 'related_to_core', 'transcription'), ('model', 'related_to_core', 'transcription'), ('audio inputs', 'instance of', 'entity'), ('academic datasets', 'instance of', 'entity'), ('utterances', 'instance of', 'entity'), ('real-world applications', 'instance of', 'entity'), ('audio', 'instance of', 'entity'), ('buffered transcription', 'instance of', 'entity'), ('long audio', 'instance of', 'entity'), ('30-second segments', 'instance of', 'entity'), ('timestamps', 'instance of', 'entity'), ('model', 'instance of', 'entity'), ('transcription', 'is_core_idea', 'true'), ('chunk_89', 'is_core_chunk', 'true'), ('chunk_89', 'mentions', 'audio inputs'), ('chunk_89', 'mentions', 'academic datasets'), ('chunk_89', 'mentions', 'utterances'), ('chunk_89', 'mentions', 'real-world applications'), ('chunk_89', 'mentions', 'audio'), ('chunk_89', 'mentions', 'buffered transcription'), ('chunk_89', 'mentions', 'long audio'), ('chunk_89', 'mentions', '30-second segments'), ('chunk_89', 'mentions', 'timestamps'), ('chunk_89', 'mentions', 'model'), ('chunk_89', 'mentions', 'transcription')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_90...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"beam search\", \"mentions\", \"beam search\"), (\"temperature scheduling\", \"mentions\", \"temperature scheduling\"), (\"repetitiveness\", \"mentions\", \"repetitiveness\"), (\"log probability\", \"mentions\", \"log probability\"), (\"model predictions\", \"mentions\", \"model predictions\"), (\"long audio\", \"mentions\", \"long audio\"), (\"transcribe\", \"mentions\", \"transcribe\"), (\"Section 4.5\", \"mentions\", \"Section 4.5\"), (\"long-form transcription\", \"mentions\", \"long-form transcription\"), (\"performance\", \"mentions\", \"performance\"), (\"datasets\", \"mentions\", \"datasets\"), (\"speech recordings\", \"mentions\", \"speech recordings\"), (\"recording conditions\", \"mentions\", \"recording conditions\"), (\"data distribution\", \"mentions\", \"data distribution\"), (\"chunk_90\", \"mentions\", \"beam search\"), (\"chunk_90\", \"mentions\", \"temperature scheduling\"), (\"chunk_90\", \"mentions\", \"repetitiveness\"), (\"chunk_90\", \"mentions\", \"log probability\"), (\"chunk_90\", \"mentions\", \"model predictions\"), (\"chunk_90\", \"mentions\", \"long audio\"), (\"chunk_90\", \"mentions\", \"transcribe\"), (\"chunk_90\", \"mentions\", \"Section 4.5\"), (\"chunk_90\", \"mentions\", \"long-form transcription\"), (\"chunk_90\", \"mentions\", \"performance\"), (\"chunk_90\", \"mentions\", \"datasets\"), (\"chunk_90\", \"mentions\", \"speech recordings\"), (\"chunk_90\", \"mentions\", \"recording conditions\"), (\"chunk_90\", \"mentions\", \"data distribution\"), (\"long-form transcription\", \"is_core_idea\", \"true\"), (\"chunk_90\", \"is_core_chunk\", \"true\"), (\"beam search\", \"related_to_core\", \"long-form transcription\"), (\"temperature scheduling\", \"related_to_core\", \"long-form transcription\"), (\"repetitiveness\", \"related_to_core\", \"long-form transcription\"), (\"log probability\", \"related_to_core\", \"long-form transcription\"), (\"model predictions\", \"related_to_core\", \"long-form transcription\"), (\"long audio\", \"related_to_core\", \"long-form transcription\"), (\"transcribe\", \"related_to_core\", \"long-form transcription\"), (\"Section 4.5\", \"related_to_core\", \"long-form transcription\"), (\"performance\", \"related_to_core\", \"long-form transcription\"), (\"datasets\", \"related_to_core\", \"long-form transcription\"), (\"speech recordings\", \"related_to_core\", \"long-form transcription\"), (\"recording conditions\", \"related_to_core\", \"long-form transcription\"), (\"data distribution\", \"related_to_core\", \"long-form transcription\")]\n",
            "✅ Extracted: [('beam search', 'mentions', 'beam search'), ('temperature scheduling', 'mentions', 'temperature scheduling'), ('repetitiveness', 'mentions', 'repetitiveness'), ('log probability', 'mentions', 'log probability'), ('model predictions', 'mentions', 'model predictions'), ('long audio', 'mentions', 'long audio'), ('transcribe', 'mentions', 'transcribe'), ('Section 4.5', 'mentions', 'Section 4.5'), ('long-form transcription', 'mentions', 'long-form transcription'), ('performance', 'mentions', 'performance'), ('datasets', 'mentions', 'datasets'), ('speech recordings', 'mentions', 'speech recordings'), ('recording conditions', 'mentions', 'recording conditions'), ('data distribution', 'mentions', 'data distribution'), ('chunk_90', 'mentions', 'beam search'), ('chunk_90', 'mentions', 'temperature scheduling'), ('chunk_90', 'mentions', 'repetitiveness'), ('chunk_90', 'mentions', 'log probability'), ('chunk_90', 'mentions', 'model predictions'), ('chunk_90', 'mentions', 'long audio'), ('chunk_90', 'mentions', 'transcribe'), ('chunk_90', 'mentions', 'Section 4.5'), ('chunk_90', 'mentions', 'long-form transcription'), ('chunk_90', 'mentions', 'performance'), ('chunk_90', 'mentions', 'datasets'), ('chunk_90', 'mentions', 'speech recordings'), ('chunk_90', 'mentions', 'recording conditions'), ('chunk_90', 'mentions', 'data distribution'), ('long-form transcription', 'is_core_idea', 'true'), ('chunk_90', 'is_core_chunk', 'true'), ('beam search', 'related_to_core', 'long-form transcription'), ('temperature scheduling', 'related_to_core', 'long-form transcription'), ('repetitiveness', 'related_to_core', 'long-form transcription'), ('log probability', 'related_to_core', 'long-form transcription'), ('model predictions', 'related_to_core', 'long-form transcription'), ('long audio', 'related_to_core', 'long-form transcription'), ('transcribe', 'related_to_core', 'long-form transcription'), ('Section 4.5', 'related_to_core', 'long-form transcription'), ('performance', 'related_to_core', 'long-form transcription'), ('datasets', 'related_to_core', 'long-form transcription'), ('speech recordings', 'related_to_core', 'long-form transcription'), ('recording conditions', 'related_to_core', 'long-form transcription'), ('data distribution', 'related_to_core', 'long-form transcription')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_91...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"TED-LIUM3\", \"is_core_idea\", \"true\"), (\"chunk_91\", \"is_core_chunk\", \"true\"), (\"TED-LIUM3\", \"related_to_core\", \"TED-LIUM3\"), (\"The Late Show with Stephen Colbert\", \"related_to_core\", \"TED-LIUM3\"), (\"Meanwhile\", \"related_to_core\", \"TED-LIUM3\"), (\"Rev16\", \"related_to_core\", \"TED-LIUM3\"), (\"Kincaid46\", \"related_to_core\", \"TED-LIUM3\"), (\"ASR benchmarks\", \"related_to_core\", \"TED-LIUM3\"), (\"earnings calls\", \"related_to_core\", \"TED-LIUM3\"), (\"Corpus of Regional African American Language\", \"related_to_core\", \"TED-LIUM3\"), (\"CORAAL\", \"related_to_core\", \"TED-LIUM3\"), (\"chunk_91\", \"mentions\", \"TED-LIUM3\"), (\"chunk_91\", \"mentions\", \"The Late Show with Stephen Colbert\"), (\"chunk_91\", \"mentions\", \"Meanwhile\"), (\"chunk_91\", \"mentions\", \"Rev16\"), (\"chunk_91\", \"mentions\", \"Kincaid46\"), (\"chunk_91\", \"mentions\", \"ASR benchmarks\"), (\"chunk_91\", \"mentions\", \"earnings calls\"), (\"chunk_91\", \"mentions\", \"Corpus of Regional African American Language\"), (\"chunk_91\", \"mentions\", \"CORAAL\")]\n",
            "✅ Extracted: [('TED-LIUM3', 'is_core_idea', 'true'), ('chunk_91', 'is_core_chunk', 'true'), ('TED-LIUM3', 'related_to_core', 'TED-LIUM3'), ('The Late Show with Stephen Colbert', 'related_to_core', 'TED-LIUM3'), ('Meanwhile', 'related_to_core', 'TED-LIUM3'), ('Rev16', 'related_to_core', 'TED-LIUM3'), ('Kincaid46', 'related_to_core', 'TED-LIUM3'), ('ASR benchmarks', 'related_to_core', 'TED-LIUM3'), ('earnings calls', 'related_to_core', 'TED-LIUM3'), ('Corpus of Regional African American Language', 'related_to_core', 'TED-LIUM3'), ('CORAAL', 'related_to_core', 'TED-LIUM3'), ('chunk_91', 'mentions', 'TED-LIUM3'), ('chunk_91', 'mentions', 'The Late Show with Stephen Colbert'), ('chunk_91', 'mentions', 'Meanwhile'), ('chunk_91', 'mentions', 'Rev16'), ('chunk_91', 'mentions', 'Kincaid46'), ('chunk_91', 'mentions', 'ASR benchmarks'), ('chunk_91', 'mentions', 'earnings calls'), ('chunk_91', 'mentions', 'Corpus of Regional African American Language'), ('chunk_91', 'mentions', 'CORAAL')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_92...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"long-form datasets\", \"is_core_idea\", \"true\"), (\"chunk_92\", \"is_core_chunk\", \"true\"), (\"chunk_92\", \"mentions\", \"long-form datasets\"), (\"open-source models\", \"related_to_core\", \"long-form datasets\"), (\"ASR services\", \"related_to_core\", \"long-form datasets\"), (\"word error rates\", \"related_to_core\", \"long-form datasets\"), (\"Whisper\", \"related_to_core\", \"long-form datasets\"), (\"TED-LIUM3\", \"related_to_core\", \"long-form datasets\"), (\"Kincaid46\", \"related_to_core\", \"long-form datasets\"), (\"Rev16\", \"related_to_core\", \"long-form datasets\"), (\"Earnings-21\", \"related_to_core\", \"long-form datasets\"), (\"Earnings-22\", \"related_to_core\", \"long-form datasets\"), (\"CORAAL\", \"related_to_core\", \"long-form datasets\"), (\"NVIDIA STT (CTC large)\", \"related_to_core\", \"long-form datasets\"), (\"chunk_92\", \"mentions\", \"open-source models\"), (\"chunk_92\", \"mentions\", \"ASR services\"), (\"chunk_92\", \"mentions\", \"word error rates\"), (\"chunk_92\", \"mentions\", \"Whisper\"), (\"chunk_92\", \"mentions\", \"TED-LIUM3\"), (\"chunk_92\", \"mentions\", \"Kincaid46\"), (\"chunk_92\", \"mentions\", \"Rev16\"), (\"chunk_92\", \"mentions\", \"Earnings-21\"), (\"chunk_92\", \"mentions\", \"Earnings-22\"), (\"chunk_92\", \"mentions\", \"CORAAL\"), (\"chunk_92\", \"mentions\", \"NVIDIA STT (CTC large)\"), (\"ASR services\", \"are\", \"commercial\"), (\"word error rates\", \"are from\", \"Whisper\"), (\"word error rates\", \"are from\", \"ASR services\")]\n",
            "✅ Extracted: [('long-form datasets', 'is_core_idea', 'true'), ('chunk_92', 'is_core_chunk', 'true'), ('chunk_92', 'mentions', 'long-form datasets'), ('open-source models', 'related_to_core', 'long-form datasets'), ('ASR services', 'related_to_core', 'long-form datasets'), ('word error rates', 'related_to_core', 'long-form datasets'), ('Whisper', 'related_to_core', 'long-form datasets'), ('TED-LIUM3', 'related_to_core', 'long-form datasets'), ('Kincaid46', 'related_to_core', 'long-form datasets'), ('Rev16', 'related_to_core', 'long-form datasets'), ('Earnings-21', 'related_to_core', 'long-form datasets'), ('Earnings-22', 'related_to_core', 'long-form datasets'), ('CORAAL', 'related_to_core', 'long-form datasets'), ('NVIDIA STT (CTC large)', 'related_to_core', 'long-form datasets'), ('chunk_92', 'mentions', 'open-source models'), ('chunk_92', 'mentions', 'ASR services'), ('chunk_92', 'mentions', 'word error rates'), ('chunk_92', 'mentions', 'Whisper'), ('chunk_92', 'mentions', 'TED-LIUM3'), ('chunk_92', 'mentions', 'Kincaid46'), ('chunk_92', 'mentions', 'Rev16'), ('chunk_92', 'mentions', 'Earnings-21'), ('chunk_92', 'mentions', 'Earnings-22'), ('chunk_92', 'mentions', 'CORAAL'), ('chunk_92', 'mentions', 'NVIDIA STT (CTC large)'), ('ASR services', 'are', 'commercial'), ('word error rates', 'are from', 'Whisper'), ('word error rates', 'are from', 'ASR services')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_93...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Whisper\", \"is competitive with\", \"state-of-the-art commercial and open-source ASR systems\"), (\"long-form transcription\", \"is a type of\", \"transcription\"), (\"word error rates\", \"are from\", \"ASR systems\"), (\"ASR systems\", \"are on\", \"long-form datasets\"), (\"input lengths\", \"range from\", \"few minutes\"), (\"input lengths\", \"range to\", \"few hours\"), (\"quartiles\", \"are of\", \"WERs\"), (\"WERs\", \"are per-example\", \"true\"), (\"WERs\", \"are annotated\", \"true\"), (\"chunk_93\", \"mentions\", \"Whisper\"), (\"chunk_93\", \"mentions\", \"state-of-the-art commercial and open-source ASR systems\"), (\"chunk_93\", \"mentions\", \"long-form transcription\"), (\"chunk_93\", \"mentions\", \"word error rates\"), (\"chunk_93\", \"mentions\", \"ASR systems\"), (\"chunk_93\", \"mentions\", \"long-form datasets\"), (\"chunk_93\", \"mentions\", \"input lengths\"), (\"chunk_93\", \"mentions\", \"minutes\"), (\"chunk_93\", \"mentions\", \"hours\"), (\"chunk_93\", \"mentions\", \"quartiles\"), (\"chunk_93\", \"mentions\", \"WERs\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_93\", \"is_core_chunk\", \"true\"), (\"state-of-the-art commercial and open-source ASR systems\", \"related_to_core\", \"Whisper\"), (\"long-form transcription\", \"related_to_core\", \"Whisper\"), (\"word error rates\", \"related_to_core\", \"Whisper\"), (\"ASR systems\", \"related_to_core\", \"Whisper\"), (\"long-form datasets\", \"related_to_core\", \"Whisper\"), (\"input lengths\", \"related_to_core\", \"Whisper\"), (\"minutes\", \"related_to_core\", \"Whisper\"), (\"hours\", \"related_to_core\", \"Whisper\"), (\"quartiles\", \"related_to_core\", \"Whisper\"), (\"WERs\", \"related_to_core\", \"Whisper\"), (\"minutes\", \"is a type of\", \"time\"), (\"hours\", \"is a type of\", \"time\")]\n",
            "✅ Extracted: [('Whisper', 'is competitive with', 'state-of-the-art commercial and open-source ASR systems'), ('long-form transcription', 'is a type of', 'transcription'), ('word error rates', 'are from', 'ASR systems'), ('ASR systems', 'are on', 'long-form datasets'), ('input lengths', 'range from', 'few minutes'), ('input lengths', 'range to', 'few hours'), ('quartiles', 'are of', 'WERs'), ('WERs', 'are per-example', 'true'), ('WERs', 'are annotated', 'true'), ('chunk_93', 'mentions', 'Whisper'), ('chunk_93', 'mentions', 'state-of-the-art commercial and open-source ASR systems'), ('chunk_93', 'mentions', 'long-form transcription'), ('chunk_93', 'mentions', 'word error rates'), ('chunk_93', 'mentions', 'ASR systems'), ('chunk_93', 'mentions', 'long-form datasets'), ('chunk_93', 'mentions', 'input lengths'), ('chunk_93', 'mentions', 'minutes'), ('chunk_93', 'mentions', 'hours'), ('chunk_93', 'mentions', 'quartiles'), ('chunk_93', 'mentions', 'WERs'), ('Whisper', 'is_core_idea', 'true'), ('chunk_93', 'is_core_chunk', 'true'), ('state-of-the-art commercial and open-source ASR systems', 'related_to_core', 'Whisper'), ('long-form transcription', 'related_to_core', 'Whisper'), ('word error rates', 'related_to_core', 'Whisper'), ('ASR systems', 'related_to_core', 'Whisper'), ('long-form datasets', 'related_to_core', 'Whisper'), ('input lengths', 'related_to_core', 'Whisper'), ('minutes', 'related_to_core', 'Whisper'), ('hours', 'related_to_core', 'Whisper'), ('quartiles', 'related_to_core', 'Whisper'), ('WERs', 'related_to_core', 'Whisper'), ('minutes', 'is a type of', 'time'), ('hours', 'is a type of', 'time')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_94...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"model\", \"outperforms\", \"NVIDIA STT\"), (\"model\", \"outperforms\", \"commercial ASR systems\"), (\"chunk_94\", \"mentions\", \"model\"), (\"chunk_94\", \"mentions\", \"NVIDIA STT\"), (\"chunk_94\", \"mentions\", \"datasets\"), (\"chunk_94\", \"mentions\", \"commercial ASR systems\"), (\"model\", \"is_core_idea\", \"true\"), (\"chunk_94\", \"is_core_chunk\", \"true\"), (\"NVIDIA STT\", \"related_to_core\", \"model\"), (\"datasets\", \"related_to_core\", \"model\"), (\"commercial ASR systems\", \"related_to_core\", \"model\")]\n",
            "✅ Extracted: [('model', 'outperforms', 'NVIDIA STT'), ('model', 'outperforms', 'commercial ASR systems'), ('chunk_94', 'mentions', 'model'), ('chunk_94', 'mentions', 'NVIDIA STT'), ('chunk_94', 'mentions', 'datasets'), ('chunk_94', 'mentions', 'commercial ASR systems'), ('model', 'is_core_idea', 'true'), ('chunk_94', 'is_core_chunk', 'true'), ('NVIDIA STT', 'related_to_core', 'model'), ('datasets', 'related_to_core', 'model'), ('commercial ASR systems', 'related_to_core', 'model')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_95...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"related_to_core\", \"NVIDIA STT Conformer-CTC Large model\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"NVIDIA STT Conformer-CTC Large model\"), (\"NVIDIA STT Conformer-CTC Large model\", \"is_core_idea\", \"true\"), (\"NeMo toolkit\", \"related_to_core\", \"NVIDIA STT Conformer-CTC Large model\"), (\"Kuchaiev et al.\", \"related_to_core\", \"NVIDIA STT Conformer-CTC Large model\"), (\"open-source models\", \"related_to_core\", \"NVIDIA STT Conformer-CTC Large model\"), (\"ASR services\", \"related_to_core\", \"NVIDIA STT Conformer-CTC Large model\"), (\"English transcription\", \"related_to_core\", \"NVIDIA STT Conformer-CTC Large model\"), (\"NVIDIA STT model\", \"related_to_core\", \"NVIDIA STT Conformer-CTC Large model\"), (\"buffered inference\", \"related_to_core\", \"NVIDIA STT Conformer-CTC Large model\"), (\"FrameBatchASR class\", \"related_to_core\", \"NVIDIA STT Conformer-CTC Large model\"), (\"chunk_95\", \"mentions\", \"Robust Speech Recognition\"), (\"chunk_95\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_95\", \"mentions\", \"NVIDIA STT Conformer-CTC Large model\"), (\"chunk_95\", \"mentions\", \"NeMo toolkit\"), (\"chunk_95\", \"mentions\", \"Kuchaiev et al.\"), (\"chunk_95\", \"mentions\", \"open-source models\"), (\"chunk_95\", \"mentions\", \"ASR services\"), (\"chunk_95\", \"mentions\", \"English transcription\"), (\"chunk_95\", \"mentions\", \"NVIDIA STT model\"), (\"chunk_95\", \"mentions\", \"buffered inference\"), (\"chunk_95\", \"mentions\", \"FrameBatchASR class\"), (\"chunk_95\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'related_to_core', 'NVIDIA STT Conformer-CTC Large model'), ('Large-Scale Weak Supervision', 'related_to_core', 'NVIDIA STT Conformer-CTC Large model'), ('NVIDIA STT Conformer-CTC Large model', 'is_core_idea', 'true'), ('NeMo toolkit', 'related_to_core', 'NVIDIA STT Conformer-CTC Large model'), ('Kuchaiev et al.', 'related_to_core', 'NVIDIA STT Conformer-CTC Large model'), ('open-source models', 'related_to_core', 'NVIDIA STT Conformer-CTC Large model'), ('ASR services', 'related_to_core', 'NVIDIA STT Conformer-CTC Large model'), ('English transcription', 'related_to_core', 'NVIDIA STT Conformer-CTC Large model'), ('NVIDIA STT model', 'related_to_core', 'NVIDIA STT Conformer-CTC Large model'), ('buffered inference', 'related_to_core', 'NVIDIA STT Conformer-CTC Large model'), ('FrameBatchASR class', 'related_to_core', 'NVIDIA STT Conformer-CTC Large model'), ('chunk_95', 'mentions', 'Robust Speech Recognition'), ('chunk_95', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_95', 'mentions', 'NVIDIA STT Conformer-CTC Large model'), ('chunk_95', 'mentions', 'NeMo toolkit'), ('chunk_95', 'mentions', 'Kuchaiev et al.'), ('chunk_95', 'mentions', 'open-source models'), ('chunk_95', 'mentions', 'ASR services'), ('chunk_95', 'mentions', 'English transcription'), ('chunk_95', 'mentions', 'NVIDIA STT model'), ('chunk_95', 'mentions', 'buffered inference'), ('chunk_95', 'mentions', 'FrameBatchASR class'), ('chunk_95', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_96...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Whisper\", \"performs_better_than\", \"compared models\"), (\"Whisper\", \"performs_on\", \"datasets\"), (\"Meanwhile dataset\", \"is_heavy_with\", \"uncommon words\"), (\"ASR systems\", \"have_been_trained_on\", \"datasets\"), (\"results\", \"reflecting\", \"robustness\"), (\"chunk_96\", \"mentions\", \"Whisper\"), (\"chunk_96\", \"mentions\", \"compared models\"), (\"chunk_96\", \"mentions\", \"datasets\"), (\"chunk_96\", \"mentions\", \"Meanwhile dataset\"), (\"chunk_96\", \"mentions\", \"uncommon words\"), (\"chunk_96\", \"mentions\", \"ASR systems\"), (\"chunk_96\", \"mentions\", \"results\"), (\"chunk_96\", \"mentions\", \"robustness\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_96\", \"is_core_chunk\", \"true\"), (\"compared models\", \"related_to_core\", \"Whisper\"), (\"datasets\", \"related_to_core\", \"Whisper\"), (\"Meanwhile dataset\", \"related_to_core\", \"Whisper\"), (\"uncommon words\", \"related_to_core\", \"Whisper\"), (\"ASR systems\", \"related_to_core\", \"Whisper\"), (\"results\", \"related_to_core\", \"Whisper\"), (\"robustness\", \"related_to_core\", \"Whisper\")]\n",
            "✅ Extracted: [('Whisper', 'performs_better_than', 'compared models'), ('Whisper', 'performs_on', 'datasets'), ('Meanwhile dataset', 'is_heavy_with', 'uncommon words'), ('ASR systems', 'have_been_trained_on', 'datasets'), ('results', 'reflecting', 'robustness'), ('chunk_96', 'mentions', 'Whisper'), ('chunk_96', 'mentions', 'compared models'), ('chunk_96', 'mentions', 'datasets'), ('chunk_96', 'mentions', 'Meanwhile dataset'), ('chunk_96', 'mentions', 'uncommon words'), ('chunk_96', 'mentions', 'ASR systems'), ('chunk_96', 'mentions', 'results'), ('chunk_96', 'mentions', 'robustness'), ('Whisper', 'is_core_idea', 'true'), ('chunk_96', 'is_core_chunk', 'true'), ('compared models', 'related_to_core', 'Whisper'), ('datasets', 'related_to_core', 'Whisper'), ('Meanwhile dataset', 'related_to_core', 'Whisper'), ('uncommon words', 'related_to_core', 'Whisper'), ('ASR systems', 'related_to_core', 'Whisper'), ('results', 'related_to_core', 'Whisper'), ('robustness', 'related_to_core', 'Whisper')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_97...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Human Performance\", \"is_core_idea\", \"true\"), (\"chunk_97\", \"is_core_chunk\", \"true\"), (\"chunk_97\", \"mentions\", \"Human Performance\"), (\"ambiguous speech\", \"related_to_core\", \"Human Performance\"), (\"indistinct speech\", \"related_to_core\", \"Human Performance\"), (\"labeling errors\", \"related_to_core\", \"Human Performance\"), (\"irreducible error\", \"related_to_core\", \"Human Performance\"), (\"WER metrics\", \"related_to_core\", \"Human Performance\"), (\"ASR systems\", \"related_to_core\", \"Human Performance\"), (\"Whisper's performance\", \"related_to_core\", \"Human Performance\"), (\"Kincaid46 dataset\", \"related_to_core\", \"Human Performance\"), (\"ambiguous speech\", \"is_a\", \"speech\"), (\"indistinct speech\", \"is_a\", \"speech\"), (\"chunk_97\", \"mentions\", \"ambiguous speech\"), (\"chunk_97\", \"mentions\", \"indistinct speech\"), (\"chunk_97\", \"mentions\", \"labeling errors\"), (\"chunk_97\", \"mentions\", \"irreducible error\"), (\"chunk_97\", \"mentions\", \"WER metrics\"), (\"chunk_97\", \"mentions\", \"ASR systems\"), (\"chunk_97\", \"mentions\", \"Whisper's performance\"), (\"chunk_97\", \"mentions\", \"Kincaid46 dataset\")]\n",
            "✅ Extracted: [('Human Performance', 'is_core_idea', 'true'), ('chunk_97', 'is_core_chunk', 'true'), ('chunk_97', 'mentions', 'Human Performance'), ('ambiguous speech', 'related_to_core', 'Human Performance'), ('indistinct speech', 'related_to_core', 'Human Performance'), ('labeling errors', 'related_to_core', 'Human Performance'), ('irreducible error', 'related_to_core', 'Human Performance'), ('WER metrics', 'related_to_core', 'Human Performance'), ('ASR systems', 'related_to_core', 'Human Performance'), (\"Whisper's performance\", 'related_to_core', 'Human Performance'), ('Kincaid46 dataset', 'related_to_core', 'Human Performance'), ('ambiguous speech', 'is_a', 'speech'), ('indistinct speech', 'is_a', 'speech'), ('chunk_97', 'mentions', 'ambiguous speech'), ('chunk_97', 'mentions', 'indistinct speech'), ('chunk_97', 'mentions', 'labeling errors'), ('chunk_97', 'mentions', 'irreducible error'), ('chunk_97', 'mentions', 'WER metrics'), ('chunk_97', 'mentions', 'ASR systems'), ('chunk_97', 'mentions', \"Whisper's performance\"), ('chunk_97', 'mentions', 'Kincaid46 dataset')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_98...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"transcripts\", \"produced_by\", \"professional transcribers\"), (\"computer-assisted transcription\", \"is_a\", \"service\"), (\"human-transcribed\", \"is_a\", \"service\"), (\"audio selection\", \"covers\", \"recording conditions\"), (\"recording conditions\", \"such_as\", \"scripted broadcast\"), (\"recording conditions\", \"such_as\", \"unscripted broadcast\"), (\"recording conditions\", \"such_as\", \"telephone calls\"), (\"recording conditions\", \"such_as\", \"VoIP calls\"), (\"recording conditions\", \"such_as\", \"meetings\"), (\"WERs\", \"distribution_shown_in\", \"Figure 7\"), (\"aggregate WER\", \"distribution_shown_in\", \"Figure 7\"), (\"chunk_98\", \"mentions\", \"transcripts\"), (\"chunk_98\", \"mentions\", \"professional transcribers\"), (\"chunk_98\", \"mentions\", \"computer-assisted transcription\"), (\"chunk_98\", \"mentions\", \"human-transcribed\"), (\"chunk_98\", \"mentions\", \"audio selection\"), (\"chunk_98\", \"mentions\", \"recording conditions\"), (\"chunk_98\", \"mentions\", \"scripted broadcast\"), (\"chunk_98\", \"mentions\", \"unscripted broadcast\"), (\"chunk_98\", \"mentions\", \"telephone calls\"), (\"chunk_98\", \"mentions\", \"VoIP calls\"), (\"chunk_98\", \"mentions\", \"meetings\"), (\"chunk_98\", \"mentions\", \"WERs\"), (\"chunk_98\", \"mentions\", \"aggregate WER\"), (\"computer-assisted transcription\", \"is_core_idea\", \"true\"), (\"chunk_98\", \"is_core_chunk\", \"true\"), (\"transcripts\", \"related_to_core\", \"computer-assisted transcription\"), (\"professional transcribers\", \"related_to_core\", \"computer-assisted transcription\"), (\"human-transcribed\", \"related_to_core\", \"computer-assisted transcription\"), (\"audio selection\", \"related_to_core\", \"computer-assisted transcription\"), (\"recording conditions\", \"related_to_core\", \"computer-assisted transcription\"), (\"scripted broadcast\", \"related_to_core\", \"computer-assisted transcription\"), (\"unscripted broadcast\", \"related_to_core\", \"computer-assisted transcription\"), (\"telephone calls\", \"related_to_core\", \"computer-assisted transcription\"), (\"VoIP calls\", \"related_to_core\", \"computer-assisted transcription\"), (\"meetings\", \"related_to_core\", \"computer-assisted transcription\"), (\"WERs\", \"related_to_core\", \"computer-assisted transcription\"), (\"aggregate WER\", \"related_to_core\", \"computer-assisted transcription\")]\n",
            "✅ Extracted: [('transcripts', 'produced_by', 'professional transcribers'), ('computer-assisted transcription', 'is_a', 'service'), ('human-transcribed', 'is_a', 'service'), ('audio selection', 'covers', 'recording conditions'), ('recording conditions', 'such_as', 'scripted broadcast'), ('recording conditions', 'such_as', 'unscripted broadcast'), ('recording conditions', 'such_as', 'telephone calls'), ('recording conditions', 'such_as', 'VoIP calls'), ('recording conditions', 'such_as', 'meetings'), ('WERs', 'distribution_shown_in', 'Figure 7'), ('aggregate WER', 'distribution_shown_in', 'Figure 7'), ('chunk_98', 'mentions', 'transcripts'), ('chunk_98', 'mentions', 'professional transcribers'), ('chunk_98', 'mentions', 'computer-assisted transcription'), ('chunk_98', 'mentions', 'human-transcribed'), ('chunk_98', 'mentions', 'audio selection'), ('chunk_98', 'mentions', 'recording conditions'), ('chunk_98', 'mentions', 'scripted broadcast'), ('chunk_98', 'mentions', 'unscripted broadcast'), ('chunk_98', 'mentions', 'telephone calls'), ('chunk_98', 'mentions', 'VoIP calls'), ('chunk_98', 'mentions', 'meetings'), ('chunk_98', 'mentions', 'WERs'), ('chunk_98', 'mentions', 'aggregate WER'), ('computer-assisted transcription', 'is_core_idea', 'true'), ('chunk_98', 'is_core_chunk', 'true'), ('transcripts', 'related_to_core', 'computer-assisted transcription'), ('professional transcribers', 'related_to_core', 'computer-assisted transcription'), ('human-transcribed', 'related_to_core', 'computer-assisted transcription'), ('audio selection', 'related_to_core', 'computer-assisted transcription'), ('recording conditions', 'related_to_core', 'computer-assisted transcription'), ('scripted broadcast', 'related_to_core', 'computer-assisted transcription'), ('unscripted broadcast', 'related_to_core', 'computer-assisted transcription'), ('telephone calls', 'related_to_core', 'computer-assisted transcription'), ('VoIP calls', 'related_to_core', 'computer-assisted transcription'), ('meetings', 'related_to_core', 'computer-assisted transcription'), ('WERs', 'related_to_core', 'computer-assisted transcription'), ('aggregate WER', 'related_to_core', 'computer-assisted transcription')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_99...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"WER\", \"is_core_idea\", \"true\"), (\"chunk_99\", \"is_core_chunk\", \"true\"), (\"Whisper\", \"related_to_core\", \"WER\"), (\"human performance\", \"related_to_core\", \"WER\"), (\"English ASR performance\", \"related_to_core\", \"WER\"), (\"human-level accuracy\", \"related_to_core\", \"WER\"), (\"Model Scaling\", \"related_to_core\", \"WER\"), (\"weakly supervised training approaches\", \"related_to_core\", \"WER\"), (\"WER\", \"predicate\", \"lowest aggregate\"), (\"Whisper\", \"possessive\", \"WER\"), (\"human performance\", \"better_than\", \"Whisper\"), (\"English ASR performance\", \"of\", \"Whisper\"), (\"English ASR performance\", \"is\", \"not perfect\"), (\"English ASR performance\", \"close_to\", \"human-level accuracy\"), (\"weakly supervised training approaches\", \"potential\", \"use datasets\"), (\"chunk_99\", \"mentions\", \"WER\"), (\"chunk_99\", \"mentions\", \"Whisper\"), (\"chunk_99\", \"mentions\", \"human performance\"), (\"chunk_99\", \"mentions\", \"English ASR performance\"), (\"chunk_99\", \"mentions\", \"human-level accuracy\"), (\"chunk_99\", \"mentions\", \"Model Scaling\"), (\"chunk_99\", \"mentions\", \"weakly supervised training approaches\")]\n",
            "✅ Extracted: [('WER', 'is_core_idea', 'true'), ('chunk_99', 'is_core_chunk', 'true'), ('Whisper', 'related_to_core', 'WER'), ('human performance', 'related_to_core', 'WER'), ('English ASR performance', 'related_to_core', 'WER'), ('human-level accuracy', 'related_to_core', 'WER'), ('Model Scaling', 'related_to_core', 'WER'), ('weakly supervised training approaches', 'related_to_core', 'WER'), ('WER', 'predicate', 'lowest aggregate'), ('Whisper', 'possessive', 'WER'), ('human performance', 'better_than', 'Whisper'), ('English ASR performance', 'of', 'Whisper'), ('English ASR performance', 'is', 'not perfect'), ('English ASR performance', 'close_to', 'human-level accuracy'), ('weakly supervised training approaches', 'potential', 'use datasets'), ('chunk_99', 'mentions', 'WER'), ('chunk_99', 'mentions', 'Whisper'), ('chunk_99', 'mentions', 'human performance'), ('chunk_99', 'mentions', 'English ASR performance'), ('chunk_99', 'mentions', 'human-level accuracy'), ('chunk_99', 'mentions', 'Model Scaling'), ('chunk_99', 'mentions', 'weakly supervised training approaches')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_100...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"supervised learning\", \"is_core_idea\", \"true\"), (\"chunk_100\", \"is_core_chunk\", \"true\"), (\"chunk_100\", \"mentions\", \"supervised learning\"), (\"data\", \"related_to_core\", \"supervised learning\"), (\"models\", \"related_to_core\", \"supervised learning\"), (\"dataset\", \"related_to_core\", \"supervised learning\"), (\"capacity\", \"related_to_core\", \"supervised learning\"), (\"compute\", \"related_to_core\", \"supervised learning\"), (\"data\", \"mentions\", \"data\"), (\"models\", \"mentions\", \"models\"), (\"dataset\", \"mentions\", \"dataset\"), (\"capacity\", \"mentions\", \"capacity\"), (\"compute\", \"mentions\", \"compute\")]\n",
            "✅ Extracted: [('supervised learning', 'is_core_idea', 'true'), ('chunk_100', 'is_core_chunk', 'true'), ('chunk_100', 'mentions', 'supervised learning'), ('data', 'related_to_core', 'supervised learning'), ('models', 'related_to_core', 'supervised learning'), ('dataset', 'related_to_core', 'supervised learning'), ('capacity', 'related_to_core', 'supervised learning'), ('compute', 'related_to_core', 'supervised learning'), ('data', 'mentions', 'data'), ('models', 'mentions', 'models'), ('dataset', 'mentions', 'dataset'), ('capacity', 'mentions', 'capacity'), ('compute', 'mentions', 'compute')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_101...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"dataset\", \"mentions\", \"Whisper\"), (\"dataset\", \"mentions\", \"ASR\"), (\"dataset\", \"mentions\", \"human transcription\"), (\"dataset\", \"mentions\", \"computer-assisted human transcription service\"), (\"dataset\", \"mentions\", \"Word Error Rate\"), (\"dataset\", \"mentions\", \"Kincaid46 dataset\"), (\"Whisper\", \"related_to_core\", \"Word Error Rate\"), (\"ASR\", \"related_to_core\", \"Word Error Rate\"), (\"human transcription\", \"related_to_core\", \"Word Error Rate\"), (\"computer-assisted human transcription service\", \"related_to_core\", \"Word Error Rate\"), (\"Kincaid46 dataset\", \"related_to_core\", \"Word Error Rate\"), (\"Whisper\", \"is_type_of\", \"ASR\"), (\"Whisper\", \"performance_compared_to\", \"human transcription\"), (\"Whisper\", \"performance_compared_to\", \"computer-assisted human transcription service\"), (\"Whisper\", \"performance_compared_to\", \"ASR\"), (\"Word Error Rate\", \"measures\", \"performance\"), (\"chunk_101\", \"mentions\", \"dataset\"), (\"chunk_101\", \"mentions\", \"Whisper\"), (\"chunk_101\", \"mentions\", \"ASR\"), (\"chunk_101\", \"mentions\", \"human transcription\"), (\"chunk_101\", \"mentions\", \"computer-assisted human transcription service\"), (\"chunk_101\", \"mentions\", \"Word Error Rate\"), (\"chunk_101\", \"mentions\", \"Kincaid46 dataset\"), (\"Word Error Rate\", \"is_core_idea\", \"true\"), (\"chunk_101\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('dataset', 'mentions', 'Whisper'), ('dataset', 'mentions', 'ASR'), ('dataset', 'mentions', 'human transcription'), ('dataset', 'mentions', 'computer-assisted human transcription service'), ('dataset', 'mentions', 'Word Error Rate'), ('dataset', 'mentions', 'Kincaid46 dataset'), ('Whisper', 'related_to_core', 'Word Error Rate'), ('ASR', 'related_to_core', 'Word Error Rate'), ('human transcription', 'related_to_core', 'Word Error Rate'), ('computer-assisted human transcription service', 'related_to_core', 'Word Error Rate'), ('Kincaid46 dataset', 'related_to_core', 'Word Error Rate'), ('Whisper', 'is_type_of', 'ASR'), ('Whisper', 'performance_compared_to', 'human transcription'), ('Whisper', 'performance_compared_to', 'computer-assisted human transcription service'), ('Whisper', 'performance_compared_to', 'ASR'), ('Word Error Rate', 'measures', 'performance'), ('chunk_101', 'mentions', 'dataset'), ('chunk_101', 'mentions', 'Whisper'), ('chunk_101', 'mentions', 'ASR'), ('chunk_101', 'mentions', 'human transcription'), ('chunk_101', 'mentions', 'computer-assisted human transcription service'), ('chunk_101', 'mentions', 'Word Error Rate'), ('chunk_101', 'mentions', 'Kincaid46 dataset'), ('Word Error Rate', 'is_core_idea', 'true'), ('chunk_101', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_102...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"human transcription services\", \"mentions\", \"chunk_102\"), (\"box plot\", \"mentions\", \"chunk_102\"), (\"WERs\", \"mentions\", \"chunk_102\"), (\"recordings\", \"mentions\", \"chunk_102\"), (\"aggregate WER\", \"mentions\", \"chunk_102\"), (\"dataset\", \"mentions\", \"chunk_102\"), (\"out-of-distribution data\", \"mentions\", \"chunk_102\"), (\"zero-shot generalization\", \"mentions\", \"chunk_102\"), (\"Whisper models\", \"mentions\", \"chunk_102\"), (\"model size\", \"mentions\", \"chunk_102\"), (\"Figure 8\", \"mentions\", \"chunk_102\"), (\"WERs\", \"on\", \"recordings\"), (\"aggregate WER\", \"over\", \"recordings\"), (\"zero-shot generalization\", \"of\", \"Whisper models\"), (\"chunk_102\", \"is_core_chunk\", \"true\"), (\"zero-shot generalization\", \"is_core_idea\", \"true\"), (\"human transcription services\", \"related_to_core\", \"zero-shot generalization\"), (\"box plot\", \"related_to_core\", \"zero-shot generalization\"), (\"WERs\", \"related_to_core\", \"zero-shot generalization\"), (\"recordings\", \"related_to_core\", \"zero-shot generalization\"), (\"aggregate WER\", \"related_to_core\", \"zero-shot generalization\"), (\"dataset\", \"related_to_core\", \"zero-shot generalization\"), (\"out-of-distribution data\", \"related_to_core\", \"zero-shot generalization\"), (\"Whisper models\", \"related_to_core\", \"zero-shot generalization\"), (\"model size\", \"related_to_core\", \"zero-shot generalization\"), (\"Figure 8\", \"related_to_core\", \"zero-shot generalization\")]\n",
            "✅ Extracted: [('human transcription services', 'mentions', 'chunk_102'), ('box plot', 'mentions', 'chunk_102'), ('WERs', 'mentions', 'chunk_102'), ('recordings', 'mentions', 'chunk_102'), ('aggregate WER', 'mentions', 'chunk_102'), ('dataset', 'mentions', 'chunk_102'), ('out-of-distribution data', 'mentions', 'chunk_102'), ('zero-shot generalization', 'mentions', 'chunk_102'), ('Whisper models', 'mentions', 'chunk_102'), ('model size', 'mentions', 'chunk_102'), ('Figure 8', 'mentions', 'chunk_102'), ('WERs', 'on', 'recordings'), ('aggregate WER', 'over', 'recordings'), ('zero-shot generalization', 'of', 'Whisper models'), ('chunk_102', 'is_core_chunk', 'true'), ('zero-shot generalization', 'is_core_idea', 'true'), ('human transcription services', 'related_to_core', 'zero-shot generalization'), ('box plot', 'related_to_core', 'zero-shot generalization'), ('WERs', 'related_to_core', 'zero-shot generalization'), ('recordings', 'related_to_core', 'zero-shot generalization'), ('aggregate WER', 'related_to_core', 'zero-shot generalization'), ('dataset', 'related_to_core', 'zero-shot generalization'), ('out-of-distribution data', 'related_to_core', 'zero-shot generalization'), ('Whisper models', 'related_to_core', 'zero-shot generalization'), ('model size', 'related_to_core', 'zero-shot generalization'), ('Figure 8', 'related_to_core', 'zero-shot generalization')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_103...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"English speech recognition\", \"performance\", \"increase\"), (\"chunk_103\", \"mentions\", \"English speech recognition\"), (\"chunk_103\", \"mentions\", \"multilingual speech recognition\"), (\"multilingual speech recognition\", \"related_to_core\", \"speech recognition\"), (\"speech translation\", \"related_to_core\", \"speech recognition\"), (\"language identiﬁcation\", \"related_to_core\", \"speech recognition\"), (\"speech recognition\", \"is_core_idea\", \"true\"), (\"chunk_103\", \"is_core_chunk\", \"true\"), (\"chunk_103\", \"mentions\", \"speech translation\"), (\"chunk_103\", \"mentions\", \"language identiﬁcation\"), (\"saturation effects\", \"related_to_core\", \"speech recognition\"), (\"human-level performance\", \"related_to_core\", \"speech recognition\"), (\"analysis\", \"related_to_core\", \"speech recognition\"), (\"Whisper dataset\", \"related_to_core\", \"speech recognition\"), (\"supervised speech recognition\", \"related_to_core\", \"speech recognition\"), (\"chunk_103\", \"mentions\", \"saturation effects\"), (\"chunk_103\", \"mentions\", \"human-level performance\"), (\"chunk_103\", \"mentions\", \"analysis\"), (\"chunk_103\", \"mentions\", \"Whisper dataset\"), (\"chunk_103\", \"mentions\", \"supervised speech recognition\"), (\"Whisper dataset\", \"hours\", \"680,000\"), (\"chunk_103\", \"mentions\", \"speech recognition\")]\n",
            "✅ Extracted: [('English speech recognition', 'performance', 'increase'), ('chunk_103', 'mentions', 'English speech recognition'), ('chunk_103', 'mentions', 'multilingual speech recognition'), ('multilingual speech recognition', 'related_to_core', 'speech recognition'), ('speech translation', 'related_to_core', 'speech recognition'), ('language identiﬁcation', 'related_to_core', 'speech recognition'), ('speech recognition', 'is_core_idea', 'true'), ('chunk_103', 'is_core_chunk', 'true'), ('chunk_103', 'mentions', 'speech translation'), ('chunk_103', 'mentions', 'language identiﬁcation'), ('saturation effects', 'related_to_core', 'speech recognition'), ('human-level performance', 'related_to_core', 'speech recognition'), ('analysis', 'related_to_core', 'speech recognition'), ('Whisper dataset', 'related_to_core', 'speech recognition'), ('supervised speech recognition', 'related_to_core', 'speech recognition'), ('chunk_103', 'mentions', 'saturation effects'), ('chunk_103', 'mentions', 'human-level performance'), ('chunk_103', 'mentions', 'analysis'), ('chunk_103', 'mentions', 'Whisper dataset'), ('chunk_103', 'mentions', 'supervised speech recognition'), ('Whisper dataset', 'hours', '680,000'), ('chunk_103', 'mentions', 'speech recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_104...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"dataset size\", \"related_to_core\", \"Whisper's performance\"), (\"medium-sized models\", \"related_to_core\", \"Whisper's performance\"), (\"subsampled versions\", \"related_to_core\", \"Whisper's performance\"), (\"validation loss\", \"related_to_core\", \"Whisper's performance\"), (\"model checkpoints\", \"related_to_core\", \"Whisper's performance\"), (\"chunk_104\", \"mentions\", \"dataset size\"), (\"chunk_104\", \"mentions\", \"Whisper's performance\"), (\"chunk_104\", \"mentions\", \"medium-sized models\"), (\"chunk_104\", \"mentions\", \"subsampled versions\"), (\"chunk_104\", \"mentions\", \"validation loss\"), (\"chunk_104\", \"mentions\", \"model checkpoints\"), (\"Whisper's performance\", \"is_core_idea\", \"true\"), (\"chunk_104\", \"is_core_chunk\", \"true\"), (\"medium-sized models\", \"trained on\", \"subsampled versions\"), (\"medium-sized models\", \"trained on\", \"dataset\"), (\"Early stopping\", \"based on\", \"validation loss\")]\n",
            "✅ Extracted: [('dataset size', 'related_to_core', \"Whisper's performance\"), ('medium-sized models', 'related_to_core', \"Whisper's performance\"), ('subsampled versions', 'related_to_core', \"Whisper's performance\"), ('validation loss', 'related_to_core', \"Whisper's performance\"), ('model checkpoints', 'related_to_core', \"Whisper's performance\"), ('chunk_104', 'mentions', 'dataset size'), ('chunk_104', 'mentions', \"Whisper's performance\"), ('chunk_104', 'mentions', 'medium-sized models'), ('chunk_104', 'mentions', 'subsampled versions'), ('chunk_104', 'mentions', 'validation loss'), ('chunk_104', 'mentions', 'model checkpoints'), (\"Whisper's performance\", 'is_core_idea', 'true'), ('chunk_104', 'is_core_chunk', 'true'), ('medium-sized models', 'trained on', 'subsampled versions'), ('medium-sized models', 'trained on', 'dataset'), ('Early stopping', 'based on', 'validation loss')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_105...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"exponential moving average estimate\", \"is_core_idea\", \"true\"), (\"chunk_105\", \"is_core_chunk\", \"true\"), (\"chunk_105\", \"mentions\", \"exponential moving average estimate\"), (\"parameters\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"parameters\"), (\"Polyak & Juditsky\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"Polyak & Juditsky\"), (\"smoothing rate\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"smoothing rate\"), (\"learning rate\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"learning rate\"), (\"models\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"models\"), (\"subsampled datasets\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"subsampled datasets\"), (\"early stopping\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"early stopping\"), (\"English\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"English\"), (\"multilingual speech recognition\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"multilingual speech recognition\"), (\"X→en translation\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"X→en translation\"), (\"Table 6\", \"related_to_core\", \"exponential moving average estimate\"), (\"chunk_105\", \"mentions\", \"Table 6\")]\n",
            "✅ Extracted: [('exponential moving average estimate', 'is_core_idea', 'true'), ('chunk_105', 'is_core_chunk', 'true'), ('chunk_105', 'mentions', 'exponential moving average estimate'), ('parameters', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'parameters'), ('Polyak & Juditsky', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'Polyak & Juditsky'), ('smoothing rate', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'smoothing rate'), ('learning rate', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'learning rate'), ('models', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'models'), ('subsampled datasets', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'subsampled datasets'), ('early stopping', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'early stopping'), ('English', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'English'), ('multilingual speech recognition', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'multilingual speech recognition'), ('X→en translation', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'X→en translation'), ('Table 6', 'related_to_core', 'exponential moving average estimate'), ('chunk_105', 'mentions', 'Table 6')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_106...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_106\", \"is_core_chunk\", \"true\"), (\"Robust Speech Recognition\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Model parameters\", \"related_to_core\", \"Robust Speech Recognition\"), (\"English Speech Recognition\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Multilingual Speech Recognition\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Fleurs\", \"related_to_core\", \"Robust Speech Recognition\"), (\"X->En Translation\", \"related_to_core\", \"Robust Speech Recognition\"), (\"CoVoST2\", \"related_to_core\", \"Robust Speech Recognition\"), (\"WER\", \"related_to_core\", \"Robust Speech Recognition\"), (\"BLEU\", \"related_to_core\", \"Robust Speech Recognition\"), (\"chunk_106\", \"mentions\", \"Robust Speech Recognition\"), (\"chunk_106\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_106\", \"mentions\", \"Model parameters\"), (\"chunk_106\", \"mentions\", \"English Speech Recognition\"), (\"chunk_106\", \"mentions\", \"Multilingual Speech Recognition\"), (\"chunk_106\", \"mentions\", \"Fleurs\"), (\"chunk_106\", \"mentions\", \"X->En Translation\"), (\"chunk_106\", \"mentions\", \"CoVoST2\"), (\"chunk_106\", \"mentions\", \"WER\"), (\"chunk_106\", \"mentions\", \"BLEU\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'is_core_idea', 'true'), ('chunk_106', 'is_core_chunk', 'true'), ('Robust Speech Recognition', 'related_to_core', 'Robust Speech Recognition'), ('Large-Scale Weak Supervision', 'related_to_core', 'Robust Speech Recognition'), ('Model parameters', 'related_to_core', 'Robust Speech Recognition'), ('English Speech Recognition', 'related_to_core', 'Robust Speech Recognition'), ('Multilingual Speech Recognition', 'related_to_core', 'Robust Speech Recognition'), ('Fleurs', 'related_to_core', 'Robust Speech Recognition'), ('X->En Translation', 'related_to_core', 'Robust Speech Recognition'), ('CoVoST2', 'related_to_core', 'Robust Speech Recognition'), ('WER', 'related_to_core', 'Robust Speech Recognition'), ('BLEU', 'related_to_core', 'Robust Speech Recognition'), ('chunk_106', 'mentions', 'Robust Speech Recognition'), ('chunk_106', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_106', 'mentions', 'Model parameters'), ('chunk_106', 'mentions', 'English Speech Recognition'), ('chunk_106', 'mentions', 'Multilingual Speech Recognition'), ('chunk_106', 'mentions', 'Fleurs'), ('chunk_106', 'mentions', 'X->En Translation'), ('chunk_106', 'mentions', 'CoVoST2'), ('chunk_106', 'mentions', 'WER'), ('chunk_106', 'mentions', 'BLEU')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_107...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"X->En Translation\", \"related_to_core\", \"Whisper performance\"), (\"CoVoST2\", \"related_to_core\", \"Whisper performance\"), (\"Large V2\", \"related_to_core\", \"Whisper performance\"), (\"Model parameters\", \"related_to_core\", \"Whisper performance\"), (\"Accuracy\", \"related_to_core\", \"Whisper performance\"), (\"Language Identification\", \"related_to_core\", \"Whisper performance\"), (\"Fleurs\", \"related_to_core\", \"Whisper performance\"), (\"Zero-shot Whisper performance\", \"is_core_idea\", \"true\"), (\"Whisper performance\", \"is_core_idea\", \"true\"), (\"chunk_107\", \"is_core_chunk\", \"true\"), (\"datasets\", \"related_to_core\", \"Whisper performance\"), (\"languages\", \"related_to_core\", \"Whisper performance\"), (\"X->En Translation\", \"mentions\", \"CoVoST2\"), (\"chunk_107\", \"mentions\", \"X->En Translation\"), (\"chunk_107\", \"mentions\", \"Large V2\"), (\"chunk_107\", \"mentions\", \"Model parameters\"), (\"chunk_107\", \"mentions\", \"Accuracy\"), (\"chunk_107\", \"mentions\", \"Language Identification\"), (\"chunk_107\", \"mentions\", \"Fleurs\"), (\"chunk_107\", \"mentions\", \"Zero-shot Whisper performance\"), (\"chunk_107\", \"mentions\", \"datasets\"), (\"chunk_107\", \"mentions\", \"languages\")]\n",
            "✅ Extracted: [('X->En Translation', 'related_to_core', 'Whisper performance'), ('CoVoST2', 'related_to_core', 'Whisper performance'), ('Large V2', 'related_to_core', 'Whisper performance'), ('Model parameters', 'related_to_core', 'Whisper performance'), ('Accuracy', 'related_to_core', 'Whisper performance'), ('Language Identification', 'related_to_core', 'Whisper performance'), ('Fleurs', 'related_to_core', 'Whisper performance'), ('Zero-shot Whisper performance', 'is_core_idea', 'true'), ('Whisper performance', 'is_core_idea', 'true'), ('chunk_107', 'is_core_chunk', 'true'), ('datasets', 'related_to_core', 'Whisper performance'), ('languages', 'related_to_core', 'Whisper performance'), ('X->En Translation', 'mentions', 'CoVoST2'), ('chunk_107', 'mentions', 'X->En Translation'), ('chunk_107', 'mentions', 'Large V2'), ('chunk_107', 'mentions', 'Model parameters'), ('chunk_107', 'mentions', 'Accuracy'), ('chunk_107', 'mentions', 'Language Identification'), ('chunk_107', 'mentions', 'Fleurs'), ('chunk_107', 'mentions', 'Zero-shot Whisper performance'), ('chunk_107', 'mentions', 'datasets'), ('chunk_107', 'mentions', 'languages')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_108...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Large V2\", \"mentions\", \"Large V2\"), (\"chunk_108\", \"mentions\", \"Large V2\"), (\"dashed orange line\", \"mentions\", \"dashed orange line\"), (\"chunk_108\", \"mentions\", \"dashed orange line\"), (\"models\", \"mentions\", \"models\"), (\"chunk_108\", \"mentions\", \"models\"), (\"analysis\", \"mentions\", \"analysis\"), (\"chunk_108\", \"mentions\", \"analysis\"), (\"Dataset\", \"mentions\", \"Dataset\"), (\"chunk_108\", \"mentions\", \"Dataset\"), (\"English Multilingual X →En\", \"mentions\", \"English Multilingual X →En\"), (\"chunk_108\", \"mentions\", \"English Multilingual X →En\"), (\"WER\", \"mentions\", \"WER\"), (\"chunk_108\", \"mentions\", \"WER\"), (\"BLEU\", \"mentions\", \"BLEU\"), (\"chunk_108\", \"mentions\", \"BLEU\"), (\"dataset size\", \"mentions\", \"dataset size\"), (\"chunk_108\", \"mentions\", \"dataset size\"), (\"dataset size\", \"is_core_idea\", \"true\"), (\"chunk_108\", \"is_core_chunk\", \"true\"), (\"Large V2\", \"related_to_core\", \"dataset size\"), (\"dashed orange line\", \"related_to_core\", \"dataset size\"), (\"models\", \"related_to_core\", \"dataset size\"), (\"analysis\", \"related_to_core\", \"dataset size\"), (\"Dataset\", \"related_to_core\", \"dataset size\"), (\"English Multilingual X →En\", \"related_to_core\", \"dataset size\"), (\"WER\", \"related_to_core\", \"dataset size\"), (\"BLEU\", \"related_to_core\", \"dataset size\")]\n",
            "✅ Extracted: [('Large V2', 'mentions', 'Large V2'), ('chunk_108', 'mentions', 'Large V2'), ('dashed orange line', 'mentions', 'dashed orange line'), ('chunk_108', 'mentions', 'dashed orange line'), ('models', 'mentions', 'models'), ('chunk_108', 'mentions', 'models'), ('analysis', 'mentions', 'analysis'), ('chunk_108', 'mentions', 'analysis'), ('Dataset', 'mentions', 'Dataset'), ('chunk_108', 'mentions', 'Dataset'), ('English Multilingual X →En', 'mentions', 'English Multilingual X →En'), ('chunk_108', 'mentions', 'English Multilingual X →En'), ('WER', 'mentions', 'WER'), ('chunk_108', 'mentions', 'WER'), ('BLEU', 'mentions', 'BLEU'), ('chunk_108', 'mentions', 'BLEU'), ('dataset size', 'mentions', 'dataset size'), ('chunk_108', 'mentions', 'dataset size'), ('dataset size', 'is_core_idea', 'true'), ('chunk_108', 'is_core_chunk', 'true'), ('Large V2', 'related_to_core', 'dataset size'), ('dashed orange line', 'related_to_core', 'dataset size'), ('models', 'related_to_core', 'dataset size'), ('analysis', 'related_to_core', 'dataset size'), ('Dataset', 'related_to_core', 'dataset size'), ('English Multilingual X →En', 'related_to_core', 'dataset size'), ('WER', 'related_to_core', 'dataset size'), ('BLEU', 'related_to_core', 'dataset size')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_109...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Multilingual speech recognition\", \"reports\", \"performance\"), (\"Fleurs\", \"is_subset_of\", \"languages\"), (\"X→en translation\", \"reports\", \"BLEU\"), (\"CoV oST2\", \"is_measured_by\", \"BLEU\"), (\"dataset size\", \"reported_in\", \"hours\"), (\"increases\", \"result_in\", \"improved performance\"), (\"English speech recognition\", \"improves\", \"performance\"), (\"chunk_109\", \"mentions\", \"Multilingual speech recognition\"), (\"chunk_109\", \"mentions\", \"Fleurs\"), (\"chunk_109\", \"mentions\", \"X→en translation\"), (\"chunk_109\", \"mentions\", \"BLEU\"), (\"chunk_109\", \"mentions\", \"CoV oST2\"), (\"chunk_109\", \"mentions\", \"dataset size\"), (\"chunk_109\", \"mentions\", \"increases\"), (\"chunk_109\", \"mentions\", \"improved performance\"), (\"chunk_109\", \"mentions\", \"English speech recognition\"), (\"dataset size\", \"is_core_idea\", \"true\"), (\"chunk_109\", \"is_core_chunk\", \"true\"), (\"Multilingual speech recognition\", \"related_to_core\", \"dataset size\"), (\"Fleurs\", \"related_to_core\", \"dataset size\"), (\"X→en translation\", \"related_to_core\", \"dataset size\"), (\"BLEU\", \"related_to_core\", \"dataset size\"), (\"CoV oST2\", \"related_to_core\", \"dataset size\"), (\"increases\", \"related_to_core\", \"dataset size\"), (\"improved performance\", \"related_to_core\", \"dataset size\"), (\"English speech recognition\", \"related_to_core\", \"dataset size\")]\n",
            "✅ Extracted: [('Multilingual speech recognition', 'reports', 'performance'), ('Fleurs', 'is_subset_of', 'languages'), ('X→en translation', 'reports', 'BLEU'), ('CoV oST2', 'is_measured_by', 'BLEU'), ('dataset size', 'reported_in', 'hours'), ('increases', 'result_in', 'improved performance'), ('English speech recognition', 'improves', 'performance'), ('chunk_109', 'mentions', 'Multilingual speech recognition'), ('chunk_109', 'mentions', 'Fleurs'), ('chunk_109', 'mentions', 'X→en translation'), ('chunk_109', 'mentions', 'BLEU'), ('chunk_109', 'mentions', 'CoV oST2'), ('chunk_109', 'mentions', 'dataset size'), ('chunk_109', 'mentions', 'increases'), ('chunk_109', 'mentions', 'improved performance'), ('chunk_109', 'mentions', 'English speech recognition'), ('dataset size', 'is_core_idea', 'true'), ('chunk_109', 'is_core_chunk', 'true'), ('Multilingual speech recognition', 'related_to_core', 'dataset size'), ('Fleurs', 'related_to_core', 'dataset size'), ('X→en translation', 'related_to_core', 'dataset size'), ('BLEU', 'related_to_core', 'dataset size'), ('CoV oST2', 'related_to_core', 'dataset size'), ('increases', 'related_to_core', 'dataset size'), ('improved performance', 'related_to_core', 'dataset size'), ('English speech recognition', 'related_to_core', 'dataset size')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_110...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"hours\", \"unit\", \"13,000\"), (\"hours\", \"unit\", \"54,000\"), (\"dataset\", \"has_size_increase\", \"12.5\"), (\"WER\", \"decrease\", \"1 point\"), (\"model size scaling\", \"observed_in\", \"English speech recognition\"), (\"saturation effects\", \"explanation_for\", \"diminishing returns\"), (\"human-level performance\", \"approached_by\", \"saturation effects\"), (\"WER\", \"follow\", \"power-law trend\"), (\"chunk_110\", \"mentions\", \"hours\"), (\"chunk_110\", \"mentions\", \"dataset\"), (\"chunk_110\", \"mentions\", \"WER\"), (\"chunk_110\", \"mentions\", \"model size scaling\"), (\"chunk_110\", \"mentions\", \"English speech recognition\"), (\"chunk_110\", \"mentions\", \"saturation effects\"), (\"chunk_110\", \"mentions\", \"human-level performance\"), (\"chunk_110\", \"is_core_chunk\", \"true\"), (\"WER\", \"is_core_idea\", \"true\"), (\"hours\", \"related_to_core\", \"WER\"), (\"dataset\", \"related_to_core\", \"WER\"), (\"model size scaling\", \"related_to_core\", \"WER\"), (\"English speech recognition\", \"related_to_core\", \"WER\"), (\"saturation effects\", \"related_to_core\", \"WER\"), (\"human-level performance\", \"related_to_core\", \"WER\")]\n",
            "✅ Extracted: [('hours', 'unit', '13,000'), ('hours', 'unit', '54,000'), ('dataset', 'has_size_increase', '12.5'), ('WER', 'decrease', '1 point'), ('model size scaling', 'observed_in', 'English speech recognition'), ('saturation effects', 'explanation_for', 'diminishing returns'), ('human-level performance', 'approached_by', 'saturation effects'), ('WER', 'follow', 'power-law trend'), ('chunk_110', 'mentions', 'hours'), ('chunk_110', 'mentions', 'dataset'), ('chunk_110', 'mentions', 'WER'), ('chunk_110', 'mentions', 'model size scaling'), ('chunk_110', 'mentions', 'English speech recognition'), ('chunk_110', 'mentions', 'saturation effects'), ('chunk_110', 'mentions', 'human-level performance'), ('chunk_110', 'is_core_chunk', 'true'), ('WER', 'is_core_idea', 'true'), ('hours', 'related_to_core', 'WER'), ('dataset', 'related_to_core', 'WER'), ('model size scaling', 'related_to_core', 'WER'), ('English speech recognition', 'related_to_core', 'WER'), ('saturation effects', 'related_to_core', 'WER'), ('human-level performance', 'related_to_core', 'WER')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_111...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Multilingual speech recognition\", \"mentions\", \"Multilingual speech recognition\"), (\"chunk_111\", \"mentions\", \"Multilingual speech recognition\"), (\"7,000 hours of audio\", \"mentions\", \"7,000 hours of audio\"), (\"chunk_111\", \"mentions\", \"7,000 hours of audio\"), (\"X→en translation\", \"mentions\", \"X→en translation\"), (\"chunk_111\", \"mentions\", \"X→en translation\"), (\"54,000 hours\", \"mentions\", \"54,000 hours\"), (\"chunk_111\", \"mentions\", \"54,000 hours\"), (\"dataset size\", \"mentions\", \"dataset size\"), (\"chunk_111\", \"mentions\", \"dataset size\"), (\"diminishing returns\", \"mentions\", \"diminishing returns\"), (\"chunk_111\", \"mentions\", \"diminishing returns\"), (\"diminishing returns\", \"is_core_idea\", \"true\"), (\"chunk_111\", \"is_core_chunk\", \"true\"), (\"Multilingual speech recognition\", \"related_to_core\", \"diminishing returns\"), (\"7,000 hours of audio\", \"related_to_core\", \"diminishing returns\"), (\"X→en translation\", \"related_to_core\", \"diminishing returns\"), (\"54,000 hours\", \"related_to_core\", \"diminishing returns\"), (\"dataset size\", \"related_to_core\", \"diminishing returns\")]\n",
            "✅ Extracted: [('Multilingual speech recognition', 'mentions', 'Multilingual speech recognition'), ('chunk_111', 'mentions', 'Multilingual speech recognition'), ('7,000 hours of audio', 'mentions', '7,000 hours of audio'), ('chunk_111', 'mentions', '7,000 hours of audio'), ('X→en translation', 'mentions', 'X→en translation'), ('chunk_111', 'mentions', 'X→en translation'), ('54,000 hours', 'mentions', '54,000 hours'), ('chunk_111', 'mentions', '54,000 hours'), ('dataset size', 'mentions', 'dataset size'), ('chunk_111', 'mentions', 'dataset size'), ('diminishing returns', 'mentions', 'diminishing returns'), ('chunk_111', 'mentions', 'diminishing returns'), ('diminishing returns', 'is_core_idea', 'true'), ('chunk_111', 'is_core_chunk', 'true'), ('Multilingual speech recognition', 'related_to_core', 'diminishing returns'), ('7,000 hours of audio', 'related_to_core', 'diminishing returns'), ('X→en translation', 'related_to_core', 'diminishing returns'), ('54,000 hours', 'related_to_core', 'diminishing returns'), ('dataset size', 'related_to_core', 'diminishing returns')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_112...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"hours\", \"is_unit_of\", \"54,000 hours\"), (\"chunk_112\", \"mentions\", \"54,000 hours\"), (\"hours\", \"is_unit_of\", \"680,000 hours\"), (\"chunk_112\", \"mentions\", \"680,000 hours\"), (\"Whisper models\", \"related_to\", \"dataset size\"), (\"Whisper models\", \"related_to\", \"performance\"), (\"chunk_112\", \"mentions\", \"Whisper models\"), (\"dataset size\", \"related_to\", \"performance\"), (\"chunk_112\", \"mentions\", \"dataset size\"), (\"chunk_112\", \"mentions\", \"performance\"), (\"training\", \"related_to\", \"models\"), (\"chunk_112\", \"mentions\", \"training\"), (\"chunk_112\", \"mentions\", \"models\"), (\"dataset size scaling\", \"related_to\", \"speech recognition\"), (\"chunk_112\", \"mentions\", \"dataset size scaling\"), (\"chunk_112\", \"mentions\", \"speech recognition\"), (\"scaling laws\", \"related_to\", \"speech recognition\"), (\"chunk_112\", \"mentions\", \"scaling laws\"), (\"analysis\", \"related_to\", \"scaling laws\"), (\"chunk_112\", \"mentions\", \"analysis\"), (\"speech recognition\", \"is_core_idea\", \"true\"), (\"chunk_112\", \"is_core_chunk\", \"true\"), (\"54,000 hours\", \"related_to_core\", \"speech recognition\"), (\"680,000 hours\", \"related_to_core\", \"speech recognition\"), (\"Whisper models\", \"related_to_core\", \"speech recognition\"), (\"dataset size\", \"related_to_core\", \"speech recognition\"), (\"performance\", \"related_to_core\", \"speech recognition\"), (\"training\", \"related_to_core\", \"speech recognition\"), (\"models\", \"related_to_core\", \"speech recognition\"), (\"dataset size scaling\", \"related_to_core\", \"speech recognition\"), (\"scaling laws\", \"related_to_core\", \"speech recognition\"), (\"analysis\", \"related_to_core\", \"speech recognition\")]\n",
            "✅ Extracted: [('hours', 'is_unit_of', '54,000 hours'), ('chunk_112', 'mentions', '54,000 hours'), ('hours', 'is_unit_of', '680,000 hours'), ('chunk_112', 'mentions', '680,000 hours'), ('Whisper models', 'related_to', 'dataset size'), ('Whisper models', 'related_to', 'performance'), ('chunk_112', 'mentions', 'Whisper models'), ('dataset size', 'related_to', 'performance'), ('chunk_112', 'mentions', 'dataset size'), ('chunk_112', 'mentions', 'performance'), ('training', 'related_to', 'models'), ('chunk_112', 'mentions', 'training'), ('chunk_112', 'mentions', 'models'), ('dataset size scaling', 'related_to', 'speech recognition'), ('chunk_112', 'mentions', 'dataset size scaling'), ('chunk_112', 'mentions', 'speech recognition'), ('scaling laws', 'related_to', 'speech recognition'), ('chunk_112', 'mentions', 'scaling laws'), ('analysis', 'related_to', 'scaling laws'), ('chunk_112', 'mentions', 'analysis'), ('speech recognition', 'is_core_idea', 'true'), ('chunk_112', 'is_core_chunk', 'true'), ('54,000 hours', 'related_to_core', 'speech recognition'), ('680,000 hours', 'related_to_core', 'speech recognition'), ('Whisper models', 'related_to_core', 'speech recognition'), ('dataset size', 'related_to_core', 'speech recognition'), ('performance', 'related_to_core', 'speech recognition'), ('training', 'related_to_core', 'speech recognition'), ('models', 'related_to_core', 'speech recognition'), ('dataset size scaling', 'related_to_core', 'speech recognition'), ('scaling laws', 'related_to_core', 'speech recognition'), ('analysis', 'related_to_core', 'speech recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_113...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Multitask\", \"related_to_core\", \"Multilingual Transfer\"), (\"Multilingual Transfer\", \"is_core_idea\", \"true\"), (\"chunk_113\", \"is_core_chunk\", \"true\"), (\"Negative transfer\", \"related_to_core\", \"Multilingual Transfer\"), (\"English speech recognition\", \"related_to_core\", \"Multilingual Transfer\"), (\"Multitask\", \"mentions\", \"Multilingual Transfer\"), (\"Multilingual Transfer\", \"mentions\", \"Multilingual Transfer\"), (\"Negative transfer\", \"mentions\", \"Negative transfer\"), (\"English speech recognition\", \"mentions\", \"English speech recognition\")]\n",
            "✅ Extracted: [('Multitask', 'related_to_core', 'Multilingual Transfer'), ('Multilingual Transfer', 'is_core_idea', 'true'), ('chunk_113', 'is_core_chunk', 'true'), ('Negative transfer', 'related_to_core', 'Multilingual Transfer'), ('English speech recognition', 'related_to_core', 'Multilingual Transfer'), ('Multitask', 'mentions', 'Multilingual Transfer'), ('Multilingual Transfer', 'mentions', 'Multilingual Transfer'), ('Negative transfer', 'mentions', 'Negative transfer'), ('English speech recognition', 'mentions', 'English speech recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_114...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"multitask training\", \"related_to_core\", \"English speech recognition\"), (\"multilingual training\", \"related_to_core\", \"English speech recognition\"), (\"multitask training\", \"is_core_idea\", \"false\"), (\"multilingual training\", \"is_core_idea\", \"false\"), (\"English speech recognition\", \"is_core_idea\", \"true\"), (\"FLOPs\", \"related_to_core\", \"English speech recognition\"), (\"English-only model\", \"related_to_core\", \"English speech recognition\"), (\"chunk_114\", \"mentions\", \"multitask training\"), (\"chunk_114\", \"mentions\", \"multilingual training\"), (\"chunk_114\", \"mentions\", \"English speech recognition\"), (\"chunk_114\", \"mentions\", \"FLOPs\"), (\"chunk_114\", \"mentions\", \"English-only model\"), (\"chunk_114\", \"is_core_chunk\", \"true\"), (\"training setup\", \"predicate\", \"multitask training\"), (\"training setup\", \"predicate\", \"multilingual training\"), (\"compute\", \"predicate\", \"spent training\"), (\"amount\", \"predicate\", \"FLOPs\")]\n",
            "✅ Extracted: [('multitask training', 'related_to_core', 'English speech recognition'), ('multilingual training', 'related_to_core', 'English speech recognition'), ('multitask training', 'is_core_idea', 'false'), ('multilingual training', 'is_core_idea', 'false'), ('English speech recognition', 'is_core_idea', 'true'), ('FLOPs', 'related_to_core', 'English speech recognition'), ('English-only model', 'related_to_core', 'English speech recognition'), ('chunk_114', 'mentions', 'multitask training'), ('chunk_114', 'mentions', 'multilingual training'), ('chunk_114', 'mentions', 'English speech recognition'), ('chunk_114', 'mentions', 'FLOPs'), ('chunk_114', 'mentions', 'English-only model'), ('chunk_114', 'is_core_chunk', 'true'), ('training setup', 'predicate', 'multitask training'), ('training setup', 'predicate', 'multilingual training'), ('compute', 'predicate', 'spent training'), ('amount', 'predicate', 'FLOPs')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_115...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"English-only model\", \"mentions\", \"English-only model\"), (\"chunk_115\", \"mentions\", \"English-only model\"), (\"Figure 9\", \"mentions\", \"Figure 9\"), (\"small models\", \"mentions\", \"small models\"), (\"moderate amounts of compute\", \"mentions\", \"moderate amounts of compute\"), (\"negative transfer\", \"mentions\", \"negative transfer\"), (\"tasks\", \"mentions\", \"tasks\"), (\"languages\", \"mentions\", \"languages\"), (\"joint models\", \"mentions\", \"joint models\"), (\"English-only models\", \"mentions\", \"English-only models\"), (\"compute\", \"mentions\", \"compute\"), (\"multitask\", \"mentions\", \"multitask\"), (\"multilingual\", \"mentions\", \"multilingual\"), (\"negative transfer\", \"is_core_idea\", \"true\"), (\"chunk_115\", \"is_core_chunk\", \"true\"), (\"small models\", \"related_to_core\", \"negative transfer\"), (\"moderate amounts of compute\", \"related_to_core\", \"negative transfer\"), (\"tasks\", \"related_to_core\", \"negative transfer\"), (\"languages\", \"related_to_core\", \"negative transfer\"), (\"joint models\", \"related_to_core\", \"negative transfer\"), (\"English-only models\", \"related_to_core\", \"negative transfer\"), (\"compute\", \"related_to_core\", \"negative transfer\"), (\"multitask\", \"related_to_core\", \"negative transfer\"), (\"multilingual\", \"related_to_core\", \"negative transfer\"), (\"Figure 9\", \"related_to_core\", \"negative transfer\")]\n",
            "✅ Extracted: [('English-only model', 'mentions', 'English-only model'), ('chunk_115', 'mentions', 'English-only model'), ('Figure 9', 'mentions', 'Figure 9'), ('small models', 'mentions', 'small models'), ('moderate amounts of compute', 'mentions', 'moderate amounts of compute'), ('negative transfer', 'mentions', 'negative transfer'), ('tasks', 'mentions', 'tasks'), ('languages', 'mentions', 'languages'), ('joint models', 'mentions', 'joint models'), ('English-only models', 'mentions', 'English-only models'), ('compute', 'mentions', 'compute'), ('multitask', 'mentions', 'multitask'), ('multilingual', 'mentions', 'multilingual'), ('negative transfer', 'is_core_idea', 'true'), ('chunk_115', 'is_core_chunk', 'true'), ('small models', 'related_to_core', 'negative transfer'), ('moderate amounts of compute', 'related_to_core', 'negative transfer'), ('tasks', 'related_to_core', 'negative transfer'), ('languages', 'related_to_core', 'negative transfer'), ('joint models', 'related_to_core', 'negative transfer'), ('English-only models', 'related_to_core', 'negative transfer'), ('compute', 'related_to_core', 'negative transfer'), ('multitask', 'related_to_core', 'negative transfer'), ('multilingual', 'related_to_core', 'negative transfer'), ('Figure 9', 'related_to_core', 'negative transfer')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_116...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"related_to_core\", \"Speech Recognition\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"Speech Recognition\"), (\"FLOPs\", \"related_to_core\", \"Speech Recognition\"), (\"English Speech Recognition\", \"related_to_core\", \"Speech Recognition\"), (\"WER\", \"related_to_core\", \"Speech Recognition\"), (\"English Speech Recognition Datasets\", \"related_to_core\", \"Speech Recognition\"), (\"English Only\", \"related_to_core\", \"Speech Recognition\"), (\"Multilingual\", \"related_to_core\", \"Speech Recognition\"), (\"Multitask\", \"related_to_core\", \"Speech Recognition\"), (\"Multilingual Models\", \"related_to_core\", \"Speech Recognition\"), (\"Multitask Models\", \"related_to_core\", \"Speech Recognition\"), (\"Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_116\", \"is_core_chunk\", \"true\"), (\"chunk_116\", \"mentions\", \"Robust Speech Recognition\"), (\"chunk_116\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_116\", \"mentions\", \"FLOPs\"), (\"chunk_116\", \"mentions\", \"English Speech Recognition\"), (\"chunk_116\", \"mentions\", \"Speech Recognition\"), (\"chunk_116\", \"mentions\", \"WER\"), (\"chunk_116\", \"mentions\", \"English Speech Recognition Datasets\"), (\"chunk_116\", \"mentions\", \"English Only\"), (\"chunk_116\", \"mentions\", \"Multilingual\"), (\"chunk_116\", \"mentions\", \"Multitask\"), (\"chunk_116\", \"mentions\", \"Multilingual Models\"), (\"chunk_116\", \"mentions\", \"Multitask Models\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'related_to_core', 'Speech Recognition'), ('Large-Scale Weak Supervision', 'related_to_core', 'Speech Recognition'), ('FLOPs', 'related_to_core', 'Speech Recognition'), ('English Speech Recognition', 'related_to_core', 'Speech Recognition'), ('WER', 'related_to_core', 'Speech Recognition'), ('English Speech Recognition Datasets', 'related_to_core', 'Speech Recognition'), ('English Only', 'related_to_core', 'Speech Recognition'), ('Multilingual', 'related_to_core', 'Speech Recognition'), ('Multitask', 'related_to_core', 'Speech Recognition'), ('Multilingual Models', 'related_to_core', 'Speech Recognition'), ('Multitask Models', 'related_to_core', 'Speech Recognition'), ('Speech Recognition', 'is_core_idea', 'true'), ('chunk_116', 'is_core_chunk', 'true'), ('chunk_116', 'mentions', 'Robust Speech Recognition'), ('chunk_116', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_116', 'mentions', 'FLOPs'), ('chunk_116', 'mentions', 'English Speech Recognition'), ('chunk_116', 'mentions', 'Speech Recognition'), ('chunk_116', 'mentions', 'WER'), ('chunk_116', 'mentions', 'English Speech Recognition Datasets'), ('chunk_116', 'mentions', 'English Only'), ('chunk_116', 'mentions', 'Multilingual'), ('chunk_116', 'mentions', 'Multitask'), ('chunk_116', 'mentions', 'Multilingual Models'), ('chunk_116', 'mentions', 'Multitask Models')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_117...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"scale\", \"related_to_core\", \"models\"), (\"models\", \"is_core_idea\", \"true\"), (\"English data\", \"related_to_core\", \"models\"), (\"bootstrap estimate conﬁdence intervals\", \"related_to_core\", \"models\"), (\"English-only counterparts\", \"related_to_core\", \"models\"), (\"positive transfer\", \"related_to_core\", \"models\"), (\"tasks\", \"related_to_core\", \"models\"), (\"joint models\", \"related_to_core\", \"models\"), (\"English-only models\", \"related_to_core\", \"models\"), (\"compute\", \"related_to_core\", \"models\"), (\"task\", \"related_to_core\", \"models\"), (\"text normalization\", \"related_to_core\", \"models\"), (\"text normalization\", \"developed_with\", \"models\"), (\"chunk_117\", \"mentions\", \"scale\"), (\"chunk_117\", \"mentions\", \"models\"), (\"chunk_117\", \"mentions\", \"English data\"), (\"chunk_117\", \"mentions\", \"bootstrap estimate conﬁdence intervals\"), (\"chunk_117\", \"mentions\", \"English-only counterparts\"), (\"chunk_117\", \"mentions\", \"positive transfer\"), (\"chunk_117\", \"mentions\", \"tasks\"), (\"chunk_117\", \"mentions\", \"joint models\"), (\"chunk_117\", \"mentions\", \"English-only models\"), (\"chunk_117\", \"mentions\", \"compute\"), (\"chunk_117\", \"mentions\", \"task\"), (\"chunk_117\", \"mentions\", \"text normalization\"), (\"chunk_117\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('scale', 'related_to_core', 'models'), ('models', 'is_core_idea', 'true'), ('English data', 'related_to_core', 'models'), ('bootstrap estimate conﬁdence intervals', 'related_to_core', 'models'), ('English-only counterparts', 'related_to_core', 'models'), ('positive transfer', 'related_to_core', 'models'), ('tasks', 'related_to_core', 'models'), ('joint models', 'related_to_core', 'models'), ('English-only models', 'related_to_core', 'models'), ('compute', 'related_to_core', 'models'), ('task', 'related_to_core', 'models'), ('text normalization', 'related_to_core', 'models'), ('text normalization', 'developed_with', 'models'), ('chunk_117', 'mentions', 'scale'), ('chunk_117', 'mentions', 'models'), ('chunk_117', 'mentions', 'English data'), ('chunk_117', 'mentions', 'bootstrap estimate conﬁdence intervals'), ('chunk_117', 'mentions', 'English-only counterparts'), ('chunk_117', 'mentions', 'positive transfer'), ('chunk_117', 'mentions', 'tasks'), ('chunk_117', 'mentions', 'joint models'), ('chunk_117', 'mentions', 'English-only models'), ('chunk_117', 'mentions', 'compute'), ('chunk_117', 'mentions', 'task'), ('chunk_117', 'mentions', 'text normalization'), ('chunk_117', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_118...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Whisper\", \"mentions\", \"Whisper\"), (\"chunk_118\", \"mentions\", \"Whisper\"), (\"normalizer\", \"mentions\", \"normalizer\"), (\"chunk_118\", \"mentions\", \"normalizer\"), (\"transcription\", \"mentions\", \"transcription\"), (\"chunk_118\", \"mentions\", \"transcription\"), (\"FairSpeech project\", \"mentions\", \"FairSpeech project\"), (\"chunk_118\", \"mentions\", \"FairSpeech project\"), (\"datasets\", \"mentions\", \"datasets\"), (\"chunk_118\", \"mentions\", \"datasets\"), (\"normalizers\", \"mentions\", \"normalizers\"), (\"chunk_118\", \"mentions\", \"normalizers\"), (\"normalizer\", \"is_core_idea\", \"true\"), (\"chunk_118\", \"is_core_chunk\", \"true\"), (\"Whisper\", \"related_to_core\", \"normalizer\"), (\"transcription\", \"related_to_core\", \"normalizer\"), (\"FairSpeech project\", \"related_to_core\", \"normalizer\"), (\"datasets\", \"related_to_core\", \"normalizer\"), (\"normalizers\", \"related_to_core\", \"normalizer\")]\n",
            "✅ Extracted: [('Whisper', 'mentions', 'Whisper'), ('chunk_118', 'mentions', 'Whisper'), ('normalizer', 'mentions', 'normalizer'), ('chunk_118', 'mentions', 'normalizer'), ('transcription', 'mentions', 'transcription'), ('chunk_118', 'mentions', 'transcription'), ('FairSpeech project', 'mentions', 'FairSpeech project'), ('chunk_118', 'mentions', 'FairSpeech project'), ('datasets', 'mentions', 'datasets'), ('chunk_118', 'mentions', 'datasets'), ('normalizers', 'mentions', 'normalizers'), ('chunk_118', 'mentions', 'normalizers'), ('normalizer', 'is_core_idea', 'true'), ('chunk_118', 'is_core_chunk', 'true'), ('Whisper', 'related_to_core', 'normalizer'), ('transcription', 'related_to_core', 'normalizer'), ('FairSpeech project', 'related_to_core', 'normalizer'), ('datasets', 'related_to_core', 'normalizer'), ('normalizers', 'related_to_core', 'normalizer')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_119...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"WER reduction\", \"related_to_core\", \"Whisper\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_119\", \"is_core_chunk\", \"true\"), (\"Whisper\", \"compared to\", \"open-source models\"), (\"datasets\", \"namely\", \"WSJ\"), (\"datasets\", \"namely\", \"CallHome\"), (\"datasets\", \"namely\", \"Switchboard\"), (\"normalizer\", \"reduces\", \"WER\"), (\"Whisper models\", \"significantly more\", \"normalizer\"), (\"reduction\", \"traced down to\", \"formats\"), (\"ground truth\", \"used by\", \"formats\"), (\"normalizers\", \"penalizing\", \"formats\"), (\"standardizer\", \"did not penalize\", \"differences\"), (\"CallHome\", \"related_to_core\", \"Whisper\"), (\"Switchboard\", \"related_to_core\", \"Whisper\"), (\"WSJ\", \"related_to_core\", \"Whisper\"), (\"open-source models\", \"related_to_core\", \"Whisper\"), (\"normalizer\", \"related_to_core\", \"Whisper\"), (\"WER\", \"related_to_core\", \"Whisper\"), (\"chunk_119\", \"mentions\", \"WER reduction\"), (\"chunk_119\", \"mentions\", \"Whisper\"), (\"chunk_119\", \"mentions\", \"open-source models\"), (\"chunk_119\", \"mentions\", \"datasets\"), (\"chunk_119\", \"mentions\", \"WSJ\"), (\"chunk_119\", \"mentions\", \"CallHome\"), (\"chunk_119\", \"mentions\", \"Switchboard\"), (\"chunk_119\", \"mentions\", \"normalizer\"), (\"chunk_119\", \"mentions\", \"reduction\"), (\"chunk_119\", \"mentions\", \"ground truth\"), (\"chunk_119\", \"mentions\", \"normalizers\"), (\"chunk_119\", \"mentions\", \"standardizer\"), (\"chunk_119\", \"mentions\", \"WER\")]\n",
            "✅ Extracted: [('WER reduction', 'related_to_core', 'Whisper'), ('Whisper', 'is_core_idea', 'true'), ('chunk_119', 'is_core_chunk', 'true'), ('Whisper', 'compared to', 'open-source models'), ('datasets', 'namely', 'WSJ'), ('datasets', 'namely', 'CallHome'), ('datasets', 'namely', 'Switchboard'), ('normalizer', 'reduces', 'WER'), ('Whisper models', 'significantly more', 'normalizer'), ('reduction', 'traced down to', 'formats'), ('ground truth', 'used by', 'formats'), ('normalizers', 'penalizing', 'formats'), ('standardizer', 'did not penalize', 'differences'), ('CallHome', 'related_to_core', 'Whisper'), ('Switchboard', 'related_to_core', 'Whisper'), ('WSJ', 'related_to_core', 'Whisper'), ('open-source models', 'related_to_core', 'Whisper'), ('normalizer', 'related_to_core', 'Whisper'), ('WER', 'related_to_core', 'Whisper'), ('chunk_119', 'mentions', 'WER reduction'), ('chunk_119', 'mentions', 'Whisper'), ('chunk_119', 'mentions', 'open-source models'), ('chunk_119', 'mentions', 'datasets'), ('chunk_119', 'mentions', 'WSJ'), ('chunk_119', 'mentions', 'CallHome'), ('chunk_119', 'mentions', 'Switchboard'), ('chunk_119', 'mentions', 'normalizer'), ('chunk_119', 'mentions', 'reduction'), ('chunk_119', 'mentions', 'ground truth'), ('chunk_119', 'mentions', 'normalizers'), ('chunk_119', 'mentions', 'standardizer'), ('chunk_119', 'mentions', 'WER')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_120...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"English contractions\", \"mentions\", \"English contractions\"), (\"chunk_120\", \"mentions\", \"English contractions\"), (\"you're\", \"mentions\", \"you're\"), (\"chunk_120\", \"mentions\", \"you're\"), (\"you are\", \"mentions\", \"you are\"), (\"chunk_120\", \"mentions\", \"you are\"), (\"WSJ\", \"mentions\", \"WSJ\"), (\"chunk_120\", \"mentions\", \"WSJ\"), (\"normalizer\", \"mentions\", \"normalizer\"), (\"chunk_120\", \"mentions\", \"normalizer\"), (\"WER reduction\", \"mentions\", \"WER reduction\"), (\"chunk_120\", \"mentions\", \"WER reduction\"), (\"FairSpeech's normalizer\", \"mentions\", \"FairSpeech's normalizer\"), (\"chunk_120\", \"mentions\", \"FairSpeech's normalizer\"), (\"CORAAL\", \"mentions\", \"CORAAL\"), (\"chunk_120\", \"mentions\", \"CORAAL\"), (\"CommonVoice9.en\", \"mentions\", \"CommonVoice9.en\"), (\"chunk_120\", \"mentions\", \"CommonVoice9.en\"), (\"AMI-SDM1\", \"mentions\", \"AMI-SDM1\"), (\"chunk_120\", \"mentions\", \"AMI-SDM1\"), (\"CommonVoice5.1\", \"mentions\", \"CommonVoice5.1\"), (\"chunk_120\", \"mentions\", \"CommonVoice5.1\"), (\"Fleurs.en_us\", \"mentions\", \"Fleurs.en_us\"), (\"chunk_120\", \"mentions\", \"Fleurs.en_us\"), (\"AMI-IHM\", \"mentions\", \"AMI-IHM\"), (\"chunk_120\", \"mentions\", \"AMI-IHM\"), (\"Artie\", \"mentions\", \"Artie\"), (\"chunk_120\", \"mentions\", \"Artie\"), (\"LibriSpeech\", \"mentions\", \"LibriSpeech\"), (\"chunk_120\", \"mentions\", \"LibriSpeech\"), (\"TED-LIUM3\", \"mentions\", \"TED-LIUM3\"), (\"chunk_120\", \"mentions\", \"TED-LIUM3\"), (\"VoxPopuli.en\", \"mentions\", \"VoxPopuli.en\"), (\"chunk_120\", \"mentions\", \"VoxPopuli.en\"), (\"CallHome\", \"mentions\", \"CallHome\"), (\"chunk_120\", \"mentions\", \"CallHome\"), (\"Switchboard\", \"mentions\", \"Switchboard\"), (\"chunk_120\", \"mentions\", \"Switchboard\"), (\"Open-source models\", \"mentions\", \"Open-source models\"), (\"chunk_120\", \"mentions\", \"Open-source models\"), (\"Whisper models\", \"mentions\", \"Whisper models\"), (\"chunk_120\", \"mentions\", \"Whisper models\"), (\"text normalizer\", \"mentions\", \"text normalizer\"), (\"chunk_120\", \"mentions\", \"text normalizer\"), (\"WERs\", \"mentions\", \"WERs\"), (\"chunk_120\", \"mentions\", \"WERs\"), (\"Whisper models\", \"subject\", \"other\"), (\"text normalizer\", \"has similar effect on reducing\", \"WERs\"), (\"text normalizer\", \"is_core_idea\", \"true\"), (\"chunk_120\", \"is_core_chunk\", \"true\"), (\"English contractions\", \"related_to_core\", \"text normalizer\"), (\"you're\", \"related_to_core\", \"text normalizer\"), (\"you are\", \"related_to_core\", \"text normalizer\"), (\"WSJ\", \"related_to_core\", \"text normalizer\"), (\"normalizer\", \"related_to_core\", \"text normalizer\"), (\"WER reduction\", \"related_to_core\", \"text normalizer\"), (\"FairSpeech's normalizer\", \"related_to_core\", \"text normalizer\"), (\"CORAAL\", \"related_to_core\", \"text normalizer\"), (\"CommonVoice9.en\", \"related_to_core\", \"text normalizer\"), (\"AMI-SDM1\", \"related_to_core\", \"text normalizer\"), (\"CommonVoice5.1\", \"related_to_core\", \"text normalizer\"), (\"Fleurs.en_us\", \"related_to_core\", \"text normalizer\"), (\"AMI-IHM\", \"related_to_core\", \"text normalizer\"), (\"Artie\", \"related_to_core\", \"text normalizer\"), (\"LibriSpeech\", \"related_to_core\", \"text normalizer\"), (\"TED-LIUM3\", \"related_to_core\", \"text normalizer\"), (\"VoxPopuli.en\", \"related_to_core\", \"text normalizer\"), (\"CallHome\", \"related_to_core\", \"text normalizer\"), (\"Switchboard\", \"related_to_core\", \"text normalizer\"), (\"Open-source models\", \"related_to_core\", \"text normalizer\"), (\"Whisper models\", \"related_to_core\", \"text normalizer\"), (\"WERs\", \"related_to_core\", \"text normalizer\")]\n",
            "✅ Extracted: [('English contractions', 'mentions', 'English contractions'), ('chunk_120', 'mentions', 'English contractions'), (\"you're\", 'mentions', \"you're\"), ('chunk_120', 'mentions', \"you're\"), ('you are', 'mentions', 'you are'), ('chunk_120', 'mentions', 'you are'), ('WSJ', 'mentions', 'WSJ'), ('chunk_120', 'mentions', 'WSJ'), ('normalizer', 'mentions', 'normalizer'), ('chunk_120', 'mentions', 'normalizer'), ('WER reduction', 'mentions', 'WER reduction'), ('chunk_120', 'mentions', 'WER reduction'), (\"FairSpeech's normalizer\", 'mentions', \"FairSpeech's normalizer\"), ('chunk_120', 'mentions', \"FairSpeech's normalizer\"), ('CORAAL', 'mentions', 'CORAAL'), ('chunk_120', 'mentions', 'CORAAL'), ('CommonVoice9.en', 'mentions', 'CommonVoice9.en'), ('chunk_120', 'mentions', 'CommonVoice9.en'), ('AMI-SDM1', 'mentions', 'AMI-SDM1'), ('chunk_120', 'mentions', 'AMI-SDM1'), ('CommonVoice5.1', 'mentions', 'CommonVoice5.1'), ('chunk_120', 'mentions', 'CommonVoice5.1'), ('Fleurs.en_us', 'mentions', 'Fleurs.en_us'), ('chunk_120', 'mentions', 'Fleurs.en_us'), ('AMI-IHM', 'mentions', 'AMI-IHM'), ('chunk_120', 'mentions', 'AMI-IHM'), ('Artie', 'mentions', 'Artie'), ('chunk_120', 'mentions', 'Artie'), ('LibriSpeech', 'mentions', 'LibriSpeech'), ('chunk_120', 'mentions', 'LibriSpeech'), ('TED-LIUM3', 'mentions', 'TED-LIUM3'), ('chunk_120', 'mentions', 'TED-LIUM3'), ('VoxPopuli.en', 'mentions', 'VoxPopuli.en'), ('chunk_120', 'mentions', 'VoxPopuli.en'), ('CallHome', 'mentions', 'CallHome'), ('chunk_120', 'mentions', 'CallHome'), ('Switchboard', 'mentions', 'Switchboard'), ('chunk_120', 'mentions', 'Switchboard'), ('Open-source models', 'mentions', 'Open-source models'), ('chunk_120', 'mentions', 'Open-source models'), ('Whisper models', 'mentions', 'Whisper models'), ('chunk_120', 'mentions', 'Whisper models'), ('text normalizer', 'mentions', 'text normalizer'), ('chunk_120', 'mentions', 'text normalizer'), ('WERs', 'mentions', 'WERs'), ('chunk_120', 'mentions', 'WERs'), ('Whisper models', 'subject', 'other'), ('text normalizer', 'has similar effect on reducing', 'WERs'), ('text normalizer', 'is_core_idea', 'true'), ('chunk_120', 'is_core_chunk', 'true'), ('English contractions', 'related_to_core', 'text normalizer'), (\"you're\", 'related_to_core', 'text normalizer'), ('you are', 'related_to_core', 'text normalizer'), ('WSJ', 'related_to_core', 'text normalizer'), ('normalizer', 'related_to_core', 'text normalizer'), ('WER reduction', 'related_to_core', 'text normalizer'), (\"FairSpeech's normalizer\", 'related_to_core', 'text normalizer'), ('CORAAL', 'related_to_core', 'text normalizer'), ('CommonVoice9.en', 'related_to_core', 'text normalizer'), ('AMI-SDM1', 'related_to_core', 'text normalizer'), ('CommonVoice5.1', 'related_to_core', 'text normalizer'), ('Fleurs.en_us', 'related_to_core', 'text normalizer'), ('AMI-IHM', 'related_to_core', 'text normalizer'), ('Artie', 'related_to_core', 'text normalizer'), ('LibriSpeech', 'related_to_core', 'text normalizer'), ('TED-LIUM3', 'related_to_core', 'text normalizer'), ('VoxPopuli.en', 'related_to_core', 'text normalizer'), ('CallHome', 'related_to_core', 'text normalizer'), ('Switchboard', 'related_to_core', 'text normalizer'), ('Open-source models', 'related_to_core', 'text normalizer'), ('Whisper models', 'related_to_core', 'text normalizer'), ('WERs', 'related_to_core', 'text normalizer')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_121...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"open-source models\", \"compared_to\", \"FairSpeech's normalizer\"), (\"chunk_121\", \"mentions\", \"open-source models\"), (\"chunk_121\", \"mentions\", \"FairSpeech's normalizer\"), (\"dataset\", \"has_property\", \"boxplot\"), (\"boxplot\", \"shows\", \"distribution of relative WER reduction\"), (\"chunk_121\", \"mentions\", \"dataset\"), (\"chunk_121\", \"mentions\", \"boxplot\"), (\"chunk_121\", \"mentions\", \"distribution of relative WER reduction\"), (\"text normalizer\", \"results_in\", \"lower WERs\"), (\"chunk_121\", \"mentions\", \"text normalizer\"), (\"chunk_121\", \"mentions\", \"WER\"), (\"normalizer\", \"reduces\", \"WER\"), (\"Whisper models\", \"include\", \"CallHome\"), (\"Whisper models\", \"include\", \"Switchboard\"), (\"CallHome\", \"have\", \"contractions\"), (\"Switchboard\", \"have\", \"contractions\"), (\"chunk_121\", \"mentions\", \"Whisper models\"), (\"chunk_121\", \"mentions\", \"CallHome\"), (\"chunk_121\", \"mentions\", \"Switchboard\"), (\"chunk_121\", \"mentions\", \"WSJ\"), (\"WSJ\", \"contains\", \"numerical expressions\"), (\"chunk_121\", \"is_core_chunk\", \"true\"), (\"text normalizer\", \"is_core_idea\", \"true\"), (\"open-source models\", \"related_to_core\", \"text normalizer\"), (\"FairSpeech's normalizer\", \"related_to_core\", \"text normalizer\"), (\"dataset\", \"related_to_core\", \"text normalizer\"), (\"boxplot\", \"related_to_core\", \"text normalizer\"), (\"distribution of relative WER reduction\", \"related_to_core\", \"text normalizer\"), (\"WER\", \"related_to_core\", \"text normalizer\"), (\"Whisper models\", \"related_to_core\", \"text normalizer\"), (\"CallHome\", \"related_to_core\", \"text normalizer\"), (\"Switchboard\", \"related_to_core\", \"text normalizer\"), (\"WSJ\", \"related_to_core\", \"text normalizer\"), (\"contractions\", \"related_to_core\", \"text normalizer\"), (\"numerical expressions\", \"related_to_core\", \"text normalizer\"), (\"numerical expressions\", \"related_to_core\", \"text normalizer\"), (\"chunk_121\", \"mentions\", \"contractions\"), (\"chunk_121\", \"mentions\", \"numerical expressions\")]\n",
            "✅ Extracted: [('open-source models', 'compared_to', \"FairSpeech's normalizer\"), ('chunk_121', 'mentions', 'open-source models'), ('chunk_121', 'mentions', \"FairSpeech's normalizer\"), ('dataset', 'has_property', 'boxplot'), ('boxplot', 'shows', 'distribution of relative WER reduction'), ('chunk_121', 'mentions', 'dataset'), ('chunk_121', 'mentions', 'boxplot'), ('chunk_121', 'mentions', 'distribution of relative WER reduction'), ('text normalizer', 'results_in', 'lower WERs'), ('chunk_121', 'mentions', 'text normalizer'), ('chunk_121', 'mentions', 'WER'), ('normalizer', 'reduces', 'WER'), ('Whisper models', 'include', 'CallHome'), ('Whisper models', 'include', 'Switchboard'), ('CallHome', 'have', 'contractions'), ('Switchboard', 'have', 'contractions'), ('chunk_121', 'mentions', 'Whisper models'), ('chunk_121', 'mentions', 'CallHome'), ('chunk_121', 'mentions', 'Switchboard'), ('chunk_121', 'mentions', 'WSJ'), ('WSJ', 'contains', 'numerical expressions'), ('chunk_121', 'is_core_chunk', 'true'), ('text normalizer', 'is_core_idea', 'true'), ('open-source models', 'related_to_core', 'text normalizer'), (\"FairSpeech's normalizer\", 'related_to_core', 'text normalizer'), ('dataset', 'related_to_core', 'text normalizer'), ('boxplot', 'related_to_core', 'text normalizer'), ('distribution of relative WER reduction', 'related_to_core', 'text normalizer'), ('WER', 'related_to_core', 'text normalizer'), ('Whisper models', 'related_to_core', 'text normalizer'), ('CallHome', 'related_to_core', 'text normalizer'), ('Switchboard', 'related_to_core', 'text normalizer'), ('WSJ', 'related_to_core', 'text normalizer'), ('contractions', 'related_to_core', 'text normalizer'), ('numerical expressions', 'related_to_core', 'text normalizer'), ('numerical expressions', 'related_to_core', 'text normalizer'), ('chunk_121', 'mentions', 'contractions'), ('chunk_121', 'mentions', 'numerical expressions')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_122...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"numerical expressions\", \"versus\", \"monetary expressions\"), (\"chunk_122\", \"mentions\", \"numerical expressions\"), (\"chunk_122\", \"mentions\", \"monetary expressions\"), (\"long-form audio\", \"using\", \"Whisper\"), (\"chunk_122\", \"mentions\", \"long-form audio\"), (\"chunk_122\", \"mentions\", \"Whisper\"), (\"timestamp tokens\", \"determine\", \"amount\"), (\"chunk_122\", \"mentions\", \"timestamp tokens\"), (\"model\", \"shift\", \"audio context window\"), (\"chunk_122\", \"mentions\", \"model\"), (\"chunk_122\", \"mentions\", \"audio context window\"), (\"transcription\", \"impact\", \"transcription\"), (\"chunk_122\", \"mentions\", \"transcription\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_122\", \"is_core_chunk\", \"true\"), (\"numerical expressions\", \"related_to_core\", \"Whisper\"), (\"monetary expressions\", \"related_to_core\", \"Whisper\"), (\"long-form audio\", \"related_to_core\", \"Whisper\"), (\"timestamp tokens\", \"related_to_core\", \"Whisper\"), (\"model\", \"related_to_core\", \"Whisper\"), (\"audio context window\", \"related_to_core\", \"Whisper\")]\n",
            "✅ Extracted: [('numerical expressions', 'versus', 'monetary expressions'), ('chunk_122', 'mentions', 'numerical expressions'), ('chunk_122', 'mentions', 'monetary expressions'), ('long-form audio', 'using', 'Whisper'), ('chunk_122', 'mentions', 'long-form audio'), ('chunk_122', 'mentions', 'Whisper'), ('timestamp tokens', 'determine', 'amount'), ('chunk_122', 'mentions', 'timestamp tokens'), ('model', 'shift', 'audio context window'), ('chunk_122', 'mentions', 'model'), ('chunk_122', 'mentions', 'audio context window'), ('transcription', 'impact', 'transcription'), ('chunk_122', 'mentions', 'transcription'), ('Whisper', 'is_core_idea', 'true'), ('chunk_122', 'is_core_chunk', 'true'), ('numerical expressions', 'related_to_core', 'Whisper'), ('monetary expressions', 'related_to_core', 'Whisper'), ('long-form audio', 'related_to_core', 'Whisper'), ('timestamp tokens', 'related_to_core', 'Whisper'), ('model', 'related_to_core', 'Whisper'), ('audio context window', 'related_to_core', 'Whisper')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_123...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"heuristics\", \"is_core_idea\", \"true\"), (\"chunk_123\", \"is_core_chunk\", \"true\"), (\"long-form transcription\", \"related_to_core\", \"heuristics\"), (\"beam search\", \"related_to_core\", \"heuristics\"), (\"log probability\", \"related_to_core\", \"heuristics\"), (\"repetition looping\", \"related_to_core\", \"heuristics\"), (\"greedy decoding\", \"related_to_core\", \"heuristics\"), (\"temperature\", \"related_to_core\", \"heuristics\"), (\"tokens\", \"related_to_core\", \"heuristics\"), (\"heuristics\", \"helps avoid\", \"failure cases\"), (\"heuristics\", \"applied in\", \"results\"), (\"beam search\", \"uses\", \"log probability\"), (\"temperature\", \"increased by\", \"0.2\"), (\"chunk_123\", \"mentions\", \"heuristics\"), (\"chunk_123\", \"mentions\", \"long-form transcription\"), (\"chunk_123\", \"mentions\", \"beam search\"), (\"chunk_123\", \"mentions\", \"log probability\"), (\"chunk_123\", \"mentions\", \"repetition looping\"), (\"chunk_123\", \"mentions\", \"greedy decoding\"), (\"chunk_123\", \"mentions\", \"temperature\"), (\"chunk_123\", \"mentions\", \"tokens\"), (\"long-form transcription\", \"is a\", \"transcription\"), (\"repetition looping\", \"happens in\", \"greedy decoding\")]\n",
            "✅ Extracted: [('heuristics', 'is_core_idea', 'true'), ('chunk_123', 'is_core_chunk', 'true'), ('long-form transcription', 'related_to_core', 'heuristics'), ('beam search', 'related_to_core', 'heuristics'), ('log probability', 'related_to_core', 'heuristics'), ('repetition looping', 'related_to_core', 'heuristics'), ('greedy decoding', 'related_to_core', 'heuristics'), ('temperature', 'related_to_core', 'heuristics'), ('tokens', 'related_to_core', 'heuristics'), ('heuristics', 'helps avoid', 'failure cases'), ('heuristics', 'applied in', 'results'), ('beam search', 'uses', 'log probability'), ('temperature', 'increased by', '0.2'), ('chunk_123', 'mentions', 'heuristics'), ('chunk_123', 'mentions', 'long-form transcription'), ('chunk_123', 'mentions', 'beam search'), ('chunk_123', 'mentions', 'log probability'), ('chunk_123', 'mentions', 'repetition looping'), ('chunk_123', 'mentions', 'greedy decoding'), ('chunk_123', 'mentions', 'temperature'), ('chunk_123', 'mentions', 'tokens'), ('long-form transcription', 'is a', 'transcription'), ('repetition looping', 'happens in', 'greedy decoding')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_124...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"average log probability\", \"is_lower_than\", \"-1\"), (\"generated tokens\", \"has_average_log_probability\", \"average log probability\"), (\"generated text\", \"has_gzip_compression_rate\", \"gzip compression rate\"), (\"gzip compression rate\", \"is_higher_than\", \"2.4\"), (\"transcribed text\", \"used_as\", \"previous-text conditioning\"), (\"previous-text conditioning\", \"applied_when\", \"applied temperature is below 0.5\"), (\"applied temperature\", \"is_below\", \"0.5\"), (\"performance\", \"further_improves_with\", \"previous-text conditioning\"), (\"probability\", \"of\", \"<|nospeech|> token\"), (\"probability\", \"is\", \"not sufficient\"), (\"<|nospeech|> token\", \"is_alone\", \"not sufficient\"), (\"chunk_124\", \"mentions\", \"average log probability\"), (\"chunk_124\", \"mentions\", \"generated tokens\"), (\"chunk_124\", \"mentions\", \"generated text\"), (\"chunk_124\", \"mentions\", \"gzip compression rate\"), (\"chunk_124\", \"mentions\", \"transcribed text\"), (\"chunk_124\", \"mentions\", \"previous-text conditioning\"), (\"chunk_124\", \"mentions\", \"applied temperature\"), (\"chunk_124\", \"mentions\", \"performance\"), (\"chunk_124\", \"mentions\", \"probability\"), (\"chunk_124\", \"mentions\", \"<|nospeech|> token\")]\n",
            "✅ Extracted: [('average log probability', 'is_lower_than', '-1'), ('generated tokens', 'has_average_log_probability', 'average log probability'), ('generated text', 'has_gzip_compression_rate', 'gzip compression rate'), ('gzip compression rate', 'is_higher_than', '2.4'), ('transcribed text', 'used_as', 'previous-text conditioning'), ('previous-text conditioning', 'applied_when', 'applied temperature is below 0.5'), ('applied temperature', 'is_below', '0.5'), ('performance', 'further_improves_with', 'previous-text conditioning'), ('probability', 'of', '<|nospeech|> token'), ('probability', 'is', 'not sufficient'), ('<|nospeech|> token', 'is_alone', 'not sufficient'), ('chunk_124', 'mentions', 'average log probability'), ('chunk_124', 'mentions', 'generated tokens'), ('chunk_124', 'mentions', 'generated text'), ('chunk_124', 'mentions', 'gzip compression rate'), ('chunk_124', 'mentions', 'transcribed text'), ('chunk_124', 'mentions', 'previous-text conditioning'), ('chunk_124', 'mentions', 'applied temperature'), ('chunk_124', 'mentions', 'performance'), ('chunk_124', 'mentions', 'probability'), ('chunk_124', 'mentions', '<|nospeech|> token')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_125...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_125\", \"is_core_chunk\", \"true\"), (\"chunk_125\", \"mentions\", \"Robust Speech Recognition\"), (\"chunk_125\", \"mentions\", \"TED-LIUM3\"), (\"chunk_125\", \"mentions\", \"Kincaid46\"), (\"chunk_125\", \"mentions\", \"Rev16\"), (\"chunk_125\", \"mentions\", \"Earnings-21\"), (\"chunk_125\", \"mentions\", \"Earnings-22\"), (\"chunk_125\", \"mentions\", \"CORAAL\"), (\"chunk_125\", \"mentions\", \"Average\"), (\"chunk_125\", \"mentions\", \"Greedy decoding\"), (\"chunk_125\", \"mentions\", \"Beam search\"), (\"chunk_125\", \"mentions\", \"Temperature fallback\"), (\"chunk_125\", \"mentions\", \"Voice activity detection\"), (\"chunk_125\", \"mentions\", \"text conditioning\"), (\"TED-LIUM3\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Kincaid46\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Rev16\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Earnings-21\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Earnings-22\", \"related_to_core\", \"Robust Speech Recognition\"), (\"CORAAL\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Average\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Greedy decoding\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Beam search\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Temperature fallback\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Voice activity detection\", \"related_to_core\", \"Robust Speech Recognition\"), (\"text conditioning\", \"related_to_core\", \"Robust Speech Recognition\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'is_core_idea', 'true'), ('chunk_125', 'is_core_chunk', 'true'), ('chunk_125', 'mentions', 'Robust Speech Recognition'), ('chunk_125', 'mentions', 'TED-LIUM3'), ('chunk_125', 'mentions', 'Kincaid46'), ('chunk_125', 'mentions', 'Rev16'), ('chunk_125', 'mentions', 'Earnings-21'), ('chunk_125', 'mentions', 'Earnings-22'), ('chunk_125', 'mentions', 'CORAAL'), ('chunk_125', 'mentions', 'Average'), ('chunk_125', 'mentions', 'Greedy decoding'), ('chunk_125', 'mentions', 'Beam search'), ('chunk_125', 'mentions', 'Temperature fallback'), ('chunk_125', 'mentions', 'Voice activity detection'), ('chunk_125', 'mentions', 'text conditioning'), ('TED-LIUM3', 'related_to_core', 'Robust Speech Recognition'), ('Kincaid46', 'related_to_core', 'Robust Speech Recognition'), ('Rev16', 'related_to_core', 'Robust Speech Recognition'), ('Earnings-21', 'related_to_core', 'Robust Speech Recognition'), ('Earnings-22', 'related_to_core', 'Robust Speech Recognition'), ('CORAAL', 'related_to_core', 'Robust Speech Recognition'), ('Average', 'related_to_core', 'Robust Speech Recognition'), ('Greedy decoding', 'related_to_core', 'Robust Speech Recognition'), ('Beam search', 'related_to_core', 'Robust Speech Recognition'), ('Temperature fallback', 'related_to_core', 'Robust Speech Recognition'), ('Voice activity detection', 'related_to_core', 'Robust Speech Recognition'), ('text conditioning', 'related_to_core', 'Robust Speech Recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_126...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"timestamp constraint\", \"is_core_idea\", \"true\"), (\"chunk_126\", \"is_core_chunk\", \"true\"), (\"decoding heuristics\", \"related_to_core\", \"timestamp constraint\"), (\"voice activity detection\", \"related_to_core\", \"timestamp constraint\"), (\"Whisper\", \"related_to_core\", \"timestamp constraint\"), (\"no-speech probability threshold\", \"related_to_core\", \"timestamp constraint\"), (\"log-probability threshold\", \"related_to_core\", \"timestamp constraint\"), (\"chunk_126\", \"mentions\", \"timestamp constraint\"), (\"chunk_126\", \"mentions\", \"decoding heuristics\"), (\"chunk_126\", \"mentions\", \"voice activity detection\"), (\"chunk_126\", \"mentions\", \"Whisper\"), (\"chunk_126\", \"mentions\", \"no-speech probability threshold\"), (\"chunk_126\", \"mentions\", \"log-probability threshold\"), (\"transcription performance\", \"improves\", \"decoding heuristics\"), (\"voice activity detection\", \"of\", \"Whisper\"), (\"no-speech probability threshold\", \"combining with\", \"log-probability threshold\")]\n",
            "✅ Extracted: [('timestamp constraint', 'is_core_idea', 'true'), ('chunk_126', 'is_core_chunk', 'true'), ('decoding heuristics', 'related_to_core', 'timestamp constraint'), ('voice activity detection', 'related_to_core', 'timestamp constraint'), ('Whisper', 'related_to_core', 'timestamp constraint'), ('no-speech probability threshold', 'related_to_core', 'timestamp constraint'), ('log-probability threshold', 'related_to_core', 'timestamp constraint'), ('chunk_126', 'mentions', 'timestamp constraint'), ('chunk_126', 'mentions', 'decoding heuristics'), ('chunk_126', 'mentions', 'voice activity detection'), ('chunk_126', 'mentions', 'Whisper'), ('chunk_126', 'mentions', 'no-speech probability threshold'), ('chunk_126', 'mentions', 'log-probability threshold'), ('transcription performance', 'improves', 'decoding heuristics'), ('voice activity detection', 'of', 'Whisper'), ('no-speech probability threshold', 'combining with', 'log-probability threshold')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_127...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"model\", \"ignores\", \"ﬁrst few words\"), (\"initial timestamp token\", \"is\", \"between 0.0 and 1.0 second\"), (\"WER\", \"reduces\", \"overall\"), (\"heuristics\", \"serve as\", \"workaround\"), (\"predictions\", \"are\", \"noisy\"), (\"model\", \"has\", \"noisy predictions\"), (\"research\", \"needed to\", \"improve reliability\"), (\"decoding\", \"is\", \"long-form\"), (\"chunk_127\", \"mentions\", \"model\"), (\"chunk_127\", \"mentions\", \"initial timestamp token\"), (\"chunk_127\", \"mentions\", \"WER\"), (\"chunk_127\", \"mentions\", \"heuristics\"), (\"chunk_127\", \"mentions\", \"predictions\"), (\"chunk_127\", \"mentions\", \"research\"), (\"chunk_127\", \"mentions\", \"decoding\"), (\"WER\", \"is_core_idea\", \"true\"), (\"chunk_127\", \"is_core_chunk\", \"true\"), (\"model\", \"related_to_core\", \"WER\"), (\"initial timestamp token\", \"related_to_core\", \"WER\"), (\"heuristics\", \"related_to_core\", \"WER\"), (\"predictions\", \"related_to_core\", \"WER\"), (\"research\", \"related_to_core\", \"WER\"), (\"decoding\", \"related_to_core\", \"WER\")]\n",
            "✅ Extracted: [('model', 'ignores', 'ﬁrst few words'), ('initial timestamp token', 'is', 'between 0.0 and 1.0 second'), ('WER', 'reduces', 'overall'), ('heuristics', 'serve as', 'workaround'), ('predictions', 'are', 'noisy'), ('model', 'has', 'noisy predictions'), ('research', 'needed to', 'improve reliability'), ('decoding', 'is', 'long-form'), ('chunk_127', 'mentions', 'model'), ('chunk_127', 'mentions', 'initial timestamp token'), ('chunk_127', 'mentions', 'WER'), ('chunk_127', 'mentions', 'heuristics'), ('chunk_127', 'mentions', 'predictions'), ('chunk_127', 'mentions', 'research'), ('chunk_127', 'mentions', 'decoding'), ('WER', 'is_core_idea', 'true'), ('chunk_127', 'is_core_chunk', 'true'), ('model', 'related_to_core', 'WER'), ('initial timestamp token', 'related_to_core', 'WER'), ('heuristics', 'related_to_core', 'WER'), ('predictions', 'related_to_core', 'WER'), ('research', 'related_to_core', 'WER'), ('decoding', 'related_to_core', 'WER')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_128...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_128\", \"is_core_chunk\", \"true\"), (\"Speech Recognition\", \"mentions\", \"Speech Recognition\"), (\"Deep Learning\", \"mentions\", \"Deep Learning\"), (\"GPU Acceleration\", \"mentions\", \"GPU Acceleration\"), (\"Training\", \"mentions\", \"Training\"), (\"Model Depth\", \"mentions\", \"Model Depth\"), (\"Model Size\", \"mentions\", \"Model Size\"), (\"chunk_128\", \"mentions\", \"Model Depth\"), (\"chunk_128\", \"mentions\", \"Model Size\"), (\"chunk_128\", \"mentions\", \"Datasets\"), (\"chunk_128\", \"mentions\", \"Deep Learning\"), (\"chunk_128\", \"mentions\", \"GPU Acceleration\"), (\"chunk_128\", \"mentions\", \"Training\"), (\"Model Depth\", \"related_to_core\", \"Speech Recognition\"), (\"Model Size\", \"related_to_core\", \"Speech Recognition\"), (\"Datasets\", \"related_to_core\", \"Speech Recognition\"), (\"Deep Learning\", \"related_to_core\", \"Speech Recognition\"), (\"GPU Acceleration\", \"related_to_core\", \"Speech Recognition\"), (\"Training\", \"related_to_core\", \"Speech Recognition\")]\n",
            "✅ Extracted: [('Speech Recognition', 'is_core_idea', 'true'), ('chunk_128', 'is_core_chunk', 'true'), ('Speech Recognition', 'mentions', 'Speech Recognition'), ('Deep Learning', 'mentions', 'Deep Learning'), ('GPU Acceleration', 'mentions', 'GPU Acceleration'), ('Training', 'mentions', 'Training'), ('Model Depth', 'mentions', 'Model Depth'), ('Model Size', 'mentions', 'Model Size'), ('chunk_128', 'mentions', 'Model Depth'), ('chunk_128', 'mentions', 'Model Size'), ('chunk_128', 'mentions', 'Datasets'), ('chunk_128', 'mentions', 'Deep Learning'), ('chunk_128', 'mentions', 'GPU Acceleration'), ('chunk_128', 'mentions', 'Training'), ('Model Depth', 'related_to_core', 'Speech Recognition'), ('Model Size', 'related_to_core', 'Speech Recognition'), ('Datasets', 'related_to_core', 'Speech Recognition'), ('Deep Learning', 'related_to_core', 'Speech Recognition'), ('GPU Acceleration', 'related_to_core', 'Speech Recognition'), ('Training', 'related_to_core', 'Speech Recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_129...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"dataset size\", \"predicate\", \"increased\"), (\"GMM-HMM systems\", \"predicate\", \"competitive with\"), (\"phone recognition\", \"predicate\", \"using for\"), (\"TIMIT training data\", \"predicate\", \"of\"), (\"word error rate\", \"predicate\", \"reduction\"), (\"Switchboard dataset\", \"predicate\", \"trained on\"), (\"weakly supervised learning\", \"predicate\", \"leveraging to increase\"), (\"deep learning\", \"predicate\", \"based on\"), (\"speech recognition dataset\", \"predicate\", \"of\"), (\"chunk_129\", \"mentions\", \"dataset size\"), (\"chunk_129\", \"mentions\", \"GMM-HMM systems\"), (\"chunk_129\", \"mentions\", \"phone recognition\"), (\"chunk_129\", \"mentions\", \"TIMIT training data\"), (\"chunk_129\", \"mentions\", \"word error rate\"), (\"chunk_129\", \"mentions\", \"Switchboard dataset\"), (\"chunk_129\", \"mentions\", \"weakly supervised learning\"), (\"chunk_129\", \"mentions\", \"deep learning\"), (\"chunk_129\", \"mentions\", \"speech recognition dataset\"), (\"dataset size\", \"is_core_idea\", \"true\"), (\"chunk_129\", \"is_core_chunk\", \"true\"), (\"GMM-HMM systems\", \"related_to_core\", \"dataset size\"), (\"phone recognition\", \"related_to_core\", \"dataset size\"), (\"TIMIT training data\", \"related_to_core\", \"dataset size\"), (\"word error rate\", \"related_to_core\", \"dataset size\"), (\"Switchboard dataset\", \"related_to_core\", \"dataset size\"), (\"weakly supervised learning\", \"related_to_core\", \"dataset size\"), (\"deep learning\", \"related_to_core\", \"dataset size\"), (\"speech recognition dataset\", \"related_to_core\", \"dataset size\")]\n",
            "✅ Extracted: [('dataset size', 'predicate', 'increased'), ('GMM-HMM systems', 'predicate', 'competitive with'), ('phone recognition', 'predicate', 'using for'), ('TIMIT training data', 'predicate', 'of'), ('word error rate', 'predicate', 'reduction'), ('Switchboard dataset', 'predicate', 'trained on'), ('weakly supervised learning', 'predicate', 'leveraging to increase'), ('deep learning', 'predicate', 'based on'), ('speech recognition dataset', 'predicate', 'of'), ('chunk_129', 'mentions', 'dataset size'), ('chunk_129', 'mentions', 'GMM-HMM systems'), ('chunk_129', 'mentions', 'phone recognition'), ('chunk_129', 'mentions', 'TIMIT training data'), ('chunk_129', 'mentions', 'word error rate'), ('chunk_129', 'mentions', 'Switchboard dataset'), ('chunk_129', 'mentions', 'weakly supervised learning'), ('chunk_129', 'mentions', 'deep learning'), ('chunk_129', 'mentions', 'speech recognition dataset'), ('dataset size', 'is_core_idea', 'true'), ('chunk_129', 'is_core_chunk', 'true'), ('GMM-HMM systems', 'related_to_core', 'dataset size'), ('phone recognition', 'related_to_core', 'dataset size'), ('TIMIT training data', 'related_to_core', 'dataset size'), ('word error rate', 'related_to_core', 'dataset size'), ('Switchboard dataset', 'related_to_core', 'dataset size'), ('weakly supervised learning', 'related_to_core', 'dataset size'), ('deep learning', 'related_to_core', 'dataset size'), ('speech recognition dataset', 'related_to_core', 'dataset size')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_130...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Deep Speech 2\", \"is_a\", \"system\"), (\"Deep Speech 2\", \"developed\", \"high-throughput distributed training\"), (\"high-throughput distributed training\", \"across\", \"GPUs\"), (\"high-throughput distributed training\", \"scaling to\", \"training data\"), (\"training data\", \"size\", \"12,000 hours\"), (\"semi-supervised pre-training\", \"used by\", \"Narayanan et al. (2018)\"), (\"Narayanan et al. (2018)\", \"grow\", \"dataset size\"), (\"dataset size\", \"size\", \"162,000 hours\"), (\"dataset size\", \"of\", \"labeled audio\"), (\"chunk_130\", \"mentions\", \"Deep Speech 2\"), (\"chunk_130\", \"mentions\", \"GPUs\"), (\"chunk_130\", \"mentions\", \"training data\"), (\"chunk_130\", \"mentions\", \"semi-supervised pre-training\"), (\"chunk_130\", \"mentions\", \"Narayanan et al. (2018)\"), (\"chunk_130\", \"mentions\", \"dataset size\"), (\"Deep Speech 2\", \"is_core_idea\", \"true\"), (\"chunk_130\", \"is_core_chunk\", \"true\"), (\"GPUs\", \"related_to_core\", \"Deep Speech 2\"), (\"training data\", \"related_to_core\", \"Deep Speech 2\"), (\"semi-supervised pre-training\", \"related_to_core\", \"Deep Speech 2\"), (\"Narayanan et al. (2018)\", \"related_to_core\", \"Deep Speech 2\"), (\"dataset size\", \"related_to_core\", \"Deep Speech 2\")]\n",
            "✅ Extracted: [('Deep Speech 2', 'is_a', 'system'), ('Deep Speech 2', 'developed', 'high-throughput distributed training'), ('high-throughput distributed training', 'across', 'GPUs'), ('high-throughput distributed training', 'scaling to', 'training data'), ('training data', 'size', '12,000 hours'), ('semi-supervised pre-training', 'used by', 'Narayanan et al. (2018)'), ('Narayanan et al. (2018)', 'grow', 'dataset size'), ('dataset size', 'size', '162,000 hours'), ('dataset size', 'of', 'labeled audio'), ('chunk_130', 'mentions', 'Deep Speech 2'), ('chunk_130', 'mentions', 'GPUs'), ('chunk_130', 'mentions', 'training data'), ('chunk_130', 'mentions', 'semi-supervised pre-training'), ('chunk_130', 'mentions', 'Narayanan et al. (2018)'), ('chunk_130', 'mentions', 'dataset size'), ('Deep Speech 2', 'is_core_idea', 'true'), ('chunk_130', 'is_core_chunk', 'true'), ('GPUs', 'related_to_core', 'Deep Speech 2'), ('training data', 'related_to_core', 'Deep Speech 2'), ('semi-supervised pre-training', 'related_to_core', 'Deep Speech 2'), ('Narayanan et al. (2018)', 'related_to_core', 'Deep Speech 2'), ('dataset size', 'related_to_core', 'Deep Speech 2')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_131...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"billion-parameter models\", \"is_core_idea\", \"true\"), (\"chunk_131\", \"is_core_chunk\", \"true\"), (\"chunk_131\", \"mentions\", \"billion-parameter models\"), (\"training data\", \"related_to_core\", \"billion-parameter models\"), (\"Multitask Learning\", \"related_to_core\", \"billion-parameter models\"), (\"speech recognition\", \"related_to_core\", \"billion-parameter models\"), (\"multi-lingual models\", \"related_to_core\", \"billion-parameter models\"), (\"NLP\", \"related_to_core\", \"billion-parameter models\"), (\"multi-task learning\", \"related_to_core\", \"billion-parameter models\"), (\"training data\", \"mentions\", \"training data\"), (\"Multitask Learning\", \"mentions\", \"Multitask Learning\"), (\"speech recognition\", \"mentions\", \"speech recognition\"), (\"multi-lingual models\", \"mentions\", \"multi-lingual models\"), (\"NLP\", \"mentions\", \"NLP\"), (\"multi-task learning\", \"mentions\", \"multi-task learning\")]\n",
            "✅ Extracted: [('billion-parameter models', 'is_core_idea', 'true'), ('chunk_131', 'is_core_chunk', 'true'), ('chunk_131', 'mentions', 'billion-parameter models'), ('training data', 'related_to_core', 'billion-parameter models'), ('Multitask Learning', 'related_to_core', 'billion-parameter models'), ('speech recognition', 'related_to_core', 'billion-parameter models'), ('multi-lingual models', 'related_to_core', 'billion-parameter models'), ('NLP', 'related_to_core', 'billion-parameter models'), ('multi-task learning', 'related_to_core', 'billion-parameter models'), ('training data', 'mentions', 'training data'), ('Multitask Learning', 'mentions', 'Multitask Learning'), ('speech recognition', 'mentions', 'speech recognition'), ('multi-lingual models', 'mentions', 'multi-lingual models'), ('NLP', 'mentions', 'NLP'), ('multi-task learning', 'mentions', 'multi-task learning')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_132...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"sequence-to-sequence framework\", \"is_core_idea\", \"true\"), (\"chunk_132\", \"is_core_chunk\", \"true\"), (\"multiple encoders\", \"related_to_core\", \"sequence-to-sequence framework\"), (\"decoders\", \"related_to_core\", \"sequence-to-sequence framework\"), (\"language codes\", \"related_to_core\", \"sequence-to-sequence framework\"), (\"encoder/decoder architecture\", \"related_to_core\", \"sequence-to-sequence framework\"), (\"machine translation\", \"related_to_core\", \"sequence-to-sequence framework\"), (\"encoders\", \"related_to_core\", \"sequence-to-sequence framework\"), (\"decoders\", \"related_to_core\", \"sequence-to-sequence framework\"), (\"text-to-text framework\", \"related_to_core\", \"sequence-to-sequence framework\"), (\"learning\", \"in\", \"sequence-to-sequence framework\"), (\"multiple encoders\", \"and\", \"decoders\"), (\"shared encoder/decoder architecture\", \"demonstrated for\", \"machine translation\"), (\"removing\", \"need for\", \"separate encoders\"), (\"separate encoders\", \"and\", \"decoders\"), (\"sequence-to-sequence framework\", \"mentions\", \"multiple encoders\"), (\"sequence-to-sequence framework\", \"mentions\", \"decoders\"), (\"sequence-to-sequence framework\", \"mentions\", \"language codes\"), (\"sequence-to-sequence framework\", \"mentions\", \"encoder/decoder architecture\"), (\"sequence-to-sequence framework\", \"mentions\", \"machine translation\"), (\"sequence-to-sequence framework\", \"mentions\", \"encoders\"), (\"sequence-to-sequence framework\", \"mentions\", \"decoders\"), (\"sequence-to-sequence framework\", \"mentions\", \"text-to-text framework\"), (\"chunk_132\", \"mentions\", \"sequence-to-sequence framework\"), (\"chunk_132\", \"mentions\", \"multiple encoders\"), (\"chunk_132\", \"mentions\", \"decoders\"), (\"chunk_132\", \"mentions\", \"language codes\"), (\"chunk_132\", \"mentions\", \"encoder/decoder architecture\"), (\"chunk_132\", \"mentions\", \"machine translation\"), (\"chunk_132\", \"mentions\", \"encoders\"), (\"chunk_132\", \"mentions\", \"decoders\"), (\"chunk_132\", \"mentions\", \"text-to-text framework\"), (\"chunk_132\", \"mentions\", \"learning\")]\n",
            "✅ Extracted: [('sequence-to-sequence framework', 'is_core_idea', 'true'), ('chunk_132', 'is_core_chunk', 'true'), ('multiple encoders', 'related_to_core', 'sequence-to-sequence framework'), ('decoders', 'related_to_core', 'sequence-to-sequence framework'), ('language codes', 'related_to_core', 'sequence-to-sequence framework'), ('encoder/decoder architecture', 'related_to_core', 'sequence-to-sequence framework'), ('machine translation', 'related_to_core', 'sequence-to-sequence framework'), ('encoders', 'related_to_core', 'sequence-to-sequence framework'), ('decoders', 'related_to_core', 'sequence-to-sequence framework'), ('text-to-text framework', 'related_to_core', 'sequence-to-sequence framework'), ('learning', 'in', 'sequence-to-sequence framework'), ('multiple encoders', 'and', 'decoders'), ('shared encoder/decoder architecture', 'demonstrated for', 'machine translation'), ('removing', 'need for', 'separate encoders'), ('separate encoders', 'and', 'decoders'), ('sequence-to-sequence framework', 'mentions', 'multiple encoders'), ('sequence-to-sequence framework', 'mentions', 'decoders'), ('sequence-to-sequence framework', 'mentions', 'language codes'), ('sequence-to-sequence framework', 'mentions', 'encoder/decoder architecture'), ('sequence-to-sequence framework', 'mentions', 'machine translation'), ('sequence-to-sequence framework', 'mentions', 'encoders'), ('sequence-to-sequence framework', 'mentions', 'decoders'), ('sequence-to-sequence framework', 'mentions', 'text-to-text framework'), ('chunk_132', 'mentions', 'sequence-to-sequence framework'), ('chunk_132', 'mentions', 'multiple encoders'), ('chunk_132', 'mentions', 'decoders'), ('chunk_132', 'mentions', 'language codes'), ('chunk_132', 'mentions', 'encoder/decoder architecture'), ('chunk_132', 'mentions', 'machine translation'), ('chunk_132', 'mentions', 'encoders'), ('chunk_132', 'mentions', 'decoders'), ('chunk_132', 'mentions', 'text-to-text framework'), ('chunk_132', 'mentions', 'learning')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_133...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"transformer language models\", \"is_core_idea\", \"true\"), (\"chunk_133\", \"is_core_chunk\", \"true\"), (\"chunk_133\", \"mentions\", \"transformer language models\"), (\"Radford et al. (2019)\", \"related_to_core\", \"transformer language models\"), (\"Raffel et al. (2020)\", \"related_to_core\", \"transformer language models\"), (\"Toshniwal et al. (2018)\", \"related_to_core\", \"transformer language models\"), (\"deep learning speech recognition system\", \"related_to_core\", \"transformer language models\"), (\"Pratap et al. (2020a)\", \"related_to_core\", \"transformer language models\"), (\"50 languages\", \"related_to_core\", \"transformer language models\"), (\"billion-parameter model\", \"related_to_core\", \"transformer language models\"), (\"MUTE (Wang et al., 2020c)\", \"related_to_core\", \"transformer language models\"), (\"mSLAM (Bapna et al., 2022)\", \"related_to_core\", \"transformer language models\"), (\"chunk_133\", \"mentions\", \"Radford et al. (2019)\"), (\"chunk_133\", \"mentions\", \"Raffel et al. (2020)\"), (\"chunk_133\", \"mentions\", \"Toshniwal et al. (2018)\"), (\"chunk_133\", \"mentions\", \"deep learning speech recognition system\"), (\"chunk_133\", \"mentions\", \"Pratap et al. (2020a)\"), (\"chunk_133\", \"mentions\", \"50 languages\"), (\"chunk_133\", \"mentions\", \"billion-parameter model\"), (\"chunk_133\", \"mentions\", \"MUTE (Wang et al., 2020c)\"), (\"chunk_133\", \"mentions\", \"mSLAM (Bapna et al., 2022)\")]\n",
            "✅ Extracted: [('transformer language models', 'is_core_idea', 'true'), ('chunk_133', 'is_core_chunk', 'true'), ('chunk_133', 'mentions', 'transformer language models'), ('Radford et al. (2019)', 'related_to_core', 'transformer language models'), ('Raffel et al. (2020)', 'related_to_core', 'transformer language models'), ('Toshniwal et al. (2018)', 'related_to_core', 'transformer language models'), ('deep learning speech recognition system', 'related_to_core', 'transformer language models'), ('Pratap et al. (2020a)', 'related_to_core', 'transformer language models'), ('50 languages', 'related_to_core', 'transformer language models'), ('billion-parameter model', 'related_to_core', 'transformer language models'), ('MUTE (Wang et al., 2020c)', 'related_to_core', 'transformer language models'), ('mSLAM (Bapna et al., 2022)', 'related_to_core', 'transformer language models'), ('chunk_133', 'mentions', 'Radford et al. (2019)'), ('chunk_133', 'mentions', 'Raffel et al. (2020)'), ('chunk_133', 'mentions', 'Toshniwal et al. (2018)'), ('chunk_133', 'mentions', 'deep learning speech recognition system'), ('chunk_133', 'mentions', 'Pratap et al. (2020a)'), ('chunk_133', 'mentions', '50 languages'), ('chunk_133', 'mentions', 'billion-parameter model'), ('chunk_133', 'mentions', 'MUTE (Wang et al., 2020c)'), ('chunk_133', 'mentions', 'mSLAM (Bapna et al., 2022)')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_134...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"language tasks\", \"mentions\", \"language tasks\"), (\"transfer\", \"mentions\", \"transfer\"), (\"language tasks\", \"related_to_core\", \"transfer\"), (\"Robustness\", \"mentions\", \"Robustness\"), (\"Robustness\", \"related_to_core\", \"transfer\"), (\"distribution shift\", \"mentions\", \"distribution shift\"), (\"distribution shift\", \"related_to_core\", \"transfer\"), (\"perturbations\", \"mentions\", \"perturbations\"), (\"perturbations\", \"related_to_core\", \"transfer\"), (\"machine learning\", \"mentions\", \"machine learning\"), (\"machine learning\", \"related_to_core\", \"transfer\"), (\"generalization\", \"mentions\", \"generalization\"), (\"generalization\", \"related_to_core\", \"transfer\"), (\"machine learning models\", \"mentions\", \"machine learning models\"), (\"machine learning models\", \"related_to_core\", \"transfer\"), (\"datasets\", \"mentions\", \"datasets\"), (\"datasets\", \"related_to_core\", \"transfer\"), (\"chunk_134\", \"mentions\", \"language tasks\"), (\"chunk_134\", \"mentions\", \"transfer\"), (\"chunk_134\", \"mentions\", \"Robustness\"), (\"chunk_134\", \"mentions\", \"distribution shift\"), (\"chunk_134\", \"mentions\", \"perturbations\"), (\"chunk_134\", \"mentions\", \"machine learning\"), (\"chunk_134\", \"mentions\", \"generalization\"), (\"chunk_134\", \"mentions\", \"machine learning models\"), (\"chunk_134\", \"mentions\", \"datasets\"), (\"transfer\", \"is_core_idea\", \"true\"), (\"chunk_134\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('language tasks', 'mentions', 'language tasks'), ('transfer', 'mentions', 'transfer'), ('language tasks', 'related_to_core', 'transfer'), ('Robustness', 'mentions', 'Robustness'), ('Robustness', 'related_to_core', 'transfer'), ('distribution shift', 'mentions', 'distribution shift'), ('distribution shift', 'related_to_core', 'transfer'), ('perturbations', 'mentions', 'perturbations'), ('perturbations', 'related_to_core', 'transfer'), ('machine learning', 'mentions', 'machine learning'), ('machine learning', 'related_to_core', 'transfer'), ('generalization', 'mentions', 'generalization'), ('generalization', 'related_to_core', 'transfer'), ('machine learning models', 'mentions', 'machine learning models'), ('machine learning models', 'related_to_core', 'transfer'), ('datasets', 'mentions', 'datasets'), ('datasets', 'related_to_core', 'transfer'), ('chunk_134', 'mentions', 'language tasks'), ('chunk_134', 'mentions', 'transfer'), ('chunk_134', 'mentions', 'Robustness'), ('chunk_134', 'mentions', 'distribution shift'), ('chunk_134', 'mentions', 'perturbations'), ('chunk_134', 'mentions', 'machine learning'), ('chunk_134', 'mentions', 'generalization'), ('chunk_134', 'mentions', 'machine learning models'), ('chunk_134', 'mentions', 'datasets'), ('transfer', 'is_core_idea', 'true'), ('chunk_134', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_135...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"IID test sets\", \"is_core_idea\", \"true\"), (\"chunk_135\", \"is_core_chunk\", \"true\"), (\"machine learning models\", \"related_to_core\", \"IID test sets\"), (\"image classification models\", \"related_to_core\", \"IID test sets\"), (\"question-answering models\", \"related_to_core\", \"IID test sets\"), (\"machine learning models\", \"can\", \"make many mistakes\"), (\"image classification models\", \"has robustness\", \"true\"), (\"question-answering models\", \"investigated\", \"this\"), (\"chunk_135\", \"mentions\", \"IID test sets\"), (\"chunk_135\", \"mentions\", \"machine learning models\"), (\"chunk_135\", \"mentions\", \"image classification models\"), (\"chunk_135\", \"mentions\", \"question-answering models\")]\n",
            "✅ Extracted: [('IID test sets', 'is_core_idea', 'true'), ('chunk_135', 'is_core_chunk', 'true'), ('machine learning models', 'related_to_core', 'IID test sets'), ('image classification models', 'related_to_core', 'IID test sets'), ('question-answering models', 'related_to_core', 'IID test sets'), ('machine learning models', 'can', 'make many mistakes'), ('image classification models', 'has robustness', 'true'), ('question-answering models', 'investigated', 'this'), ('chunk_135', 'mentions', 'IID test sets'), ('chunk_135', 'mentions', 'machine learning models'), ('chunk_135', 'mentions', 'image classification models'), ('chunk_135', 'mentions', 'question-answering models')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_136...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"robustness\", \"related_to_core\", \"generalization\"), (\"generalization\", \"is_core_idea\", \"true\"), (\"chunk_136\", \"is_core_chunk\", \"true\"), (\"robustness\", \"mentions\", \"generalization\"), (\"speech recognition\", \"related_to_core\", \"generalization\"), (\"NLP\", \"related_to_core\", \"generalization\"), (\"computer vision\", \"related_to_core\", \"generalization\"), (\"chunk_136\", \"mentions\", \"robustness\"), (\"chunk_136\", \"mentions\", \"generalization\"), (\"chunk_136\", \"mentions\", \"speech recognition\"), (\"chunk_136\", \"mentions\", \"NLP\"), (\"chunk_136\", \"mentions\", \"computer vision\")]\n",
            "✅ Extracted: [('robustness', 'related_to_core', 'generalization'), ('generalization', 'is_core_idea', 'true'), ('chunk_136', 'is_core_chunk', 'true'), ('robustness', 'mentions', 'generalization'), ('speech recognition', 'related_to_core', 'generalization'), ('NLP', 'related_to_core', 'generalization'), ('computer vision', 'related_to_core', 'generalization'), ('chunk_136', 'mentions', 'robustness'), ('chunk_136', 'mentions', 'generalization'), ('chunk_136', 'mentions', 'speech recognition'), ('chunk_136', 'mentions', 'NLP'), ('chunk_136', 'mentions', 'computer vision')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_137...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Speech Recognition\", \"related_to_core\", \"Whisper\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"Whisper\"), (\"Decoding Strategies\", \"related_to_core\", \"Whisper\"), (\"Models\", \"related_to_core\", \"Whisper\"), (\"Perception-Related Errors\", \"related_to_core\", \"Whisper\"), (\"Words\", \"related_to_core\", \"Whisper\"), (\"Transcription\", \"related_to_core\", \"Whisper\"), (\"Failure Modes\", \"related_to_core\", \"Whisper\"), (\"seq2seq\", \"related_to_core\", \"Whisper\"), (\"Speech Recognition\", \"via\", \"Large-Scale Weak Supervision\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_137\", \"is_core_chunk\", \"true\"), (\"chunk_137\", \"mentions\", \"Speech Recognition\"), (\"chunk_137\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_137\", \"mentions\", \"Decoding Strategies\"), (\"chunk_137\", \"mentions\", \"Whisper\"), (\"chunk_137\", \"mentions\", \"Models\"), (\"chunk_137\", \"mentions\", \"Perception-Related Errors\"), (\"chunk_137\", \"mentions\", \"Words\"), (\"chunk_137\", \"mentions\", \"Transcription\"), (\"chunk_137\", \"mentions\", \"Failure Modes\"), (\"chunk_137\", \"mentions\", \"seq2seq\")]\n",
            "✅ Extracted: [('Speech Recognition', 'related_to_core', 'Whisper'), ('Large-Scale Weak Supervision', 'related_to_core', 'Whisper'), ('Decoding Strategies', 'related_to_core', 'Whisper'), ('Models', 'related_to_core', 'Whisper'), ('Perception-Related Errors', 'related_to_core', 'Whisper'), ('Words', 'related_to_core', 'Whisper'), ('Transcription', 'related_to_core', 'Whisper'), ('Failure Modes', 'related_to_core', 'Whisper'), ('seq2seq', 'related_to_core', 'Whisper'), ('Speech Recognition', 'via', 'Large-Scale Weak Supervision'), ('Whisper', 'is_core_idea', 'true'), ('chunk_137', 'is_core_chunk', 'true'), ('chunk_137', 'mentions', 'Speech Recognition'), ('chunk_137', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_137', 'mentions', 'Decoding Strategies'), ('chunk_137', 'mentions', 'Whisper'), ('chunk_137', 'mentions', 'Models'), ('chunk_137', 'mentions', 'Perception-Related Errors'), ('chunk_137', 'mentions', 'Words'), ('chunk_137', 'mentions', 'Transcription'), ('chunk_137', 'mentions', 'Failure Modes'), ('chunk_137', 'mentions', 'seq2seq')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_138...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"language models\", \"and\", \"text-audio alignment\"), (\"chunk_138\", \"mentions\", \"language models\"), (\"chunk_138\", \"mentions\", \"text-audio alignment\"), (\"repeat loops\", \"not tran-\", \"scribing\"), (\"chunk_138\", \"mentions\", \"repeat loops\"), (\"audio segment\", \"or\", \"complete hallucination\"), (\"chunk_138\", \"mentions\", \"audio segment\"), (\"chunk_138\", \"mentions\", \"complete hallucination\"), (\"model\", \"output\", \"transcript\"), (\"chunk_138\", \"mentions\", \"model\"), (\"chunk_138\", \"mentions\", \"transcript\"), (\"audio\", \"related to\", \"transcript\"), (\"chunk_138\", \"mentions\", \"audio\"), (\"decoding details\", \"help\", \"signiﬁcantly\"), (\"chunk_138\", \"mentions\", \"decoding details\"), (\"Whisper models\", \"on\", \"dataset\"), (\"chunk_138\", \"mentions\", \"Whisper models\"), (\"supervised dataset\", \"and/or\", \"reinforcement learning\"), (\"chunk_138\", \"mentions\", \"supervised dataset\"), (\"chunk_138\", \"mentions\", \"reinforcement learning\"), (\"Whisper models\", \"is_core_idea\", \"true\"), (\"chunk_138\", \"is_core_chunk\", \"true\"), (\"language models\", \"related_to_core\", \"Whisper models\"), (\"text-audio alignment\", \"related_to_core\", \"Whisper models\"), (\"repeat loops\", \"related_to_core\", \"Whisper models\"), (\"audio segment\", \"related_to_core\", \"Whisper models\"), (\"complete hallucination\", \"related_to_core\", \"Whisper models\"), (\"model\", \"related_to_core\", \"Whisper models\"), (\"transcript\", \"related_to_core\", \"Whisper models\"), (\"audio\", \"related_to_core\", \"Whisper models\"), (\"decoding details\", \"related_to_core\", \"Whisper models\"), (\"supervised dataset\", \"related_to_core\", \"Whisper models\"), (\"reinforcement learning\", \"related_to_core\", \"Whisper models\")]\n",
            "✅ Extracted: [('language models', 'and', 'text-audio alignment'), ('chunk_138', 'mentions', 'language models'), ('chunk_138', 'mentions', 'text-audio alignment'), ('repeat loops', 'not tran-', 'scribing'), ('chunk_138', 'mentions', 'repeat loops'), ('audio segment', 'or', 'complete hallucination'), ('chunk_138', 'mentions', 'audio segment'), ('chunk_138', 'mentions', 'complete hallucination'), ('model', 'output', 'transcript'), ('chunk_138', 'mentions', 'model'), ('chunk_138', 'mentions', 'transcript'), ('audio', 'related to', 'transcript'), ('chunk_138', 'mentions', 'audio'), ('decoding details', 'help', 'signiﬁcantly'), ('chunk_138', 'mentions', 'decoding details'), ('Whisper models', 'on', 'dataset'), ('chunk_138', 'mentions', 'Whisper models'), ('supervised dataset', 'and/or', 'reinforcement learning'), ('chunk_138', 'mentions', 'supervised dataset'), ('chunk_138', 'mentions', 'reinforcement learning'), ('Whisper models', 'is_core_idea', 'true'), ('chunk_138', 'is_core_chunk', 'true'), ('language models', 'related_to_core', 'Whisper models'), ('text-audio alignment', 'related_to_core', 'Whisper models'), ('repeat loops', 'related_to_core', 'Whisper models'), ('audio segment', 'related_to_core', 'Whisper models'), ('complete hallucination', 'related_to_core', 'Whisper models'), ('model', 'related_to_core', 'Whisper models'), ('transcript', 'related_to_core', 'Whisper models'), ('audio', 'related_to_core', 'Whisper models'), ('decoding details', 'related_to_core', 'Whisper models'), ('supervised dataset', 'related_to_core', 'Whisper models'), ('reinforcement learning', 'related_to_core', 'Whisper models')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_139...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"decoding performance\", \"is_core_idea\", \"true\"), (\"chunk_139\", \"is_core_chunk\", \"true\"), (\"chunk_139\", \"mentions\", \"decoding performance\"), (\"errors\", \"related_to_core\", \"decoding performance\"), (\"errors\", \"related_to_core\", \"decoding performance\"), (\"Training Data\", \"related_to_core\", \"decoding performance\"), (\"Lower-Resource Languages\", \"related_to_core\", \"decoding performance\"), (\"Whisper\", \"related_to_core\", \"decoding performance\"), (\"speech recognition\", \"related_to_core\", \"decoding performance\"), (\"languages\", \"related_to_core\", \"decoding performance\"), (\"language\", \"related_to_core\", \"decoding performance\"), (\"training data\", \"related_to_core\", \"decoding performance\"), (\"language\", \"related_to_core\", \"decoding performance\"), (\"pre-training dataset\", \"related_to_core\", \"decoding performance\"), (\"English\", \"related_to_core\", \"decoding performance\"), (\"errors\", \"related_to_core\", \"decoding performance\"), (\"errors\", \"related_to_core\", \"decoding performance\"), (\"Training Data\", \"related_to_core\", \"decoding performance\"), (\"Lower-Resource Languages\", \"related_to_core\", \"decoding performance\"), (\"Whisper\", \"related_to_core\", \"decoding performance\"), (\"speech recognition\", \"related_to_core\", \"decoding performance\"), (\"languages\", \"related_to_core\", \"decoding performance\"), (\"language\", \"related_to_core\", \"decoding performance\"), (\"training data\", \"related_to_core\", \"decoding performance\"), (\"language\", \"related_to_core\", \"decoding performance\"), (\"pre-training dataset\", \"related_to_core\", \"decoding performance\"), (\"English\", \"related_to_core\", \"decoding performance\"), (\"chunk_139\", \"mentions\", \"errors\"), (\"chunk_139\", \"mentions\", \"Training Data\"), (\"chunk_139\", \"mentions\", \"Lower-Resource Languages\"), (\"chunk_139\", \"mentions\", \"Whisper\"), (\"chunk_139\", \"mentions\", \"speech recognition\"), (\"chunk_139\", \"mentions\", \"languages\"), (\"chunk_139\", \"mentions\", \"language\"), (\"chunk_139\", \"mentions\", \"training data\"), (\"chunk_139\", \"mentions\", \"pre-training dataset\"), (\"chunk_139\", \"mentions\", \"English\")]\n",
            "✅ Extracted: [('decoding performance', 'is_core_idea', 'true'), ('chunk_139', 'is_core_chunk', 'true'), ('chunk_139', 'mentions', 'decoding performance'), ('errors', 'related_to_core', 'decoding performance'), ('errors', 'related_to_core', 'decoding performance'), ('Training Data', 'related_to_core', 'decoding performance'), ('Lower-Resource Languages', 'related_to_core', 'decoding performance'), ('Whisper', 'related_to_core', 'decoding performance'), ('speech recognition', 'related_to_core', 'decoding performance'), ('languages', 'related_to_core', 'decoding performance'), ('language', 'related_to_core', 'decoding performance'), ('training data', 'related_to_core', 'decoding performance'), ('language', 'related_to_core', 'decoding performance'), ('pre-training dataset', 'related_to_core', 'decoding performance'), ('English', 'related_to_core', 'decoding performance'), ('errors', 'related_to_core', 'decoding performance'), ('errors', 'related_to_core', 'decoding performance'), ('Training Data', 'related_to_core', 'decoding performance'), ('Lower-Resource Languages', 'related_to_core', 'decoding performance'), ('Whisper', 'related_to_core', 'decoding performance'), ('speech recognition', 'related_to_core', 'decoding performance'), ('languages', 'related_to_core', 'decoding performance'), ('language', 'related_to_core', 'decoding performance'), ('training data', 'related_to_core', 'decoding performance'), ('language', 'related_to_core', 'decoding performance'), ('pre-training dataset', 'related_to_core', 'decoding performance'), ('English', 'related_to_core', 'decoding performance'), ('chunk_139', 'mentions', 'errors'), ('chunk_139', 'mentions', 'Training Data'), ('chunk_139', 'mentions', 'Lower-Resource Languages'), ('chunk_139', 'mentions', 'Whisper'), ('chunk_139', 'mentions', 'speech recognition'), ('chunk_139', 'mentions', 'languages'), ('chunk_139', 'mentions', 'language'), ('chunk_139', 'mentions', 'training data'), ('chunk_139', 'mentions', 'pre-training dataset'), ('chunk_139', 'mentions', 'English')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_140...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"data collection pipeline\", \"mentions\", \"English\"), (\"data collection pipeline\", \"mentions\", \"languages\"), (\"data collection pipeline\", \"mentions\", \"training data\"), (\"data collection pipeline\", \"mentions\", \"speech recognition performance\"), (\"data collection pipeline\", \"mentions\", \"training dataset\"), (\"data collection pipeline\", \"mentions\", \"speech processing systems\"), (\"chunk_140\", \"mentions\", \"data collection pipeline\"), (\"chunk_140\", \"mentions\", \"English\"), (\"chunk_140\", \"mentions\", \"languages\"), (\"chunk_140\", \"mentions\", \"training data\"), (\"chunk_140\", \"mentions\", \"speech recognition performance\"), (\"chunk_140\", \"mentions\", \"training dataset\"), (\"chunk_140\", \"mentions\", \"speech processing systems\"), (\"speech processing systems\", \"related_to_core\", \"training data\"), (\"speech recognition performance\", \"related_to_core\", \"training data\"), (\"training dataset\", \"related_to_core\", \"training data\"), (\"languages\", \"related_to_core\", \"training data\"), (\"English\", \"related_to_core\", \"training data\"), (\"training data\", \"is_core_idea\", \"true\"), (\"chunk_140\", \"is_core_chunk\", \"true\")]\n",
            "✅ Extracted: [('data collection pipeline', 'mentions', 'English'), ('data collection pipeline', 'mentions', 'languages'), ('data collection pipeline', 'mentions', 'training data'), ('data collection pipeline', 'mentions', 'speech recognition performance'), ('data collection pipeline', 'mentions', 'training dataset'), ('data collection pipeline', 'mentions', 'speech processing systems'), ('chunk_140', 'mentions', 'data collection pipeline'), ('chunk_140', 'mentions', 'English'), ('chunk_140', 'mentions', 'languages'), ('chunk_140', 'mentions', 'training data'), ('chunk_140', 'mentions', 'speech recognition performance'), ('chunk_140', 'mentions', 'training dataset'), ('chunk_140', 'mentions', 'speech processing systems'), ('speech processing systems', 'related_to_core', 'training data'), ('speech recognition performance', 'related_to_core', 'training data'), ('training dataset', 'related_to_core', 'training data'), ('languages', 'related_to_core', 'training data'), ('English', 'related_to_core', 'training data'), ('training data', 'is_core_idea', 'true'), ('chunk_140', 'is_core_chunk', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_141...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"zero-shot transfer performance\", \"related_to_core\", \"Whisper\"), (\"Whisper\", \"is_core_idea\", \"true\"), (\"chunk_141\", \"is_core_chunk\", \"true\"), (\"supervised speech data\", \"related_to_core\", \"Whisper\"), (\"fine-tuning\", \"related_to_core\", \"Whisper\"), (\"evaluation setting\", \"related_to_core\", \"Whisper\"), (\"chunk_141\", \"mentions\", \"zero-shot transfer performance\"), (\"chunk_141\", \"mentions\", \"Whisper\"), (\"chunk_141\", \"mentions\", \"supervised speech data\"), (\"chunk_141\", \"mentions\", \"fine-tuning\"), (\"chunk_141\", \"mentions\", \"evaluation setting\")]\n",
            "✅ Extracted: [('zero-shot transfer performance', 'related_to_core', 'Whisper'), ('Whisper', 'is_core_idea', 'true'), ('chunk_141', 'is_core_chunk', 'true'), ('supervised speech data', 'related_to_core', 'Whisper'), ('fine-tuning', 'related_to_core', 'Whisper'), ('evaluation setting', 'related_to_core', 'Whisper'), ('chunk_141', 'mentions', 'zero-shot transfer performance'), ('chunk_141', 'mentions', 'Whisper'), ('chunk_141', 'mentions', 'supervised speech data'), ('chunk_141', 'mentions', 'fine-tuning'), ('chunk_141', 'mentions', 'evaluation setting')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_142...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"evaluation setting\", \"is_core_idea\", \"true\"), (\"chunk_142\", \"is_core_chunk\", \"true\"), (\"Language Models\", \"related_to_core\", \"evaluation setting\"), (\"Whisper\", \"related_to_core\", \"evaluation setting\"), (\"decoder\", \"related_to_core\", \"evaluation setting\"), (\"audio conditional language model\", \"related_to_core\", \"evaluation setting\"), (\"encoder\", \"related_to_core\", \"evaluation setting\"), (\"design components\", \"related_to_core\", \"evaluation setting\"), (\"CTC model\", \"related_to_core\", \"evaluation setting\"), (\"evaluation setting\", \"instance of\", \"setting\"), (\"Language Models\", \"instance of\", \"model\"), (\"Language Models\", \"on\", \"Robustness\"), (\"Whisper\", \"instance of\", \"model\"), (\"robustness\", \"partially due to\", \"decoder\"), (\"decoder\", \"instance of\", \"language model\"), (\"decoder\", \"is\", \"audio conditional language model\"), (\"encoder\", \"or\", \"decoder\"), (\"design components\", \"of\", \"Whisper\"), (\"CTC model\", \"instance of\", \"model\"), (\"CTC model\", \"is\", \"decoder-less\"), (\"chunk_142\", \"mentions\", \"evaluation setting\"), (\"chunk_142\", \"mentions\", \"Language Models\"), (\"chunk_142\", \"mentions\", \"Robustness\"), (\"chunk_142\", \"mentions\", \"Whisper\"), (\"chunk_142\", \"mentions\", \"robustness\"), (\"chunk_142\", \"mentions\", \"decoder\"), (\"chunk_142\", \"mentions\", \"audio conditional language model\"), (\"chunk_142\", \"mentions\", \"encoder\"), (\"chunk_142\", \"mentions\", \"design components\"), (\"chunk_142\", \"mentions\", \"CTC model\")]\n",
            "✅ Extracted: [('evaluation setting', 'is_core_idea', 'true'), ('chunk_142', 'is_core_chunk', 'true'), ('Language Models', 'related_to_core', 'evaluation setting'), ('Whisper', 'related_to_core', 'evaluation setting'), ('decoder', 'related_to_core', 'evaluation setting'), ('audio conditional language model', 'related_to_core', 'evaluation setting'), ('encoder', 'related_to_core', 'evaluation setting'), ('design components', 'related_to_core', 'evaluation setting'), ('CTC model', 'related_to_core', 'evaluation setting'), ('evaluation setting', 'instance of', 'setting'), ('Language Models', 'instance of', 'model'), ('Language Models', 'on', 'Robustness'), ('Whisper', 'instance of', 'model'), ('robustness', 'partially due to', 'decoder'), ('decoder', 'instance of', 'language model'), ('decoder', 'is', 'audio conditional language model'), ('encoder', 'or', 'decoder'), ('design components', 'of', 'Whisper'), ('CTC model', 'instance of', 'model'), ('CTC model', 'is', 'decoder-less'), ('chunk_142', 'mentions', 'evaluation setting'), ('chunk_142', 'mentions', 'Language Models'), ('chunk_142', 'mentions', 'Robustness'), ('chunk_142', 'mentions', 'Whisper'), ('chunk_142', 'mentions', 'robustness'), ('chunk_142', 'mentions', 'decoder'), ('chunk_142', 'mentions', 'audio conditional language model'), ('chunk_142', 'mentions', 'encoder'), ('chunk_142', 'mentions', 'design components'), ('chunk_142', 'mentions', 'CTC model')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_143...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"speech recognition encoders\", \"mentions\", \"speech recognition encoders\"), (\"chunk_143\", \"mentions\", \"speech recognition encoders\"), (\"wav2vec 2.0\", \"mentions\", \"wav2vec 2.0\"), (\"chunk_143\", \"mentions\", \"wav2vec 2.0\"), (\"language model\", \"mentions\", \"language model\"), (\"chunk_143\", \"mentions\", \"language model\"), (\"Auxiliary Training Objectives\", \"mentions\", \"Auxiliary Training Objectives\"), (\"chunk_143\", \"mentions\", \"Auxiliary Training Objectives\"), (\"Whisper\", \"mentions\", \"Whisper\"), (\"chunk_143\", \"mentions\", \"Whisper\"), (\"state-of-the-art speech recognition systems\", \"mentions\", \"state-of-the-art speech recognition systems\"), (\"chunk_143\", \"mentions\", \"state-of-the-art speech recognition systems\"), (\"unsupervised pre-training\", \"mentions\", \"unsupervised pre-training\"), (\"chunk_143\", \"mentions\", \"unsupervised pre-training\"), (\"self-teaching methods\", \"mentions\", \"self-teaching methods\"), (\"chunk_143\", \"mentions\", \"self-teaching methods\"), (\"speech recognition encoders\", \"performance_of\", \"wav2vec 2.0\"), (\"speech recognition encoders\", \"used_with\", \"language model\"), (\"Whisper\", \"departs_from\", \"state-of-the-art speech recognition systems\"), (\"speech recognition encoders\", \"is_core_idea\", \"true\"), (\"chunk_143\", \"is_core_chunk\", \"true\"), (\"wav2vec 2.0\", \"related_to_core\", \"speech recognition encoders\"), (\"language model\", \"related_to_core\", \"speech recognition encoders\"), (\"Auxiliary Training Objectives\", \"related_to_core\", \"speech recognition encoders\"), (\"Whisper\", \"related_to_core\", \"speech recognition encoders\"), (\"state-of-the-art speech recognition systems\", \"related_to_core\", \"speech recognition encoders\"), (\"unsupervised pre-training\", \"related_to_core\", \"speech recognition encoders\"), (\"self-teaching methods\", \"related_to_core\", \"speech recognition encoders\")]\n",
            "✅ Extracted: [('speech recognition encoders', 'mentions', 'speech recognition encoders'), ('chunk_143', 'mentions', 'speech recognition encoders'), ('wav2vec 2.0', 'mentions', 'wav2vec 2.0'), ('chunk_143', 'mentions', 'wav2vec 2.0'), ('language model', 'mentions', 'language model'), ('chunk_143', 'mentions', 'language model'), ('Auxiliary Training Objectives', 'mentions', 'Auxiliary Training Objectives'), ('chunk_143', 'mentions', 'Auxiliary Training Objectives'), ('Whisper', 'mentions', 'Whisper'), ('chunk_143', 'mentions', 'Whisper'), ('state-of-the-art speech recognition systems', 'mentions', 'state-of-the-art speech recognition systems'), ('chunk_143', 'mentions', 'state-of-the-art speech recognition systems'), ('unsupervised pre-training', 'mentions', 'unsupervised pre-training'), ('chunk_143', 'mentions', 'unsupervised pre-training'), ('self-teaching methods', 'mentions', 'self-teaching methods'), ('chunk_143', 'mentions', 'self-teaching methods'), ('speech recognition encoders', 'performance_of', 'wav2vec 2.0'), ('speech recognition encoders', 'used_with', 'language model'), ('Whisper', 'departs_from', 'state-of-the-art speech recognition systems'), ('speech recognition encoders', 'is_core_idea', 'true'), ('chunk_143', 'is_core_chunk', 'true'), ('wav2vec 2.0', 'related_to_core', 'speech recognition encoders'), ('language model', 'related_to_core', 'speech recognition encoders'), ('Auxiliary Training Objectives', 'related_to_core', 'speech recognition encoders'), ('Whisper', 'related_to_core', 'speech recognition encoders'), ('state-of-the-art speech recognition systems', 'related_to_core', 'speech recognition encoders'), ('unsupervised pre-training', 'related_to_core', 'speech recognition encoders'), ('self-teaching methods', 'related_to_core', 'speech recognition encoders')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_144...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Whisper\", \"suggests\", \"scaling weakly supervised pre-training\"), (\"chunk_144\", \"mentions\", \"Whisper\"), (\"chunk_144\", \"mentions\", \"scaling weakly supervised pre-training\"), (\"scaling weakly supervised pre-training\", \"is_core_idea\", \"true\"), (\"chunk_144\", \"is_core_chunk\", \"true\"), (\"speech recognition research\", \"related_to_core\", \"scaling weakly supervised pre-training\"), (\"chunk_144\", \"mentions\", \"speech recognition research\"), (\"self-supervision\", \"related_to_core\", \"scaling weakly supervised pre-training\"), (\"chunk_144\", \"mentions\", \"self-supervision\"), (\"self-training techniques\", \"related_to_core\", \"scaling weakly supervised pre-training\"), (\"chunk_144\", \"mentions\", \"self-training techniques\"), (\"large-scale speech recognition\", \"related_to_core\", \"scaling weakly supervised pre-training\"), (\"chunk_144\", \"mentions\", \"large-scale speech recognition\"), (\"supervised dataset\", \"related_to_core\", \"scaling weakly supervised pre-training\"), (\"chunk_144\", \"mentions\", \"supervised dataset\"), (\"zero-shot transfer\", \"related_to_core\", \"scaling weakly supervised pre-training\"), (\"chunk_144\", \"mentions\", \"zero-shot transfer\"), (\"speech recognition system\", \"related_to_core\", \"scaling weakly supervised pre-training\"), (\"chunk_144\", \"mentions\", \"speech recognition system\")]\n",
            "✅ Extracted: [('Whisper', 'suggests', 'scaling weakly supervised pre-training'), ('chunk_144', 'mentions', 'Whisper'), ('chunk_144', 'mentions', 'scaling weakly supervised pre-training'), ('scaling weakly supervised pre-training', 'is_core_idea', 'true'), ('chunk_144', 'is_core_chunk', 'true'), ('speech recognition research', 'related_to_core', 'scaling weakly supervised pre-training'), ('chunk_144', 'mentions', 'speech recognition research'), ('self-supervision', 'related_to_core', 'scaling weakly supervised pre-training'), ('chunk_144', 'mentions', 'self-supervision'), ('self-training techniques', 'related_to_core', 'scaling weakly supervised pre-training'), ('chunk_144', 'mentions', 'self-training techniques'), ('large-scale speech recognition', 'related_to_core', 'scaling weakly supervised pre-training'), ('chunk_144', 'mentions', 'large-scale speech recognition'), ('supervised dataset', 'related_to_core', 'scaling weakly supervised pre-training'), ('chunk_144', 'mentions', 'supervised dataset'), ('zero-shot transfer', 'related_to_core', 'scaling weakly supervised pre-training'), ('chunk_144', 'mentions', 'zero-shot transfer'), ('speech recognition system', 'related_to_core', 'scaling weakly supervised pre-training'), ('chunk_144', 'mentions', 'speech recognition system')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_145...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"recognition system\", \"is_core_idea\", \"true\"), (\"chunk_145\", \"is_core_chunk\", \"true\"), (\"chunk_145\", \"mentions\", \"recognition system\"), (\"data\", \"related_to_core\", \"recognition system\"), (\"Nick Ryder\", \"related_to_core\", \"recognition system\"), (\"Will Zhuk\", \"related_to_core\", \"recognition system\"), (\"Andrew Carr\", \"related_to_core\", \"recognition system\"), (\"waterfall hike\", \"related_to_core\", \"recognition system\"), (\"project\", \"related_to_core\", \"recognition system\"), (\"Acceleration\", \"related_to_core\", \"recognition system\"), (\"Supercomputing\", \"related_to_core\", \"recognition system\"), (\"OpenAI\", \"related_to_core\", \"recognition system\"), (\"software\", \"related_to_core\", \"recognition system\"), (\"hardware infrastructure\", \"related_to_core\", \"recognition system\"), (\"data\", \"used_by\", \"Whisper\"), (\"chunk_145\", \"mentions\", \"data\"), (\"chunk_145\", \"mentions\", \"Whisper\"), (\"chunk_145\", \"mentions\", \"Nick Ryder\"), (\"chunk_145\", \"mentions\", \"Will Zhuk\"), (\"chunk_145\", \"mentions\", \"Andrew Carr\"), (\"chunk_145\", \"mentions\", \"waterfall hike\"), (\"chunk_145\", \"mentions\", \"project\"), (\"chunk_145\", \"mentions\", \"Acceleration\"), (\"chunk_145\", \"mentions\", \"Supercomputing\"), (\"chunk_145\", \"mentions\", \"OpenAI\"), (\"chunk_145\", \"mentions\", \"software\"), (\"chunk_145\", \"mentions\", \"hardware infrastructure\")]\n",
            "✅ Extracted: [('recognition system', 'is_core_idea', 'true'), ('chunk_145', 'is_core_chunk', 'true'), ('chunk_145', 'mentions', 'recognition system'), ('data', 'related_to_core', 'recognition system'), ('Nick Ryder', 'related_to_core', 'recognition system'), ('Will Zhuk', 'related_to_core', 'recognition system'), ('Andrew Carr', 'related_to_core', 'recognition system'), ('waterfall hike', 'related_to_core', 'recognition system'), ('project', 'related_to_core', 'recognition system'), ('Acceleration', 'related_to_core', 'recognition system'), ('Supercomputing', 'related_to_core', 'recognition system'), ('OpenAI', 'related_to_core', 'recognition system'), ('software', 'related_to_core', 'recognition system'), ('hardware infrastructure', 'related_to_core', 'recognition system'), ('data', 'used_by', 'Whisper'), ('chunk_145', 'mentions', 'data'), ('chunk_145', 'mentions', 'Whisper'), ('chunk_145', 'mentions', 'Nick Ryder'), ('chunk_145', 'mentions', 'Will Zhuk'), ('chunk_145', 'mentions', 'Andrew Carr'), ('chunk_145', 'mentions', 'waterfall hike'), ('chunk_145', 'mentions', 'project'), ('chunk_145', 'mentions', 'Acceleration'), ('chunk_145', 'mentions', 'Supercomputing'), ('chunk_145', 'mentions', 'OpenAI'), ('chunk_145', 'mentions', 'software'), ('chunk_145', 'mentions', 'hardware infrastructure')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_146...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Pamela Mishkin\", \"is_advisor_of\", \"project\"), (\"policy perspective\", \"is_perspective_of\", \"Pamela Mishkin\"), (\"software packages\", \"used_in\", \"project\"), (\"Numpy\", \"is_a\", \"software package\"), (\"SciPy\", \"is_a\", \"software package\"), (\"ftfy\", \"is_a\", \"software package\"), (\"PyTorch\", \"is_a\", \"software package\"), (\"pandas\", \"is_a\", \"software package\"), (\"scikit-learn\", \"is_a\", \"software package\"), (\"chunk_146\", \"mentions\", \"Pamela Mishkin\"), (\"chunk_146\", \"mentions\", \"policy perspective\"), (\"chunk_146\", \"mentions\", \"software packages\"), (\"chunk_146\", \"mentions\", \"Numpy\"), (\"chunk_146\", \"mentions\", \"SciPy\"), (\"chunk_146\", \"mentions\", \"ftfy\"), (\"chunk_146\", \"mentions\", \"PyTorch\"), (\"chunk_146\", \"mentions\", \"pandas\"), (\"chunk_146\", \"mentions\", \"scikit-learn\")]\n",
            "✅ Extracted: [('Pamela Mishkin', 'is_advisor_of', 'project'), ('policy perspective', 'is_perspective_of', 'Pamela Mishkin'), ('software packages', 'used_in', 'project'), ('Numpy', 'is_a', 'software package'), ('SciPy', 'is_a', 'software package'), ('ftfy', 'is_a', 'software package'), ('PyTorch', 'is_a', 'software package'), ('pandas', 'is_a', 'software package'), ('scikit-learn', 'is_a', 'software package'), ('chunk_146', 'mentions', 'Pamela Mishkin'), ('chunk_146', 'mentions', 'policy perspective'), ('chunk_146', 'mentions', 'software packages'), ('chunk_146', 'mentions', 'Numpy'), ('chunk_146', 'mentions', 'SciPy'), ('chunk_146', 'mentions', 'ftfy'), ('chunk_146', 'mentions', 'PyTorch'), ('chunk_146', 'mentions', 'pandas'), ('chunk_146', 'mentions', 'scikit-learn')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_147...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Neural networks\", \"are_fooled_by\", \"strange poses\"), (\"familiar objects\", \"has_property\", \"familiar\"), (\"IEEE/CVF Conference on Computer Vision and Pattern Recognition\", \"is_a\", \"Conference\"), (\"Deep speech 2\", \"is_a\", \"speech recognition\"), (\"English\", \"is_a\", \"language\"), (\"Mandarin\", \"is_a\", \"language\"), (\"chunk_147\", \"mentions\", \"Neural networks\"), (\"chunk_147\", \"mentions\", \"familiar objects\"), (\"chunk_147\", \"mentions\", \"IEEE/CVF Conference on Computer Vision and Pattern Recognition\"), (\"chunk_147\", \"mentions\", \"Deep speech 2\"), (\"chunk_147\", \"mentions\", \"English\"), (\"chunk_147\", \"mentions\", \"Mandarin\"), (\"Neural networks\", \"is_core_idea\", \"true\"), (\"chunk_147\", \"is_core_chunk\", \"true\"), (\"familiar objects\", \"related_to_core\", \"Neural networks\"), (\"IEEE/CVF Conference on Computer Vision and Pattern Recognition\", \"related_to_core\", \"Neural networks\"), (\"Deep speech 2\", \"related_to_core\", \"Neural networks\"), (\"English\", \"related_to_core\", \"Neural networks\"), (\"Mandarin\", \"related_to_core\", \"Neural networks\")]\n",
            "✅ Extracted: [('Neural networks', 'are_fooled_by', 'strange poses'), ('familiar objects', 'has_property', 'familiar'), ('IEEE/CVF Conference on Computer Vision and Pattern Recognition', 'is_a', 'Conference'), ('Deep speech 2', 'is_a', 'speech recognition'), ('English', 'is_a', 'language'), ('Mandarin', 'is_a', 'language'), ('chunk_147', 'mentions', 'Neural networks'), ('chunk_147', 'mentions', 'familiar objects'), ('chunk_147', 'mentions', 'IEEE/CVF Conference on Computer Vision and Pattern Recognition'), ('chunk_147', 'mentions', 'Deep speech 2'), ('chunk_147', 'mentions', 'English'), ('chunk_147', 'mentions', 'Mandarin'), ('Neural networks', 'is_core_idea', 'true'), ('chunk_147', 'is_core_chunk', 'true'), ('familiar objects', 'related_to_core', 'Neural networks'), ('IEEE/CVF Conference on Computer Vision and Pattern Recognition', 'related_to_core', 'Neural networks'), ('Deep speech 2', 'related_to_core', 'Neural networks'), ('English', 'related_to_core', 'Neural networks'), ('Mandarin', 'related_to_core', 'Neural networks')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_148...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"arXiv:1512.02595\", \"mentions\", \"2015\"), (\"chunk_148\", \"mentions\", \"arXiv:1512.02595\"), (\"chunk_148\", \"mentions\", \"Ardila\"), (\"chunk_148\", \"mentions\", \"R\"), (\"chunk_148\", \"mentions\", \"Branson\"), (\"chunk_148\", \"mentions\", \"M\"), (\"chunk_148\", \"mentions\", \"Davis\"), (\"chunk_148\", \"mentions\", \"K\"), (\"chunk_148\", \"mentions\", \"Henretty\"), (\"chunk_148\", \"mentions\", \"Kohler\"), (\"chunk_148\", \"mentions\", \"M\"), (\"chunk_148\", \"mentions\", \"Meyer\"), (\"chunk_148\", \"mentions\", \"J\"), (\"chunk_148\", \"mentions\", \"Morais\"), (\"chunk_148\", \"mentions\", \"R\"), (\"chunk_148\", \"mentions\", \"Saunders\"), (\"chunk_148\", \"mentions\", \"L\"), (\"chunk_148\", \"mentions\", \"Tyers\"), (\"chunk_148\", \"mentions\", \"F. M\")]\n",
            "✅ Extracted: [('arXiv:1512.02595', 'mentions', '2015'), ('chunk_148', 'mentions', 'arXiv:1512.02595'), ('chunk_148', 'mentions', 'Ardila'), ('chunk_148', 'mentions', 'R'), ('chunk_148', 'mentions', 'Branson'), ('chunk_148', 'mentions', 'M'), ('chunk_148', 'mentions', 'Davis'), ('chunk_148', 'mentions', 'K'), ('chunk_148', 'mentions', 'Henretty'), ('chunk_148', 'mentions', 'Kohler'), ('chunk_148', 'mentions', 'M'), ('chunk_148', 'mentions', 'Meyer'), ('chunk_148', 'mentions', 'J'), ('chunk_148', 'mentions', 'Morais'), ('chunk_148', 'mentions', 'R'), ('chunk_148', 'mentions', 'Saunders'), ('chunk_148', 'mentions', 'L'), ('chunk_148', 'mentions', 'Tyers'), ('chunk_148', 'mentions', 'F. M')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_149...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_149\", \"is_core_chunk\", \"true\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Common voice\", \"related_to_core\", \"Robust Speech Recognition\"), (\"speech corpus\", \"related_to_core\", \"Robust Speech Recognition\"), (\"XLS-R\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Self-supervised cross-lingual speech representation learning\", \"related_to_core\", \"Robust Speech Recognition\"), (\"wav2vec\", \"related_to_core\", \"Robust Speech Recognition\"), (\"chunk_149\", \"mentions\", \"Robust Speech Recognition\"), (\"chunk_149\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_149\", \"mentions\", \"Common voice\"), (\"chunk_149\", \"mentions\", \"speech corpus\"), (\"chunk_149\", \"mentions\", \"XLS-R\"), (\"chunk_149\", \"mentions\", \"Self-supervised cross-lingual speech representation learning\"), (\"chunk_149\", \"mentions\", \"wav2vec\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'is_core_idea', 'true'), ('chunk_149', 'is_core_chunk', 'true'), ('Large-Scale Weak Supervision', 'related_to_core', 'Robust Speech Recognition'), ('Large-Scale Weak Supervision', 'related_to_core', 'Robust Speech Recognition'), ('Common voice', 'related_to_core', 'Robust Speech Recognition'), ('speech corpus', 'related_to_core', 'Robust Speech Recognition'), ('XLS-R', 'related_to_core', 'Robust Speech Recognition'), ('Self-supervised cross-lingual speech representation learning', 'related_to_core', 'Robust Speech Recognition'), ('wav2vec', 'related_to_core', 'Robust Speech Recognition'), ('chunk_149', 'mentions', 'Robust Speech Recognition'), ('chunk_149', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_149', 'mentions', 'Common voice'), ('chunk_149', 'mentions', 'speech corpus'), ('chunk_149', 'mentions', 'XLS-R'), ('chunk_149', 'mentions', 'Self-supervised cross-lingual speech representation learning'), ('chunk_149', 'mentions', 'wav2vec')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_150...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"self-supervised learning\", \"is_core_idea\", \"true\"), (\"chunk_150\", \"is_core_chunk\", \"true\"), (\"chunk_150\", \"mentions\", \"self-supervised learning\"), (\"speech representations\", \"related_to_core\", \"self-supervised learning\"), (\"speech representations\", \"related_to_core\", \"self-supervised learning\"), (\"speech representations\", \"related_to_core\", \"self-supervised learning\"), (\"speech representations\", \"related_to_core\", \"self-supervised learning\"), (\"framework\", \"related_to_core\", \"self-supervised learning\"), (\"framework\", \"related_to_core\", \"self-supervised learning\"), (\"framework\", \"related_to_core\", \"self-supervised learning\"), (\"framework\", \"related_to_core\", \"self-supervised learning\"), (\"framework\", \"related_to_core\", \"self-supervised learning\"), (\"framework\", \"related_to_core\", \"self-supervised learning\"), (\"framework\", \"related_to_core\", \"self-supervised learning\"), (\"framework\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\", \"self-supervised learning\"), (\"arXiv\", \"related_to_core\n",
            "❌ Parse error: unterminated string literal (detected at line 1) (<unknown>, line 1)\n",
            "✅ Extracted: []\n",
            "🔍 Processing chunk_151...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"arXiv preprint\", \"mentions\", \"arXiv:2202.01374\"), (\"chunk_151\", \"mentions\", \"arXiv preprint\"), (\"arXiv:2202.01374\", \"is_core_idea\", \"true\"), (\"chunk_151\", \"is_core_chunk\", \"true\"), (\"Barbu, A.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Mayo, D.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Alverio, J.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Luo, W.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Wang, C.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Gut-freund, D.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Tenenbaum, J.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Katz, B.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Objectnet\", \"related_to_core\", \"arXiv:2202.01374\"), (\"object recognition models\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Advances in neural information processing systems\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Caruana, R.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Multitask learning\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Machine learning\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Chan, W.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Park, D.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Lee, C.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Zhang, Y\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Le, Q.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"Norouzi, M.\", \"related_to_core\", \"arXiv:2202.01374\"), (\"SpeechStew\", \"related_to_core\", \"arXiv:2202.01374\"), (\"speech recognition\", \"related_to_core\", \"arXiv:2202.01374\"), (\"chunk_151\", \"mentions\", \"Barbu, A.\"), (\"chunk_151\", \"mentions\", \"Mayo, D.\"), (\"chunk_151\", \"mentions\", \"Alverio, J.\"), (\"chunk_151\", \"mentions\", \"Luo, W.\"), (\"chunk_151\", \"mentions\", \"Wang, C.\"), (\"chunk_151\", \"mentions\", \"Gut-freund, D.\"), (\"chunk_151\", \"mentions\", \"Tenenbaum, J.\"), (\"chunk_151\", \"mentions\", \"Katz, B.\"), (\"chunk_151\", \"mentions\", \"Objectnet\"), (\"chunk_151\", \"mentions\", \"object recognition models\"), (\"chunk_151\", \"mentions\", \"Advances in neural information processing systems\"), (\"chunk_151\", \"mentions\", \"Caruana, R.\"), (\"chunk_151\", \"mentions\", \"Multitask learning\"), (\"chunk_151\", \"mentions\", \"Machine learning\"), (\"chunk_151\", \"mentions\", \"Chan, W.\"), (\"chunk_151\", \"mentions\", \"Park, D.\"), (\"chunk_151\", \"mentions\", \"Lee, C.\"), (\"chunk_151\", \"mentions\", \"Zhang, Y\"), (\"chunk_151\", \"mentions\", \"Le, Q.\"), (\"chunk_151\", \"mentions\", \"Norouzi, M.\"), (\"chunk_151\", \"mentions\", \"SpeechStew\"), (\"chunk_151\", \"mentions\", \"speech recognition\")]\n",
            "✅ Extracted: [('arXiv preprint', 'mentions', 'arXiv:2202.01374'), ('chunk_151', 'mentions', 'arXiv preprint'), ('arXiv:2202.01374', 'is_core_idea', 'true'), ('chunk_151', 'is_core_chunk', 'true'), ('Barbu, A.', 'related_to_core', 'arXiv:2202.01374'), ('Mayo, D.', 'related_to_core', 'arXiv:2202.01374'), ('Alverio, J.', 'related_to_core', 'arXiv:2202.01374'), ('Luo, W.', 'related_to_core', 'arXiv:2202.01374'), ('Wang, C.', 'related_to_core', 'arXiv:2202.01374'), ('Gut-freund, D.', 'related_to_core', 'arXiv:2202.01374'), ('Tenenbaum, J.', 'related_to_core', 'arXiv:2202.01374'), ('Katz, B.', 'related_to_core', 'arXiv:2202.01374'), ('Objectnet', 'related_to_core', 'arXiv:2202.01374'), ('object recognition models', 'related_to_core', 'arXiv:2202.01374'), ('Advances in neural information processing systems', 'related_to_core', 'arXiv:2202.01374'), ('Caruana, R.', 'related_to_core', 'arXiv:2202.01374'), ('Multitask learning', 'related_to_core', 'arXiv:2202.01374'), ('Machine learning', 'related_to_core', 'arXiv:2202.01374'), ('Chan, W.', 'related_to_core', 'arXiv:2202.01374'), ('Park, D.', 'related_to_core', 'arXiv:2202.01374'), ('Lee, C.', 'related_to_core', 'arXiv:2202.01374'), ('Zhang, Y', 'related_to_core', 'arXiv:2202.01374'), ('Le, Q.', 'related_to_core', 'arXiv:2202.01374'), ('Norouzi, M.', 'related_to_core', 'arXiv:2202.01374'), ('SpeechStew', 'related_to_core', 'arXiv:2202.01374'), ('speech recognition', 'related_to_core', 'arXiv:2202.01374'), ('chunk_151', 'mentions', 'Barbu, A.'), ('chunk_151', 'mentions', 'Mayo, D.'), ('chunk_151', 'mentions', 'Alverio, J.'), ('chunk_151', 'mentions', 'Luo, W.'), ('chunk_151', 'mentions', 'Wang, C.'), ('chunk_151', 'mentions', 'Gut-freund, D.'), ('chunk_151', 'mentions', 'Tenenbaum, J.'), ('chunk_151', 'mentions', 'Katz, B.'), ('chunk_151', 'mentions', 'Objectnet'), ('chunk_151', 'mentions', 'object recognition models'), ('chunk_151', 'mentions', 'Advances in neural information processing systems'), ('chunk_151', 'mentions', 'Caruana, R.'), ('chunk_151', 'mentions', 'Multitask learning'), ('chunk_151', 'mentions', 'Machine learning'), ('chunk_151', 'mentions', 'Chan, W.'), ('chunk_151', 'mentions', 'Park, D.'), ('chunk_151', 'mentions', 'Lee, C.'), ('chunk_151', 'mentions', 'Zhang, Y'), ('chunk_151', 'mentions', 'Le, Q.'), ('chunk_151', 'mentions', 'Norouzi, M.'), ('chunk_151', 'mentions', 'SpeechStew'), ('chunk_151', 'mentions', 'speech recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_152...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"neural network\", \"is_core_idea\", \"true\"), (\"chunk_152\", \"is_core_chunk\", \"true\"), (\"chunk_152\", \"mentions\", \"neural network\"), (\"arXiv preprint\", \"related_to_core\", \"neural network\"), (\"arXiv:2104.02133\", \"related_to_core\", \"neural network\"), (\"Gigaspeech\", \"related_to_core\", \"neural network\"), (\"asr corpus\", \"related_to_core\", \"neural network\"), (\"transcribed audio\", \"related_to_core\", \"neural network\"), (\"arXiv:2106.06909\", \"related_to_core\", \"neural network\"), (\"Unispeech-sat\", \"related_to_core\", \"neural network\"), (\"speech representation learning\", \"related_to_core\", \"neural network\"), (\"speaker aware\", \"related_to_core\", \"neural network\"), (\"chunk_152\", \"mentions\", \"arXiv preprint\"), (\"chunk_152\", \"mentions\", \"arXiv:2104.02133\"), (\"chunk_152\", \"mentions\", \"Gigaspeech\"), (\"chunk_152\", \"mentions\", \"asr corpus\"), (\"chunk_152\", \"mentions\", \"transcribed audio\"), (\"chunk_152\", \"mentions\", \"arXiv:2106.06909\"), (\"chunk_152\", \"mentions\", \"Unispeech-sat\"), (\"chunk_152\", \"mentions\", \"speech representation learning\"), (\"chunk_152\", \"mentions\", \"speaker aware\")]\n",
            "✅ Extracted: [('neural network', 'is_core_idea', 'true'), ('chunk_152', 'is_core_chunk', 'true'), ('chunk_152', 'mentions', 'neural network'), ('arXiv preprint', 'related_to_core', 'neural network'), ('arXiv:2104.02133', 'related_to_core', 'neural network'), ('Gigaspeech', 'related_to_core', 'neural network'), ('asr corpus', 'related_to_core', 'neural network'), ('transcribed audio', 'related_to_core', 'neural network'), ('arXiv:2106.06909', 'related_to_core', 'neural network'), ('Unispeech-sat', 'related_to_core', 'neural network'), ('speech representation learning', 'related_to_core', 'neural network'), ('speaker aware', 'related_to_core', 'neural network'), ('chunk_152', 'mentions', 'arXiv preprint'), ('chunk_152', 'mentions', 'arXiv:2104.02133'), ('chunk_152', 'mentions', 'Gigaspeech'), ('chunk_152', 'mentions', 'asr corpus'), ('chunk_152', 'mentions', 'transcribed audio'), ('chunk_152', 'mentions', 'arXiv:2106.06909'), ('chunk_152', 'mentions', 'Unispeech-sat'), ('chunk_152', 'mentions', 'speech representation learning'), ('chunk_152', 'mentions', 'speaker aware')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_153...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"pre-training\", \"is_core_idea\", \"true\"), (\"chunk_153\", \"is_core_chunk\", \"true\"), (\"ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing\", \"related_to_core\", \"pre-training\"), (\"deep nets\", \"related_to_core\", \"pre-training\"), (\"sublinear memory cost\", \"related_to_core\", \"pre-training\"), (\"arXiv preprint arXiv:1604.06174\", \"related_to_core\", \"pre-training\"), (\"Matched speech text representations\", \"related_to_core\", \"pre-training\"), (\"modality matching\", \"related_to_core\", \"pre-training\"), (\"arXiv preprint arXiv:2204.03409\", \"related_to_core\", \"pre-training\"), (\"chunk_153\", \"mentions\", \"pre-training\"), (\"chunk_153\", \"mentions\", \"ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing\"), (\"chunk_153\", \"mentions\", \"deep nets\"), (\"chunk_153\", \"mentions\", \"sublinear memory cost\"), (\"chunk_153\", \"mentions\", \"arXiv preprint arXiv:1604.06174\"), (\"chunk_153\", \"mentions\", \"Matched speech text representations\"), (\"chunk_153\", \"mentions\", \"modality matching\"), (\"chunk_153\", \"mentions\", \"arXiv preprint arXiv:2204.03409\")]\n",
            "✅ Extracted: [('pre-training', 'is_core_idea', 'true'), ('chunk_153', 'is_core_chunk', 'true'), ('ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing', 'related_to_core', 'pre-training'), ('deep nets', 'related_to_core', 'pre-training'), ('sublinear memory cost', 'related_to_core', 'pre-training'), ('arXiv preprint arXiv:1604.06174', 'related_to_core', 'pre-training'), ('Matched speech text representations', 'related_to_core', 'pre-training'), ('modality matching', 'related_to_core', 'pre-training'), ('arXiv preprint arXiv:2204.03409', 'related_to_core', 'pre-training'), ('chunk_153', 'mentions', 'pre-training'), ('chunk_153', 'mentions', 'ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing'), ('chunk_153', 'mentions', 'deep nets'), ('chunk_153', 'mentions', 'sublinear memory cost'), ('chunk_153', 'mentions', 'arXiv preprint arXiv:1604.06174'), ('chunk_153', 'mentions', 'Matched speech text representations'), ('chunk_153', 'mentions', 'modality matching'), ('chunk_153', 'mentions', 'arXiv preprint arXiv:2204.03409')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_154...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"arXiv preprint arXiv:2204.03409\", \"is_publication\", \"true\"), (\"chunk_154\", \"is_core_chunk\", \"true\"), (\"arXiv preprint arXiv:2204.03409\", \"related_to_core\", \"arXiv preprint arXiv:2204.03409\"), (\"arXiv preprint arXiv:1904.10509\", \"is_publication\", \"true\"), (\"arXiv preprint arXiv:1904.10509\", \"related_to_core\", \"arXiv preprint arXiv:2204.03409\"), (\"Natural language processing\", \"related_to_core\", \"arXiv preprint arXiv:2204.03409\"), (\"Journal of machine learning research\", \"related_to_core\", \"arXiv preprint arXiv:2204.03409\"), (\"chunk_154\", \"mentions\", \"arXiv preprint arXiv:2204.03409\"), (\"chunk_154\", \"mentions\", \"arXiv preprint arXiv:1904.10509\"), (\"chunk_154\", \"mentions\", \"Natural language processing\"), (\"chunk_154\", \"mentions\", \"Journal of machine learning research\"), (\"Natural language processing\", \"is_field\", \"true\"), (\"Journal of machine learning research\", \"is_publication\", \"true\")]\n",
            "✅ Extracted: [('arXiv preprint arXiv:2204.03409', 'is_publication', 'true'), ('chunk_154', 'is_core_chunk', 'true'), ('arXiv preprint arXiv:2204.03409', 'related_to_core', 'arXiv preprint arXiv:2204.03409'), ('arXiv preprint arXiv:1904.10509', 'is_publication', 'true'), ('arXiv preprint arXiv:1904.10509', 'related_to_core', 'arXiv preprint arXiv:2204.03409'), ('Natural language processing', 'related_to_core', 'arXiv preprint arXiv:2204.03409'), ('Journal of machine learning research', 'related_to_core', 'arXiv preprint arXiv:2204.03409'), ('chunk_154', 'mentions', 'arXiv preprint arXiv:2204.03409'), ('chunk_154', 'mentions', 'arXiv preprint arXiv:1904.10509'), ('chunk_154', 'mentions', 'Natural language processing'), ('chunk_154', 'mentions', 'Journal of machine learning research'), ('Natural language processing', 'is_field', 'true'), ('Journal of machine learning research', 'is_publication', 'true')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_155...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"chunk_155\", \"mentions\", \"Dalmia, S.\"), (\"chunk_155\", \"mentions\", \"Riesa, J.\"), (\"chunk_155\", \"mentions\", \"Rivera, C.\"), (\"chunk_155\", \"mentions\", \"Bapna, A.\"), (\"chunk_155\", \"mentions\", \"Fleurs\"), (\"chunk_155\", \"mentions\", \"Few-shot learning\"), (\"chunk_155\", \"mentions\", \"universal representations of speech\"), (\"chunk_155\", \"mentions\", \"arXiv preprint arXiv:2205.12446\"), (\"chunk_155\", \"mentions\", \"2022\"), (\"chunk_155\", \"mentions\", \"Del Rio, M.\"), (\"chunk_155\", \"mentions\", \"Delworth, N.\"), (\"chunk_155\", \"mentions\", \"Westerman, R.\"), (\"chunk_155\", \"mentions\", \"Huang, M.\"), (\"chunk_155\", \"mentions\", \"Bhandari, N.\"), (\"chunk_155\", \"mentions\", \"Palakapilly, J.\"), (\"chunk_155\", \"mentions\", \"McNamara, Q.\"), (\"chunk_155\", \"mentions\", \"Dong, J.\"), (\"chunk_155\", \"mentions\", \"Zelasko, P.\"), (\"chunk_155\", \"mentions\", \"Jett´e, M.\"), (\"chunk_155\", \"mentions\", \"Earnings-21\"), (\"chunk_155\", \"mentions\", \"ASR\"), (\"chunk_155\", \"mentions\", \"arXiv preprint arXiv:2104.11348\"), (\"chunk_155\", \"mentions\", \"2021\"), (\"chunk_155\", \"mentions\", \"Galvez, D.\"), (\"chunk_155\", \"mentions\", \"Diamos, G.\"), (\"chunk_155\", \"mentions\", \"Torres, J. M. C.\"), (\"chunk_155\", \"mentions\", \"Achorn, K.\"), (\"chunk_155\", \"mentions\", \"Gopi\"), (\"Fleurs\", \"is_core_idea\", \"true\"), (\"chunk_155\", \"is_core_chunk\", \"true\"), (\"Few-shot learning\", \"related_to_core\", \"Fleurs\"), (\"universal representations of speech\", \"related_to_core\", \"Fleurs\"), (\"Earnings-21\", \"related_to_core\", \"Fleurs\"), (\"ASR\", \"related_to_core\", \"Fleurs\")]\n",
            "✅ Extracted: [('chunk_155', 'mentions', 'Dalmia, S.'), ('chunk_155', 'mentions', 'Riesa, J.'), ('chunk_155', 'mentions', 'Rivera, C.'), ('chunk_155', 'mentions', 'Bapna, A.'), ('chunk_155', 'mentions', 'Fleurs'), ('chunk_155', 'mentions', 'Few-shot learning'), ('chunk_155', 'mentions', 'universal representations of speech'), ('chunk_155', 'mentions', 'arXiv preprint arXiv:2205.12446'), ('chunk_155', 'mentions', '2022'), ('chunk_155', 'mentions', 'Del Rio, M.'), ('chunk_155', 'mentions', 'Delworth, N.'), ('chunk_155', 'mentions', 'Westerman, R.'), ('chunk_155', 'mentions', 'Huang, M.'), ('chunk_155', 'mentions', 'Bhandari, N.'), ('chunk_155', 'mentions', 'Palakapilly, J.'), ('chunk_155', 'mentions', 'McNamara, Q.'), ('chunk_155', 'mentions', 'Dong, J.'), ('chunk_155', 'mentions', 'Zelasko, P.'), ('chunk_155', 'mentions', 'Jett´e, M.'), ('chunk_155', 'mentions', 'Earnings-21'), ('chunk_155', 'mentions', 'ASR'), ('chunk_155', 'mentions', 'arXiv preprint arXiv:2104.11348'), ('chunk_155', 'mentions', '2021'), ('chunk_155', 'mentions', 'Galvez, D.'), ('chunk_155', 'mentions', 'Diamos, G.'), ('chunk_155', 'mentions', 'Torres, J. M. C.'), ('chunk_155', 'mentions', 'Achorn, K.'), ('chunk_155', 'mentions', 'Gopi'), ('Fleurs', 'is_core_idea', 'true'), ('chunk_155', 'is_core_chunk', 'true'), ('Few-shot learning', 'related_to_core', 'Fleurs'), ('universal representations of speech', 'related_to_core', 'Fleurs'), ('Earnings-21', 'related_to_core', 'Fleurs'), ('ASR', 'related_to_core', 'Fleurs')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_156...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"english speech recognition dataset\", \"is_core_idea\", \"true\"), (\"chunk_156\", \"is_core_chunk\", \"true\"), (\"chunk_156\", \"mentions\", \"english speech recognition dataset\"), (\"deep neural networks\", \"related_to_core\", \"english speech recognition dataset\"), (\"chunk_156\", \"mentions\", \"deep neural networks\")]\n",
            "✅ Extracted: [('english speech recognition dataset', 'is_core_idea', 'true'), ('chunk_156', 'is_core_chunk', 'true'), ('chunk_156', 'mentions', 'english speech recognition dataset'), ('deep neural networks', 'related_to_core', 'english speech recognition dataset'), ('chunk_156', 'mentions', 'deep neural networks')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_157...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"neural machine translation\", \"is_core_idea\", \"true\"), (\"chunk_157\", \"is_core_chunk\", \"true\"), (\"chunk_157\", \"mentions\", \"neural machine translation\"), (\"scaling laws\", \"related_to_core\", \"neural machine translation\"), (\"arXiv preprint\", \"related_to_core\", \"neural machine translation\"), (\"checkpointing\", \"related_to_core\", \"neural machine translation\"), (\"reverse mode\", \"related_to_core\", \"neural machine translation\"), (\"adjoint mode\", \"related_to_core\", \"neural machine translation\"), (\"computational differentiation\", \"related_to_core\", \"neural machine translation\"), (\"ACM Transactions on Mathematical Software\", \"related_to_core\", \"neural machine translation\"), (\"Sibilant variation\", \"related_to_core\", \"neural machine translation\"), (\"chunk_157\", \"mentions\", \"scaling laws\"), (\"chunk_157\", \"mentions\", \"arXiv preprint\"), (\"chunk_157\", \"mentions\", \"checkpointing\"), (\"chunk_157\", \"mentions\", \"reverse mode\"), (\"chunk_157\", \"mentions\", \"adjoint mode\"), (\"chunk_157\", \"mentions\", \"computational differentiation\"), (\"chunk_157\", \"mentions\", \"ACM Transactions on Mathematical Software\"), (\"chunk_157\", \"mentions\", \"Sibilant variation\")]\n",
            "✅ Extracted: [('neural machine translation', 'is_core_idea', 'true'), ('chunk_157', 'is_core_chunk', 'true'), ('chunk_157', 'mentions', 'neural machine translation'), ('scaling laws', 'related_to_core', 'neural machine translation'), ('arXiv preprint', 'related_to_core', 'neural machine translation'), ('checkpointing', 'related_to_core', 'neural machine translation'), ('reverse mode', 'related_to_core', 'neural machine translation'), ('adjoint mode', 'related_to_core', 'neural machine translation'), ('computational differentiation', 'related_to_core', 'neural machine translation'), ('ACM Transactions on Mathematical Software', 'related_to_core', 'neural machine translation'), ('Sibilant variation', 'related_to_core', 'neural machine translation'), ('chunk_157', 'mentions', 'scaling laws'), ('chunk_157', 'mentions', 'arXiv preprint'), ('chunk_157', 'mentions', 'checkpointing'), ('chunk_157', 'mentions', 'reverse mode'), ('chunk_157', 'mentions', 'adjoint mode'), ('chunk_157', 'mentions', 'computational differentiation'), ('chunk_157', 'mentions', 'ACM Transactions on Mathematical Software'), ('chunk_157', 'mentions', 'Sibilant variation')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_158...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"african american language\", \"is_core_idea\", \"true\"), (\"chunk_158\", \"is_core_chunk\", \"true\"), (\"Language Variation\", \"related_to_core\", \"african american language\"), (\"Change\", \"related_to_core\", \"african american language\"), (\"Array programming\", \"related_to_core\", \"african american language\"), (\"chunk_158\", \"mentions\", \"african american language\"), (\"chunk_158\", \"mentions\", \"Language Variation\"), (\"chunk_158\", \"mentions\", \"Change\"), (\"chunk_158\", \"mentions\", \"Array programming\")]\n",
            "✅ Extracted: [('african american language', 'is_core_idea', 'true'), ('chunk_158', 'is_core_chunk', 'true'), ('Language Variation', 'related_to_core', 'african american language'), ('Change', 'related_to_core', 'african american language'), ('Array programming', 'related_to_core', 'african american language'), ('chunk_158', 'mentions', 'african american language'), ('chunk_158', 'mentions', 'Language Variation'), ('chunk_158', 'mentions', 'Change'), ('chunk_158', 'mentions', 'Array programming')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_159...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Array programming\", \"related_to_core\", \"NumPy\"), (\"NumPy\", \"is_core_idea\", \"true\"), (\"chunk_159\", \"is_core_chunk\", \"true\"), (\"Gohlke, C.\", \"and\", \"Oliphant, T. E\"), (\"Array programming\", \"with\", \"NumPy\"), (\"Nature\", \"volume\", \"585\"), (\"Nature\", \"pages\", \"357–362\"), (\"Nature\", \"year\", \"2020\"), (\"doi\", \"is\", \"10.1038/s41586-020-2649-2\"), (\"chunk_159\", \"mentions\", \"Gohlke, C.\"), (\"chunk_159\", \"mentions\", \"Oliphant, T. E\"), (\"chunk_159\", \"mentions\", \"Array programming\"), (\"chunk_159\", \"mentions\", \"NumPy\"), (\"chunk_159\", \"mentions\", \"Nature\"), (\"chunk_159\", \"mentions\", \"doi\")]\n",
            "✅ Extracted: [('Array programming', 'related_to_core', 'NumPy'), ('NumPy', 'is_core_idea', 'true'), ('chunk_159', 'is_core_chunk', 'true'), ('Gohlke, C.', 'and', 'Oliphant, T. E'), ('Array programming', 'with', 'NumPy'), ('Nature', 'volume', '585'), ('Nature', 'pages', '357–362'), ('Nature', 'year', '2020'), ('doi', 'is', '10.1038/s41586-020-2649-2'), ('chunk_159', 'mentions', 'Gohlke, C.'), ('chunk_159', 'mentions', 'Oliphant, T. E'), ('chunk_159', 'mentions', 'Array programming'), ('chunk_159', 'mentions', 'NumPy'), ('chunk_159', 'mentions', 'Nature'), ('chunk_159', 'mentions', 'doi')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_160...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_160\", \"is_core_chunk\", \"true\"), (\"chunk_160\", \"mentions\", \"Speech Recognition\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"Speech Recognition\"), (\"Gaussian error linear units\", \"related_to_core\", \"Speech Recognition\"), (\"arXiv\", \"related_to_core\", \"Speech Recognition\"), (\"Pretrained transformers\", \"related_to_core\", \"Speech Recognition\"), (\"Ted-lium 3\", \"related_to_core\", \"Speech Recognition\"), (\"chunk_160\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_160\", \"mentions\", \"Gaussian error linear units\"), (\"chunk_160\", \"mentions\", \"arXiv\"), (\"chunk_160\", \"mentions\", \"Pretrained transformers\"), (\"chunk_160\", \"mentions\", \"Ted-lium 3\")]\n",
            "✅ Extracted: [('Speech Recognition', 'is_core_idea', 'true'), ('chunk_160', 'is_core_chunk', 'true'), ('chunk_160', 'mentions', 'Speech Recognition'), ('Large-Scale Weak Supervision', 'related_to_core', 'Speech Recognition'), ('Gaussian error linear units', 'related_to_core', 'Speech Recognition'), ('arXiv', 'related_to_core', 'Speech Recognition'), ('Pretrained transformers', 'related_to_core', 'Speech Recognition'), ('Ted-lium 3', 'related_to_core', 'Speech Recognition'), ('chunk_160', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_160', 'mentions', 'Gaussian error linear units'), ('chunk_160', 'mentions', 'arXiv'), ('chunk_160', 'mentions', 'Pretrained transformers'), ('chunk_160', 'mentions', 'Ted-lium 3')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_161...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"speaker adaptation\", \"is_core_idea\", \"true\"), (\"chunk_161\", \"is_core_chunk\", \"true\"), (\"SPECOM\", \"related_to_core\", \"speaker adaptation\"), (\"Hubert\", \"related_to_core\", \"speaker adaptation\"), (\"Self-supervised speech representation learning\", \"related_to_core\", \"speaker adaptation\"), (\"masked prediction\", \"related_to_core\", \"speaker adaptation\"), (\"hidden units\", \"related_to_core\", \"speaker adaptation\"), (\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\", \"related_to_core\", \"speaker adaptation\"), (\"repartition\", \"for\", \"experiments\"), (\"experiments\", \"on\", \"speaker adaptation\"), (\"chunk_161\", \"mentions\", \"repartition\"), (\"chunk_161\", \"mentions\", \"speaker adaptation\"), (\"chunk_161\", \"mentions\", \"SPECOM\"), (\"chunk_161\", \"mentions\", \"Hubert\"), (\"chunk_161\", \"mentions\", \"Self-supervised speech representation learning\"), (\"chunk_161\", \"mentions\", \"masked prediction\"), (\"chunk_161\", \"mentions\", \"hidden units\"), (\"chunk_161\", \"mentions\", \"IEEE/ACM Transactions on Audio, Speech, and Language Processing\")]\n",
            "✅ Extracted: [('speaker adaptation', 'is_core_idea', 'true'), ('chunk_161', 'is_core_chunk', 'true'), ('SPECOM', 'related_to_core', 'speaker adaptation'), ('Hubert', 'related_to_core', 'speaker adaptation'), ('Self-supervised speech representation learning', 'related_to_core', 'speaker adaptation'), ('masked prediction', 'related_to_core', 'speaker adaptation'), ('hidden units', 'related_to_core', 'speaker adaptation'), ('IEEE/ACM Transactions on Audio, Speech, and Language Processing', 'related_to_core', 'speaker adaptation'), ('repartition', 'for', 'experiments'), ('experiments', 'on', 'speaker adaptation'), ('chunk_161', 'mentions', 'repartition'), ('chunk_161', 'mentions', 'speaker adaptation'), ('chunk_161', 'mentions', 'SPECOM'), ('chunk_161', 'mentions', 'Hubert'), ('chunk_161', 'mentions', 'Self-supervised speech representation learning'), ('chunk_161', 'mentions', 'masked prediction'), ('chunk_161', 'mentions', 'hidden units'), ('chunk_161', 'mentions', 'IEEE/ACM Transactions on Audio, Speech, and Language Processing')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_162...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"wav2vec 2.0\", \"is_core_idea\", \"true\"), (\"chunk_162\", \"is_core_chunk\", \"true\"), (\"domain shift\", \"related_to_core\", \"wav2vec 2.0\"), (\"self-supervised pre-training\", \"related_to_core\", \"wav2vec 2.0\"), (\"deep networks\", \"related_to_core\", \"wav2vec 2.0\"), (\"stochastic depth\", \"related_to_core\", \"wav2vec 2.0\"), (\"European conference on computer vision\", \"related_to_core\", \"wav2vec 2.0\"), (\"adversarial examples\", \"related_to_core\", \"wav2vec 2.0\"), (\"reading comprehension systems\", \"related_to_core\", \"wav2vec 2.0\"), (\"chunk_162\", \"mentions\", \"wav2vec 2.0\"), (\"chunk_162\", \"mentions\", \"domain shift\"), (\"chunk_162\", \"mentions\", \"self-supervised pre-training\"), (\"chunk_162\", \"mentions\", \"deep networks\"), (\"chunk_162\", \"mentions\", \"stochastic depth\"), (\"chunk_162\", \"mentions\", \"European conference on computer vision\"), (\"chunk_162\", \"mentions\", \"adversarial examples\"), (\"chunk_162\", \"mentions\", \"reading comprehension systems\")]\n",
            "✅ Extracted: [('wav2vec 2.0', 'is_core_idea', 'true'), ('chunk_162', 'is_core_chunk', 'true'), ('domain shift', 'related_to_core', 'wav2vec 2.0'), ('self-supervised pre-training', 'related_to_core', 'wav2vec 2.0'), ('deep networks', 'related_to_core', 'wav2vec 2.0'), ('stochastic depth', 'related_to_core', 'wav2vec 2.0'), ('European conference on computer vision', 'related_to_core', 'wav2vec 2.0'), ('adversarial examples', 'related_to_core', 'wav2vec 2.0'), ('reading comprehension systems', 'related_to_core', 'wav2vec 2.0'), ('chunk_162', 'mentions', 'wav2vec 2.0'), ('chunk_162', 'mentions', 'domain shift'), ('chunk_162', 'mentions', 'self-supervised pre-training'), ('chunk_162', 'mentions', 'deep networks'), ('chunk_162', 'mentions', 'stochastic depth'), ('chunk_162', 'mentions', 'European conference on computer vision'), ('chunk_162', 'mentions', 'adversarial examples'), ('chunk_162', 'mentions', 'reading comprehension systems')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_163...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Google's multilingual neural machine translation system\", \"is_core_idea\", \"true\"), (\"chunk_163\", \"is_core_chunk\", \"true\"), (\"Google's multilingual neural machine translation system\", \"related_to_core\", \"Google's multilingual neural machine translation system\"), (\"zero-shot translation\", \"related_to_core\", \"Google's multilingual neural machine translation system\"), (\"Transactions of the Association for Computational Linguistics\", \"related_to_core\", \"Google's multilingual neural machine translation system\"), (\"the corpus of regional african american language\", \"related_to_core\", \"Google's multilingual neural machine translation system\"), (\"The Online Resources for African American Language Project\", \"related_to_core\", \"Google's multilingual neural machine translation system\"), (\"chunk_163\", \"mentions\", \"Google's multilingual neural machine translation system\"), (\"chunk_163\", \"mentions\", \"zero-shot translation\"), (\"chunk_163\", \"mentions\", \"Transactions of the Association for Computational Linguistics\"), (\"chunk_163\", \"mentions\", \"the corpus of regional african american language\"), (\"chunk_163\", \"mentions\", \"The Online Resources for African American Language Project\"), (\"Google's multilingual neural machine translation system\", \"enabling\", \"zero-shot translation\")]\n",
            "✅ Extracted: [(\"Google's multilingual neural machine translation system\", 'is_core_idea', 'true'), ('chunk_163', 'is_core_chunk', 'true'), (\"Google's multilingual neural machine translation system\", 'related_to_core', \"Google's multilingual neural machine translation system\"), ('zero-shot translation', 'related_to_core', \"Google's multilingual neural machine translation system\"), ('Transactions of the Association for Computational Linguistics', 'related_to_core', \"Google's multilingual neural machine translation system\"), ('the corpus of regional african american language', 'related_to_core', \"Google's multilingual neural machine translation system\"), ('The Online Resources for African American Language Project', 'related_to_core', \"Google's multilingual neural machine translation system\"), ('chunk_163', 'mentions', \"Google's multilingual neural machine translation system\"), ('chunk_163', 'mentions', 'zero-shot translation'), ('chunk_163', 'mentions', 'Transactions of the Association for Computational Linguistics'), ('chunk_163', 'mentions', 'the corpus of regional african american language'), ('chunk_163', 'mentions', 'The Online Resources for African American Language Project'), (\"Google's multilingual neural machine translation system\", 'enabling', 'zero-shot translation')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_164...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"automated speech recognition\", \"is_core_idea\", \"true\"), (\"chunk_164\", \"is_core_chunk\", \"true\"), (\"Racial disparities\", \"related_to_core\", \"automated speech recognition\"), (\"National Academy of Sciences\", \"related_to_core\", \"automated speech recognition\"), (\"visual representation learning\", \"related_to_core\", \"automated speech recognition\"), (\"European conference\", \"related_to_core\", \"automated speech recognition\"), (\"Racial disparities\", \"is_a\", \"entity\"), (\"automated speech recognition\", \"is_a\", \"entity\"), (\"National Academy of Sciences\", \"is_a\", \"entity\"), (\"visual representation learning\", \"is_a\", \"entity\"), (\"European conference\", \"is_a\", \"entity\"), (\"chunk_164\", \"mentions\", \"Racial disparities\"), (\"chunk_164\", \"mentions\", \"automated speech recognition\"), (\"chunk_164\", \"mentions\", \"National Academy of Sciences\"), (\"chunk_164\", \"mentions\", \"visual representation learning\"), (\"chunk_164\", \"mentions\", \"European conference\")]\n",
            "✅ Extracted: [('automated speech recognition', 'is_core_idea', 'true'), ('chunk_164', 'is_core_chunk', 'true'), ('Racial disparities', 'related_to_core', 'automated speech recognition'), ('National Academy of Sciences', 'related_to_core', 'automated speech recognition'), ('visual representation learning', 'related_to_core', 'automated speech recognition'), ('European conference', 'related_to_core', 'automated speech recognition'), ('Racial disparities', 'is_a', 'entity'), ('automated speech recognition', 'is_a', 'entity'), ('National Academy of Sciences', 'is_a', 'entity'), ('visual representation learning', 'is_a', 'entity'), ('European conference', 'is_a', 'entity'), ('chunk_164', 'mentions', 'Racial disparities'), ('chunk_164', 'mentions', 'automated speech recognition'), ('chunk_164', 'mentions', 'National Academy of Sciences'), ('chunk_164', 'mentions', 'visual representation learning'), ('chunk_164', 'mentions', 'European conference')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_165...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"computer vision\", \"is_a\", \"field\"), (\"chunk_165\", \"mentions\", \"computer vision\"), (\"Nemo\", \"is_a\", \"toolkit\"), (\"Nemo\", \"for\", \"building ai applications\"), (\"Nemo\", \"using\", \"neural modules\"), (\"chunk_165\", \"mentions\", \"Nemo\"), (\"ai applications\", \"is_a\", \"application\"), (\"chunk_165\", \"mentions\", \"ai applications\"), (\"neural modules\", \"is_a\", \"module\"), (\"chunk_165\", \"mentions\", \"neural modules\"), (\"machines\", \"can\", \"learn and think\"), (\"machines\", \"like\", \"people\"), (\"chunk_165\", \"mentions\", \"machines\"), (\"chunk_165\", \"is_core_chunk\", \"true\"), (\"machines\", \"is_core_idea\", \"true\"), (\"computer vision\", \"related_to_core\", \"machines\"), (\"ai applications\", \"related_to_core\", \"machines\"), (\"neural modules\", \"related_to_core\", \"machines\")]\n",
            "✅ Extracted: [('computer vision', 'is_a', 'field'), ('chunk_165', 'mentions', 'computer vision'), ('Nemo', 'is_a', 'toolkit'), ('Nemo', 'for', 'building ai applications'), ('Nemo', 'using', 'neural modules'), ('chunk_165', 'mentions', 'Nemo'), ('ai applications', 'is_a', 'application'), ('chunk_165', 'mentions', 'ai applications'), ('neural modules', 'is_a', 'module'), ('chunk_165', 'mentions', 'neural modules'), ('machines', 'can', 'learn and think'), ('machines', 'like', 'people'), ('chunk_165', 'mentions', 'machines'), ('chunk_165', 'is_core_chunk', 'true'), ('machines', 'is_core_idea', 'true'), ('computer vision', 'related_to_core', 'machines'), ('ai applications', 'related_to_core', 'machines'), ('neural modules', 'related_to_core', 'machines')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_166...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Behavioral and brain sciences\", \"is_journal\", \"true\"), (\"chunk_166\", \"mentions\", \"Behavioral and brain sciences\"), (\"Large scale deep neural network acoustic modeling\", \"is_method\", \"true\"), (\"chunk_166\", \"mentions\", \"Large scale deep neural network acoustic modeling\"), (\"semi-supervised training data\", \"is_data\", \"true\"), (\"chunk_166\", \"mentions\", \"semi-supervised training data\"), (\"youtube video transcription\", \"is_task\", \"true\"), (\"chunk_166\", \"mentions\", \"youtube video transcription\"), (\"Automatic Speech Recognition\", \"is_task\", \"true\"), (\"chunk_166\", \"mentions\", \"Automatic Speech Recognition\"), (\"ASR\", \"is_task\", \"true\"), (\"chunk_166\", \"mentions\", \"ASR\"), (\"robustness\", \"is_property\", \"true\"), (\"chunk_166\", \"mentions\", \"robustness\"), (\"ASR\", \"is_core_idea\", \"true\"), (\"chunk_166\", \"is_core_chunk\", \"true\"), (\"Behavioral and brain sciences\", \"related_to_core\", \"ASR\"), (\"Large scale deep neural network acoustic modeling\", \"related_to_core\", \"ASR\"), (\"semi-supervised training data\", \"related_to_core\", \"ASR\"), (\"youtube video transcription\", \"related_to_core\", \"ASR\"), (\"Automatic Speech Recognition\", \"related_to_core\", \"ASR\"), (\"robustness\", \"related_to_core\", \"ASR\")]\n",
            "✅ Extracted: [('Behavioral and brain sciences', 'is_journal', 'true'), ('chunk_166', 'mentions', 'Behavioral and brain sciences'), ('Large scale deep neural network acoustic modeling', 'is_method', 'true'), ('chunk_166', 'mentions', 'Large scale deep neural network acoustic modeling'), ('semi-supervised training data', 'is_data', 'true'), ('chunk_166', 'mentions', 'semi-supervised training data'), ('youtube video transcription', 'is_task', 'true'), ('chunk_166', 'mentions', 'youtube video transcription'), ('Automatic Speech Recognition', 'is_task', 'true'), ('chunk_166', 'mentions', 'Automatic Speech Recognition'), ('ASR', 'is_task', 'true'), ('chunk_166', 'mentions', 'ASR'), ('robustness', 'is_property', 'true'), ('chunk_166', 'mentions', 'robustness'), ('ASR', 'is_core_idea', 'true'), ('chunk_166', 'is_core_chunk', 'true'), ('Behavioral and brain sciences', 'related_to_core', 'ASR'), ('Large scale deep neural network acoustic modeling', 'related_to_core', 'ASR'), ('semi-supervised training data', 'related_to_core', 'ASR'), ('youtube video transcription', 'related_to_core', 'ASR'), ('Automatic Speech Recognition', 'related_to_core', 'ASR'), ('robustness', 'related_to_core', 'ASR')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_167...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"arXiv preprint arXiv:2010.11745\", \"is_type_of\", \"preprint\"), (\"chunk_167\", \"mentions\", \"arXiv preprint arXiv:2010.11745\"), (\"Decoupled weight decay regularization\", \"is_type_of\", \"regularization\"), (\"chunk_167\", \"mentions\", \"Decoupled weight decay regularization\"), (\"arXiv preprint arXiv:1711.05101\", \"is_type_of\", \"preprint\"), (\"chunk_167\", \"mentions\", \"arXiv preprint arXiv:1711.05101\"), (\"Multi-task sequence to sequence learning\", \"is_type_of\", \"learning\"), (\"chunk_167\", \"mentions\", \"Multi-task sequence to sequence learning\"), (\"arXiv preprint arXiv:1511.06114\", \"is_type_of\", \"preprint\"), (\"chunk_167\", \"mentions\", \"arXiv preprint arXiv:1511.06114\"), (\"weakly supervised pretraining\", \"is_type_of\", \"pretraining\"), (\"chunk_167\", \"mentions\", \"weakly supervised pretraining\"), (\"weakly supervised pretraining\", \"is_core_idea\", \"true\"), (\"chunk_167\", \"is_core_chunk\", \"true\"), (\"arXiv preprint arXiv:2010.11745\", \"related_to_core\", \"weakly supervised pretraining\"), (\"Decoupled weight decay regularization\", \"related_to_core\", \"weakly supervised pretraining\"), (\"arXiv preprint arXiv:1711.05101\", \"related_to_core\", \"weakly supervised pretraining\"), (\"Multi-task sequence to sequence learning\", \"related_to_core\", \"weakly supervised pretraining\"), (\"arXiv preprint arXiv:1511.06114\", \"related_to_core\", \"weakly supervised pretraining\")]\n",
            "✅ Extracted: [('arXiv preprint arXiv:2010.11745', 'is_type_of', 'preprint'), ('chunk_167', 'mentions', 'arXiv preprint arXiv:2010.11745'), ('Decoupled weight decay regularization', 'is_type_of', 'regularization'), ('chunk_167', 'mentions', 'Decoupled weight decay regularization'), ('arXiv preprint arXiv:1711.05101', 'is_type_of', 'preprint'), ('chunk_167', 'mentions', 'arXiv preprint arXiv:1711.05101'), ('Multi-task sequence to sequence learning', 'is_type_of', 'learning'), ('chunk_167', 'mentions', 'Multi-task sequence to sequence learning'), ('arXiv preprint arXiv:1511.06114', 'is_type_of', 'preprint'), ('chunk_167', 'mentions', 'arXiv preprint arXiv:1511.06114'), ('weakly supervised pretraining', 'is_type_of', 'pretraining'), ('chunk_167', 'mentions', 'weakly supervised pretraining'), ('weakly supervised pretraining', 'is_core_idea', 'true'), ('chunk_167', 'is_core_chunk', 'true'), ('arXiv preprint arXiv:2010.11745', 'related_to_core', 'weakly supervised pretraining'), ('Decoupled weight decay regularization', 'related_to_core', 'weakly supervised pretraining'), ('arXiv preprint arXiv:1711.05101', 'related_to_core', 'weakly supervised pretraining'), ('Multi-task sequence to sequence learning', 'related_to_core', 'weakly supervised pretraining'), ('arXiv preprint arXiv:1511.06114', 'related_to_core', 'weakly supervised pretraining')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_168...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"European conference on computer vision\", \"is_a\", \"conference\"), (\"ECCV\", \"is_an_acronym_for\", \"European conference on computer vision\"), (\"audio degradation toolbox\", \"is_a\", \"software\"), (\"robustness evaluation\", \"is_a\", \"method\"), (\"International Society for Music Information Retrieval Conference\", \"is_a\", \"conference\"), (\"ISMIR 2013\", \"is_an_acronym_for\", \"International Society for Music Information Retrieval Conference\"), (\"natural language decathlon\", \"is_a\", \"dataset\"), (\"multitask learning\", \"is_a\", \"technique\"), (\"question answering\", \"is_a\", \"task\"), (\"arXiv preprint\", \"is_a\", \"publication\"), (\"chunk_168\", \"mentions\", \"European conference on computer vision\"), (\"chunk_168\", \"mentions\", \"ECCV\"), (\"chunk_168\", \"mentions\", \"audio degradation toolbox\"), (\"chunk_168\", \"mentions\", \"robustness evaluation\"), (\"chunk_168\", \"mentions\", \"International Society for Music Information Retrieval Conference\"), (\"chunk_168\", \"mentions\", \"ISMIR 2013\"), (\"chunk_168\", \"mentions\", \"natural language decathlon\"), (\"chunk_168\", \"mentions\", \"multitask learning\"), (\"chunk_168\", \"mentions\", \"question answering\"), (\"chunk_168\", \"mentions\", \"arXiv preprint\")]\n",
            "✅ Extracted: [('European conference on computer vision', 'is_a', 'conference'), ('ECCV', 'is_an_acronym_for', 'European conference on computer vision'), ('audio degradation toolbox', 'is_a', 'software'), ('robustness evaluation', 'is_a', 'method'), ('International Society for Music Information Retrieval Conference', 'is_a', 'conference'), ('ISMIR 2013', 'is_an_acronym_for', 'International Society for Music Information Retrieval Conference'), ('natural language decathlon', 'is_a', 'dataset'), ('multitask learning', 'is_a', 'technique'), ('question answering', 'is_a', 'task'), ('arXiv preprint', 'is_a', 'publication'), ('chunk_168', 'mentions', 'European conference on computer vision'), ('chunk_168', 'mentions', 'ECCV'), ('chunk_168', 'mentions', 'audio degradation toolbox'), ('chunk_168', 'mentions', 'robustness evaluation'), ('chunk_168', 'mentions', 'International Society for Music Information Retrieval Conference'), ('chunk_168', 'mentions', 'ISMIR 2013'), ('chunk_168', 'mentions', 'natural language decathlon'), ('chunk_168', 'mentions', 'multitask learning'), ('chunk_168', 'mentions', 'question answering'), ('chunk_168', 'mentions', 'arXiv preprint')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_169...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Artie bias corpus\", \"is_core_idea\", \"true\"), (\"chunk_169\", \"is_core_chunk\", \"true\"), (\"chunk_169\", \"mentions\", \"Artie bias corpus\"), (\"speech applications\", \"related_to_core\", \"Artie bias corpus\"), (\"speech applications\", \"mentions\", \"speech applications\"), (\"dataset\", \"related_to_core\", \"Artie bias corpus\"), (\"dataset\", \"mentions\", \"dataset\"), (\"demographic bias\", \"related_to_core\", \"Artie bias corpus\"), (\"demographic bias\", \"mentions\", \"demographic bias\"), (\"detecting\", \"related_to_core\", \"Artie bias corpus\"), (\"detecting\", \"mentions\", \"detecting\"), (\"Proceedings of the 12th Language Resources and Evaluation Conference\", \"mentions\", \"Proceedings of the 12th Language Resources and Evaluation Conference\"), (\"European Language Resources Association\", \"mentions\", \"European Language Resources Association\")]\n",
            "✅ Extracted: [('Artie bias corpus', 'is_core_idea', 'true'), ('chunk_169', 'is_core_chunk', 'true'), ('chunk_169', 'mentions', 'Artie bias corpus'), ('speech applications', 'related_to_core', 'Artie bias corpus'), ('speech applications', 'mentions', 'speech applications'), ('dataset', 'related_to_core', 'Artie bias corpus'), ('dataset', 'mentions', 'dataset'), ('demographic bias', 'related_to_core', 'Artie bias corpus'), ('demographic bias', 'mentions', 'demographic bias'), ('detecting', 'related_to_core', 'Artie bias corpus'), ('detecting', 'mentions', 'detecting'), ('Proceedings of the 12th Language Resources and Evaluation Conference', 'mentions', 'Proceedings of the 12th Language Resources and Evaluation Conference'), ('European Language Resources Association', 'mentions', 'European Language Resources Association')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_170...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"natural distribution shift\", \"is_core_idea\", \"true\"), (\"chunk_170\", \"is_core_chunk\", \"true\"), (\"question answering models\", \"related_to_core\", \"natural distribution shift\"), (\"question answering models\", \"type\", \"model\"), (\"natural distribution shift\", \"on\", \"question answering models\"), (\"ICML\", \"year\", \"2020\"), (\"chunk_170\", \"mentions\", \"natural distribution shift\"), (\"chunk_170\", \"mentions\", \"question answering models\"), (\"chunk_170\", \"mentions\", \"ICML\")]\n",
            "✅ Extracted: [('natural distribution shift', 'is_core_idea', 'true'), ('chunk_170', 'is_core_chunk', 'true'), ('question answering models', 'related_to_core', 'natural distribution shift'), ('question answering models', 'type', 'model'), ('natural distribution shift', 'on', 'question answering models'), ('ICML', 'year', '2020'), ('chunk_170', 'mentions', 'natural distribution shift'), ('chunk_170', 'mentions', 'question answering models'), ('chunk_170', 'mentions', 'ICML')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_171...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_171\", \"is_core_chunk\", \"true\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Deep belief networks\", \"related_to_core\", \"Robust Speech Recognition\"), (\"phone recognition\", \"related_to_core\", \"Robust Speech Recognition\"), (\"speech recognition\", \"related_to_core\", \"Robust Speech Recognition\"), (\"domain-invariant speech recognition\", \"related_to_core\", \"Robust Speech Recognition\"), (\"large scale training\", \"related_to_core\", \"Robust Speech Recognition\"), (\"IEEE Spoken Language\", \"related_to_core\", \"Robust Speech Recognition\"), (\"chunk_171\", \"mentions\", \"Robust Speech Recognition\"), (\"chunk_171\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_171\", \"mentions\", \"Deep belief networks\"), (\"chunk_171\", \"mentions\", \"phone recognition\"), (\"chunk_171\", \"mentions\", \"speech recognition\"), (\"chunk_171\", \"mentions\", \"domain-invariant speech recognition\"), (\"chunk_171\", \"mentions\", \"large scale training\"), (\"chunk_171\", \"mentions\", \"IEEE Spoken Language\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'is_core_idea', 'true'), ('chunk_171', 'is_core_chunk', 'true'), ('Large-Scale Weak Supervision', 'related_to_core', 'Robust Speech Recognition'), ('Deep belief networks', 'related_to_core', 'Robust Speech Recognition'), ('phone recognition', 'related_to_core', 'Robust Speech Recognition'), ('speech recognition', 'related_to_core', 'Robust Speech Recognition'), ('domain-invariant speech recognition', 'related_to_core', 'Robust Speech Recognition'), ('large scale training', 'related_to_core', 'Robust Speech Recognition'), ('IEEE Spoken Language', 'related_to_core', 'Robust Speech Recognition'), ('chunk_171', 'mentions', 'Robust Speech Recognition'), ('chunk_171', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_171', 'mentions', 'Deep belief networks'), ('chunk_171', 'mentions', 'phone recognition'), ('chunk_171', 'mentions', 'speech recognition'), ('chunk_171', 'mentions', 'domain-invariant speech recognition'), ('chunk_171', 'mentions', 'large scale training'), ('chunk_171', 'mentions', 'IEEE Spoken Language')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_172...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Technology Workshop (SLT)\", \"is_core_idea\", \"true\"), (\"chunk_172\", \"is_core_chunk\", \"true\"), (\"chunk_172\", \"mentions\", \"Technology Workshop (SLT)\"), (\"IEEE\", \"related_to_core\", \"Technology Workshop (SLT)\"), (\"Librispeech\", \"related_to_core\", \"Technology Workshop (SLT)\"), (\"IEEE international conference on acoustics, speech and signal processing (ICASSP)\", \"related_to_core\", \"Technology Workshop (SLT)\"), (\"pandas\", \"related_to_core\", \"Technology Workshop (SLT)\"), (\"chunk_172\", \"mentions\", \"IEEE\"), (\"chunk_172\", \"mentions\", \"Librispeech\"), (\"chunk_172\", \"mentions\", \"IEEE international conference on acoustics, speech and signal processing (ICASSP)\"), (\"chunk_172\", \"mentions\", \"pandas\")]\n",
            "✅ Extracted: [('Technology Workshop (SLT)', 'is_core_idea', 'true'), ('chunk_172', 'is_core_chunk', 'true'), ('chunk_172', 'mentions', 'Technology Workshop (SLT)'), ('IEEE', 'related_to_core', 'Technology Workshop (SLT)'), ('Librispeech', 'related_to_core', 'Technology Workshop (SLT)'), ('IEEE international conference on acoustics, speech and signal processing (ICASSP)', 'related_to_core', 'Technology Workshop (SLT)'), ('pandas', 'related_to_core', 'Technology Workshop (SLT)'), ('chunk_172', 'mentions', 'IEEE'), ('chunk_172', 'mentions', 'Librispeech'), ('chunk_172', 'mentions', 'IEEE international conference on acoustics, speech and signal processing (ICASSP)'), ('chunk_172', 'mentions', 'pandas')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_173...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"SpecAugment\", \"is_core_idea\", \"true\"), (\"chunk_173\", \"is_core_chunk\", \"true\"), (\"chunk_173\", \"mentions\", \"Cubuk\"), (\"chunk_173\", \"mentions\", \"Le\"), (\"chunk_173\", \"mentions\", \"SpecAugment\"), (\"chunk_173\", \"mentions\", \"data augmentation method\"), (\"chunk_173\", \"mentions\", \"automatic speech recognition\"), (\"chunk_173\", \"mentions\", \"arXiv\"), (\"chunk_173\", \"mentions\", \"Pascanu\"), (\"chunk_173\", \"mentions\", \"Mikolov\"), (\"chunk_173\", \"mentions\", \"Bengio\"), (\"chunk_173\", \"mentions\", \"recurrent neural networks\"), (\"chunk_173\", \"mentions\", \"International conference on machine learning\"), (\"chunk_173\", \"mentions\", \"PMLR\"), (\"chunk_173\", \"mentions\", \"Paszke\"), (\"chunk_173\", \"mentions\", \"Gross\"), (\"chunk_173\", \"mentions\", \"Massa\"), (\"chunk_173\", \"mentions\", \"Lerer\"), (\"chunk_173\", \"mentions\", \"Bradbury\"), (\"chunk_173\", \"mentions\", \"Chanan\"), (\"chunk_173\", \"mentions\", \"Killeen\"), (\"chunk_173\", \"mentions\", \"Lin\"), (\"chunk_173\", \"mentions\", \"Gimelshein\"), (\"chunk_173\", \"mentions\", \"Antiga\"), (\"chunk_173\", \"mentions\", \"Desmaison\"), (\"chunk_173\", \"mentions\", \"Kopf\"), (\"chunk_173\", \"mentions\", \"Yang\"), (\"chunk_173\", \"mentions\", \"DeVito\"), (\"Cubuk\", \"related_to_core\", \"SpecAugment\"), (\"Le\", \"related_to_core\", \"SpecAugment\"), (\"data augmentation method\", \"related_to_core\", \"SpecAugment\"), (\"automatic speech recognition\", \"related_to_core\", \"SpecAugment\"), (\"arXiv\", \"related_to_core\", \"SpecAugment\"), (\"Pascanu\", \"related_to_core\", \"SpecAugment\"), (\"Mikolov\", \"related_to_core\", \"SpecAugment\"), (\"Bengio\", \"related_to_core\", \"SpecAugment\"), (\"recurrent neural networks\", \"related_to_core\", \"SpecAugment\"), (\"International conference on machine learning\", \"related_to_core\", \"SpecAugment\"), (\"PMLR\", \"related_to_core\", \"SpecAugment\"), (\"Paszke\", \"related_to_core\", \"SpecAugment\"), (\"Gross\", \"related_to_core\", \"SpecAugment\"), (\"Massa\", \"related_to_core\", \"SpecAugment\"), (\"Lerer\", \"related_to_core\", \"SpecAugment\"), (\"Bradbury\", \"related_to_core\", \"SpecAugment\"), (\"Chanan\", \"related_to_core\", \"SpecAugment\"), (\"Killeen\", \"related_to_core\", \"SpecAugment\"), (\"Lin\", \"related_to_core\", \"SpecAugment\"), (\"Gimelshein\", \"related_to_core\", \"SpecAugment\"), (\"Antiga\", \"related_to_core\", \"SpecAugment\"), (\"Desmaison\", \"related_to_core\", \"SpecAugment\"), (\"Kopf\", \"related_to_core\", \"SpecAugment\"), (\"Yang\", \"related_to_core\", \"SpecAugment\"), (\"DeVito\", \"related_to_core\", \"SpecAugment\")]\n",
            "✅ Extracted: [('SpecAugment', 'is_core_idea', 'true'), ('chunk_173', 'is_core_chunk', 'true'), ('chunk_173', 'mentions', 'Cubuk'), ('chunk_173', 'mentions', 'Le'), ('chunk_173', 'mentions', 'SpecAugment'), ('chunk_173', 'mentions', 'data augmentation method'), ('chunk_173', 'mentions', 'automatic speech recognition'), ('chunk_173', 'mentions', 'arXiv'), ('chunk_173', 'mentions', 'Pascanu'), ('chunk_173', 'mentions', 'Mikolov'), ('chunk_173', 'mentions', 'Bengio'), ('chunk_173', 'mentions', 'recurrent neural networks'), ('chunk_173', 'mentions', 'International conference on machine learning'), ('chunk_173', 'mentions', 'PMLR'), ('chunk_173', 'mentions', 'Paszke'), ('chunk_173', 'mentions', 'Gross'), ('chunk_173', 'mentions', 'Massa'), ('chunk_173', 'mentions', 'Lerer'), ('chunk_173', 'mentions', 'Bradbury'), ('chunk_173', 'mentions', 'Chanan'), ('chunk_173', 'mentions', 'Killeen'), ('chunk_173', 'mentions', 'Lin'), ('chunk_173', 'mentions', 'Gimelshein'), ('chunk_173', 'mentions', 'Antiga'), ('chunk_173', 'mentions', 'Desmaison'), ('chunk_173', 'mentions', 'Kopf'), ('chunk_173', 'mentions', 'Yang'), ('chunk_173', 'mentions', 'DeVito'), ('Cubuk', 'related_to_core', 'SpecAugment'), ('Le', 'related_to_core', 'SpecAugment'), ('data augmentation method', 'related_to_core', 'SpecAugment'), ('automatic speech recognition', 'related_to_core', 'SpecAugment'), ('arXiv', 'related_to_core', 'SpecAugment'), ('Pascanu', 'related_to_core', 'SpecAugment'), ('Mikolov', 'related_to_core', 'SpecAugment'), ('Bengio', 'related_to_core', 'SpecAugment'), ('recurrent neural networks', 'related_to_core', 'SpecAugment'), ('International conference on machine learning', 'related_to_core', 'SpecAugment'), ('PMLR', 'related_to_core', 'SpecAugment'), ('Paszke', 'related_to_core', 'SpecAugment'), ('Gross', 'related_to_core', 'SpecAugment'), ('Massa', 'related_to_core', 'SpecAugment'), ('Lerer', 'related_to_core', 'SpecAugment'), ('Bradbury', 'related_to_core', 'SpecAugment'), ('Chanan', 'related_to_core', 'SpecAugment'), ('Killeen', 'related_to_core', 'SpecAugment'), ('Lin', 'related_to_core', 'SpecAugment'), ('Gimelshein', 'related_to_core', 'SpecAugment'), ('Antiga', 'related_to_core', 'SpecAugment'), ('Desmaison', 'related_to_core', 'SpecAugment'), ('Kopf', 'related_to_core', 'SpecAugment'), ('Yang', 'related_to_core', 'SpecAugment'), ('DeVito', 'related_to_core', 'SpecAugment')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_174...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Pytorch\", \"is_a\", \"deep learning library\"), (\"Pytorch\", \"has_style\", \"imperative style\"), (\"Pytorch\", \"has_performance\", \"high-performance\"), (\"chunk_174\", \"mentions\", \"Pytorch\"), (\"deep learning library\", \"related_to_core\", \"Pytorch\"), (\"deep learning library\", \"is_core_idea\", \"true\"), (\"chunk_174\", \"is_core_chunk\", \"true\"), (\"chunk_174\", \"mentions\", \"deep learning library\")]\n",
            "✅ Extracted: [('Pytorch', 'is_a', 'deep learning library'), ('Pytorch', 'has_style', 'imperative style'), ('Pytorch', 'has_performance', 'high-performance'), ('chunk_174', 'mentions', 'Pytorch'), ('deep learning library', 'related_to_core', 'Pytorch'), ('deep learning library', 'is_core_idea', 'true'), ('chunk_174', 'is_core_chunk', 'true'), ('chunk_174', 'mentions', 'deep learning library')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_175...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Scikit-learn\", \"is_core_idea\", \"true\"), (\"chunk_175\", \"is_core_chunk\", \"true\"), (\"Scikit-learn\", \"mentions\", \"Scikit-learn\"), (\"Machine learning\", \"mentions\", \"Machine learning\"), (\"Python\", \"mentions\", \"Python\"), (\"Journal of Machine Learning Research\", \"mentions\", \"Journal of Machine Learning Research\"), (\"Polyak, B. T.\", \"mentions\", \"Polyak, B. T.\"), (\"Juditsky, A. B.\", \"mentions\", \"Juditsky, A. B.\"), (\"Acceleration of stochastic approximation by averaging\", \"mentions\", \"Acceleration of stochastic approximation by averaging\"), (\"SIAM journal on control and optimization\", \"mentions\", \"SIAM journal on control and optimization\"), (\"Pratap, V .\", \"mentions\", \"Pratap, V .\"), (\"Sriram, A.\", \"mentions\", \"Sriram, A.\"), (\"Tomasello, P.\", \"mentions\", \"Tomasello, P.\"), (\"Hannun, A. Y .\", \"mentions\", \"Hannun, A. Y .\"), (\"Liptchinsky, V .\", \"mentions\", \"Liptchinsky, V .\"), (\"Synnaeve, G.\", \"mentions\", \"Synnaeve, G.\"), (\"Collobert, R.\", \"mentions\", \"Collobert, R.\"), (\"Massively multilingual asr\", \"mentions\", \"Massively multilingual asr\"), (\"ArXiv\", \"mentions\", \"ArXiv\"), (\"Machine learning\", \"related_to_core\", \"Scikit-learn\"), (\"Python\", \"related_to_core\", \"Scikit-learn\"), (\"Journal of Machine Learning Research\", \"related_to_core\", \"Scikit-learn\"), (\"Polyak, B. T.\", \"related_to_core\", \"Scikit-learn\"), (\"Juditsky, A. B.\", \"related_to_core\", \"Scikit-learn\"), (\"Acceleration of stochastic approximation by averaging\", \"related_to_core\", \"Scikit-learn\"), (\"SIAM journal on control and optimization\", \"related_to_core\", \"Scikit-learn\"), (\"Pratap, V .\", \"related_to_core\", \"Scikit-learn\"), (\"Sriram, A.\", \"related_to_core\", \"Scikit-learn\"), (\"Tomasello, P.\", \"related_to_core\", \"Scikit-learn\"), (\"Hannun, A. Y .\", \"related_to_core\", \"Scikit-learn\"), (\"Liptchinsky, V .\", \"related_to_core\", \"Scikit-learn\"), (\"Synnaeve, G.\", \"related_to_core\", \"Scikit-learn\"), (\"Collobert, R.\", \"related_to_core\", \"Scikit-learn\"), (\"Massively multilingual asr\", \"related_to_core\", \"Scikit-learn\"), (\"ArXiv\", \"related_to_core\", \"Scikit-learn\")]\n",
            "✅ Extracted: [('Scikit-learn', 'is_core_idea', 'true'), ('chunk_175', 'is_core_chunk', 'true'), ('Scikit-learn', 'mentions', 'Scikit-learn'), ('Machine learning', 'mentions', 'Machine learning'), ('Python', 'mentions', 'Python'), ('Journal of Machine Learning Research', 'mentions', 'Journal of Machine Learning Research'), ('Polyak, B. T.', 'mentions', 'Polyak, B. T.'), ('Juditsky, A. B.', 'mentions', 'Juditsky, A. B.'), ('Acceleration of stochastic approximation by averaging', 'mentions', 'Acceleration of stochastic approximation by averaging'), ('SIAM journal on control and optimization', 'mentions', 'SIAM journal on control and optimization'), ('Pratap, V .', 'mentions', 'Pratap, V .'), ('Sriram, A.', 'mentions', 'Sriram, A.'), ('Tomasello, P.', 'mentions', 'Tomasello, P.'), ('Hannun, A. Y .', 'mentions', 'Hannun, A. Y .'), ('Liptchinsky, V .', 'mentions', 'Liptchinsky, V .'), ('Synnaeve, G.', 'mentions', 'Synnaeve, G.'), ('Collobert, R.', 'mentions', 'Collobert, R.'), ('Massively multilingual asr', 'mentions', 'Massively multilingual asr'), ('ArXiv', 'mentions', 'ArXiv'), ('Machine learning', 'related_to_core', 'Scikit-learn'), ('Python', 'related_to_core', 'Scikit-learn'), ('Journal of Machine Learning Research', 'related_to_core', 'Scikit-learn'), ('Polyak, B. T.', 'related_to_core', 'Scikit-learn'), ('Juditsky, A. B.', 'related_to_core', 'Scikit-learn'), ('Acceleration of stochastic approximation by averaging', 'related_to_core', 'Scikit-learn'), ('SIAM journal on control and optimization', 'related_to_core', 'Scikit-learn'), ('Pratap, V .', 'related_to_core', 'Scikit-learn'), ('Sriram, A.', 'related_to_core', 'Scikit-learn'), ('Tomasello, P.', 'related_to_core', 'Scikit-learn'), ('Hannun, A. Y .', 'related_to_core', 'Scikit-learn'), ('Liptchinsky, V .', 'related_to_core', 'Scikit-learn'), ('Synnaeve, G.', 'related_to_core', 'Scikit-learn'), ('Collobert, R.', 'related_to_core', 'Scikit-learn'), ('Massively multilingual asr', 'related_to_core', 'Scikit-learn'), ('ArXiv', 'related_to_core', 'Scikit-learn')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_176...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"parameters\", \"is_core_idea\", \"true\"), (\"chunk_176\", \"is_core_chunk\", \"true\"), (\"ArXiv\", \"related_to_core\", \"parameters\"), (\"speech research\", \"related_to_core\", \"parameters\"), (\"multilingual dataset\", \"related_to_core\", \"parameters\"), (\"language models\", \"related_to_core\", \"parameters\"), (\"output embedding\", \"related_to_core\", \"parameters\"), (\"chunk_176\", \"mentions\", \"parameters\"), (\"chunk_176\", \"mentions\", \"ArXiv\"), (\"chunk_176\", \"mentions\", \"speech research\"), (\"chunk_176\", \"mentions\", \"multilingual dataset\"), (\"chunk_176\", \"mentions\", \"language models\"), (\"chunk_176\", \"mentions\", \"output embedding\")]\n",
            "✅ Extracted: [('parameters', 'is_core_idea', 'true'), ('chunk_176', 'is_core_chunk', 'true'), ('ArXiv', 'related_to_core', 'parameters'), ('speech research', 'related_to_core', 'parameters'), ('multilingual dataset', 'related_to_core', 'parameters'), ('language models', 'related_to_core', 'parameters'), ('output embedding', 'related_to_core', 'parameters'), ('chunk_176', 'mentions', 'parameters'), ('chunk_176', 'mentions', 'ArXiv'), ('chunk_176', 'mentions', 'speech research'), ('chunk_176', 'mentions', 'multilingual dataset'), ('chunk_176', 'mentions', 'language models'), ('chunk_176', 'mentions', 'output embedding')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_177...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Association for Computational Linguistics\", \"is_a\", \"organization\"), (\"chunk_177\", \"mentions\", \"Association for Computational Linguistics\"), (\"Bpe-dropout\", \"is_a\", \"subword regularization\"), (\"chunk_177\", \"mentions\", \"Bpe-dropout\"), (\"arXiv\", \"is_a\", \"preprint server\"), (\"chunk_177\", \"mentions\", \"arXiv\"), (\"Language models\", \"is_a\", \"unsupervised multitask learners\"), (\"chunk_177\", \"mentions\", \"Language models\")]\n",
            "✅ Extracted: [('Association for Computational Linguistics', 'is_a', 'organization'), ('chunk_177', 'mentions', 'Association for Computational Linguistics'), ('Bpe-dropout', 'is_a', 'subword regularization'), ('chunk_177', 'mentions', 'Bpe-dropout'), ('arXiv', 'is_a', 'preprint server'), ('chunk_177', 'mentions', 'arXiv'), ('Language models', 'is_a', 'unsupervised multitask learners'), ('chunk_177', 'mentions', 'Language models')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_178...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"transferable visual models\", \"is_core_idea\", \"true\"), (\"chunk_178\", \"is_core_chunk\", \"true\"), (\"J., Krueger, G., and Sutskever, I\", \"related_to_core\", \"transferable visual models\"), (\"natural language supervision\", \"related_to_core\", \"transferable visual models\"), (\"arXiv preprint\", \"related_to_core\", \"transferable visual models\"), (\"Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y ., Li, W., Liu, P. J., et al\", \"related_to_core\", \"transferable visual models\"), (\"transfer learning\", \"related_to_core\", \"transferable visual models\"), (\"uniﬁed text-to-text transformer\", \"related_to_core\", \"transferable visual models\"), (\"J. Mach. Learn. Res.\", \"related_to_core\", \"transferable visual models\"), (\"Ravanelli, M., Parcollet, T., Plantinga, P., Rouhe, A., Cor- nell, S., Lugosch, L., Subakan, C., Dawalatabad, N\", \"related_to_core\", \"transferable visual models\"), (\"chunk_178\", \"mentions\", \"J., Krueger, G., and Sutskever, I\"), (\"chunk_178\", \"mentions\", \"transferable visual models\"), (\"chunk_178\", \"mentions\", \"natural language supervision\"), (\"chunk_178\", \"mentions\", \"arXiv preprint\"), (\"chunk_178\", \"mentions\", \"Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y ., Li, W., Liu, P. J., et al\"), (\"chunk_178\", \"mentions\", \"transfer learning\"), (\"chunk_178\", \"mentions\", \"uniﬁed text-to-text transformer\"), (\"chunk_178\", \"mentions\", \"J. Mach. Learn. Res.\"), (\"chunk_178\", \"mentions\", \"Ravanelli, M., Parcollet, T., Plantinga, P., Rouhe, A., Cor- nell, S., Lugosch, L., Subakan, C., Dawalatabad, N\")]\n",
            "✅ Extracted: [('transferable visual models', 'is_core_idea', 'true'), ('chunk_178', 'is_core_chunk', 'true'), ('J., Krueger, G., and Sutskever, I', 'related_to_core', 'transferable visual models'), ('natural language supervision', 'related_to_core', 'transferable visual models'), ('arXiv preprint', 'related_to_core', 'transferable visual models'), ('Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y ., Li, W., Liu, P. J., et al', 'related_to_core', 'transferable visual models'), ('transfer learning', 'related_to_core', 'transferable visual models'), ('uniﬁed text-to-text transformer', 'related_to_core', 'transferable visual models'), ('J. Mach. Learn. Res.', 'related_to_core', 'transferable visual models'), ('Ravanelli, M., Parcollet, T., Plantinga, P., Rouhe, A., Cor- nell, S., Lugosch, L., Subakan, C., Dawalatabad, N', 'related_to_core', 'transferable visual models'), ('chunk_178', 'mentions', 'J., Krueger, G., and Sutskever, I'), ('chunk_178', 'mentions', 'transferable visual models'), ('chunk_178', 'mentions', 'natural language supervision'), ('chunk_178', 'mentions', 'arXiv preprint'), ('chunk_178', 'mentions', 'Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y ., Li, W., Liu, P. J., et al'), ('chunk_178', 'mentions', 'transfer learning'), ('chunk_178', 'mentions', 'uniﬁed text-to-text transformer'), ('chunk_178', 'mentions', 'J. Mach. Learn. Res.'), ('chunk_178', 'mentions', 'Ravanelli, M., Parcollet, T., Plantinga, P., Rouhe, A., Cor- nell, S., Lugosch, L., Subakan, C., Dawalatabad, N')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_179...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"SpeechBrain\", \"is_core_idea\", \"true\"), (\"chunk_179\", \"is_core_chunk\", \"true\"), (\"SpeechBrain\", \"related_to_core\", \"SpeechBrain\"), (\"ImageNet classiﬁers\", \"related_to_core\", \"SpeechBrain\"), (\"ImageNet\", \"related_to_core\", \"SpeechBrain\"), (\"International Conference on Machine Learning\", \"related_to_core\", \"SpeechBrain\"), (\"Machine Learning\", \"related_to_core\", \"SpeechBrain\"), (\"chunk_179\", \"mentions\", \"SpeechBrain\"), (\"chunk_179\", \"mentions\", \"ImageNet classiﬁers\"), (\"chunk_179\", \"mentions\", \"ImageNet\"), (\"chunk_179\", \"mentions\", \"International Conference on Machine Learning\"), (\"chunk_179\", \"mentions\", \"Machine Learning\")]\n",
            "✅ Extracted: [('SpeechBrain', 'is_core_idea', 'true'), ('chunk_179', 'is_core_chunk', 'true'), ('SpeechBrain', 'related_to_core', 'SpeechBrain'), ('ImageNet classiﬁers', 'related_to_core', 'SpeechBrain'), ('ImageNet', 'related_to_core', 'SpeechBrain'), ('International Conference on Machine Learning', 'related_to_core', 'SpeechBrain'), ('Machine Learning', 'related_to_core', 'SpeechBrain'), ('chunk_179', 'mentions', 'SpeechBrain'), ('chunk_179', 'mentions', 'ImageNet classiﬁers'), ('chunk_179', 'mentions', 'ImageNet'), ('chunk_179', 'mentions', 'International Conference on Machine Learning'), ('chunk_179', 'mentions', 'Machine Learning')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_180...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Feature engineering\", \"is_core_idea\", \"true\"), (\"chunk_180\", \"is_core_chunk\", \"true\"), (\"Imagenet large scale visual recognition challenge\", \"related_to_core\", \"Feature engineering\"), (\"Multilingual speech processing\", \"related_to_core\", \"Feature engineering\"), (\"Imagenet large scale visual recognition challenge\", \"instance_of\", \"Challenge\"), (\"International journal of computer vision\", \"instance_of\", \"Journal\"), (\"Multilingual speech processing\", \"instance_of\", \"Process\"), (\"Elsevier\", \"instance_of\", \"Publisher\"), (\"Feature engineering\", \"instance_of\", \"Technique\"), (\"chunk_180\", \"mentions\", \"Imagenet large scale visual recognition challenge\"), (\"chunk_180\", \"mentions\", \"International journal of computer vision\"), (\"chunk_180\", \"mentions\", \"Multilingual speech processing\"), (\"chunk_180\", \"mentions\", \"Elsevier\"), (\"chunk_180\", \"mentions\", \"Feature engineering\")]\n",
            "✅ Extracted: [('Feature engineering', 'is_core_idea', 'true'), ('chunk_180', 'is_core_chunk', 'true'), ('Imagenet large scale visual recognition challenge', 'related_to_core', 'Feature engineering'), ('Multilingual speech processing', 'related_to_core', 'Feature engineering'), ('Imagenet large scale visual recognition challenge', 'instance_of', 'Challenge'), ('International journal of computer vision', 'instance_of', 'Journal'), ('Multilingual speech processing', 'instance_of', 'Process'), ('Elsevier', 'instance_of', 'Publisher'), ('Feature engineering', 'instance_of', 'Technique'), ('chunk_180', 'mentions', 'Imagenet large scale visual recognition challenge'), ('chunk_180', 'mentions', 'International journal of computer vision'), ('chunk_180', 'mentions', 'Multilingual speech processing'), ('chunk_180', 'mentions', 'Elsevier'), ('chunk_180', 'mentions', 'Feature engineering')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_181...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"context-dependent deep neural networks\", \"used_for\", \"conversational speech transcription\"), (\"chunk_181\", \"mentions\", \"context-dependent deep neural networks\"), (\"chunk_181\", \"mentions\", \"conversational speech transcription\"), (\"chunk_181\", \"mentions\", \"IEEE Workshop on Automatic Speech Recognition & Understanding\"), (\"chunk_181\", \"mentions\", \"IEEE\")]\n",
            "✅ Extracted: [('context-dependent deep neural networks', 'used_for', 'conversational speech transcription'), ('chunk_181', 'mentions', 'context-dependent deep neural networks'), ('chunk_181', 'mentions', 'conversational speech transcription'), ('chunk_181', 'mentions', 'IEEE Workshop on Automatic Speech Recognition & Understanding'), ('chunk_181', 'mentions', 'IEEE')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_182...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_182\", \"is_core_chunk\", \"true\"), (\"Robust Speech Recognition\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Large-Scale Weak Supervision\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Neural machine translation\", \"related_to_core\", \"Robust Speech Recognition\"), (\"subword units\", \"related_to_core\", \"Robust Speech Recognition\"), (\"arXiv preprint arXiv:1508.07909\", \"related_to_core\", \"Robust Speech Recognition\"), (\"ftfy\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Zenodo\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Sequence to sequence learning\", \"related_to_core\", \"Robust Speech Recognition\"), (\"neural networks\", \"related_to_core\", \"Robust Speech Recognition\"), (\"neural information processing systems\", \"related_to_core\", \"Robust Speech Recognition\"), (\"chunk_182\", \"mentions\", \"Robust Speech Recognition\"), (\"chunk_182\", \"mentions\", \"Large-Scale Weak Supervision\"), (\"chunk_182\", \"mentions\", \"Neural machine translation\"), (\"chunk_182\", \"mentions\", \"subword units\"), (\"chunk_182\", \"mentions\", \"arXiv preprint arXiv:1508.07909\"), (\"chunk_182\", \"mentions\", \"ftfy\"), (\"chunk_182\", \"mentions\", \"Zenodo\"), (\"chunk_182\", \"mentions\", \"Sequence to sequence learning\"), (\"chunk_182\", \"mentions\", \"neural networks\"), (\"chunk_182\", \"mentions\", \"neural information processing systems\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'is_core_idea', 'true'), ('chunk_182', 'is_core_chunk', 'true'), ('Robust Speech Recognition', 'related_to_core', 'Robust Speech Recognition'), ('Large-Scale Weak Supervision', 'related_to_core', 'Robust Speech Recognition'), ('Neural machine translation', 'related_to_core', 'Robust Speech Recognition'), ('subword units', 'related_to_core', 'Robust Speech Recognition'), ('arXiv preprint arXiv:1508.07909', 'related_to_core', 'Robust Speech Recognition'), ('ftfy', 'related_to_core', 'Robust Speech Recognition'), ('Zenodo', 'related_to_core', 'Robust Speech Recognition'), ('Sequence to sequence learning', 'related_to_core', 'Robust Speech Recognition'), ('neural networks', 'related_to_core', 'Robust Speech Recognition'), ('neural information processing systems', 'related_to_core', 'Robust Speech Recognition'), ('chunk_182', 'mentions', 'Robust Speech Recognition'), ('chunk_182', 'mentions', 'Large-Scale Weak Supervision'), ('chunk_182', 'mentions', 'Neural machine translation'), ('chunk_182', 'mentions', 'subword units'), ('chunk_182', 'mentions', 'arXiv preprint arXiv:1508.07909'), ('chunk_182', 'mentions', 'ftfy'), ('chunk_182', 'mentions', 'Zenodo'), ('chunk_182', 'mentions', 'Sequence to sequence learning'), ('chunk_182', 'mentions', 'neural networks'), ('chunk_182', 'mentions', 'neural information processing systems')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_183...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"information processing systems\", \"is_core_idea\", \"true\"), (\"chunk_183\", \"is_core_chunk\", \"true\"), (\"Measuring robustness to natural distribution shifts in image classiﬁcation\", \"related_to_core\", \"information processing systems\"), (\"Advances in Neural Information Processing Systems\", \"related_to_core\", \"information processing systems\"), (\"image classiﬁcation\", \"related_to_core\", \"information processing systems\"), (\"chunk_183\", \"mentions\", \"information processing systems\"), (\"chunk_183\", \"mentions\", \"Measuring robustness to natural distribution shifts in image classiﬁcation\"), (\"chunk_183\", \"mentions\", \"Advances in Neural Information Processing Systems\"), (\"chunk_183\", \"mentions\", \"image classiﬁcation\")]\n",
            "✅ Extracted: [('information processing systems', 'is_core_idea', 'true'), ('chunk_183', 'is_core_chunk', 'true'), ('Measuring robustness to natural distribution shifts in image classiﬁcation', 'related_to_core', 'information processing systems'), ('Advances in Neural Information Processing Systems', 'related_to_core', 'information processing systems'), ('image classiﬁcation', 'related_to_core', 'information processing systems'), ('chunk_183', 'mentions', 'information processing systems'), ('chunk_183', 'mentions', 'Measuring robustness to natural distribution shifts in image classiﬁcation'), ('chunk_183', 'mentions', 'Advances in Neural Information Processing Systems'), ('chunk_183', 'mentions', 'image classiﬁcation')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_184...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Torralba, A.\", \"is_author_of\", \"Unbiased look at dataset bias\"), (\"chunk_184\", \"mentions\", \"Torralba, A.\"), (\"Efros, A. A.\", \"is_author_of\", \"Unbiased look at dataset bias\"), (\"chunk_184\", \"mentions\", \"Efros, A. A.\"), (\"Unbiased look at dataset bias\", \"published_in\", \"CVPR 2011\"), (\"chunk_184\", \"mentions\", \"Unbiased look at dataset bias\"), (\"chunk_184\", \"mentions\", \"CVPR 2011\"), (\"Toshniwal, S.\", \"is_author_of\", \"Multilingual speech recognition with a single end-to-end model\"), (\"chunk_184\", \"mentions\", \"Toshniwal, S.\"), (\"Sainath, T. N.\", \"is_author_of\", \"Multilingual speech recognition with a single end-to-end model\"), (\"chunk_184\", \"mentions\", \"Sainath, T. N.\"), (\"Weiss, R. J.\", \"is_author_of\", \"Multilingual speech recognition with a single end-to-end model\"), (\"chunk_184\", \"mentions\", \"Weiss, R. J.\"), (\"Li, B.\", \"is_author_of\", \"Multilingual speech recognition with a single end-to-end model\"), (\"chunk_184\", \"mentions\", \"Li, B.\"), (\"Moreno, P. J.\", \"is_author_of\", \"Multilingual speech recognition with a single end-to-end model\"), (\"chunk_184\", \"mentions\", \"Moreno, P. J.\"), (\"Weinstein, E.\", \"is_author_of\", \"Multilingual speech recognition with a single end-to-end model\"), (\"chunk_184\", \"mentions\", \"Weinstein, E.\"), (\"Rao, K.\", \"is_author_of\", \"Multilingual speech recognition with a single end-to-end model\"), (\"chunk_184\", \"mentions\", \"Rao, K.\"), (\"Multilingual speech recognition with a single end-to-end model\", \"published_in\", \"2018 IEEE International Conference on Acoustics, Speech and Sig-nal Processing (ICASSP)\"), (\"chunk_184\", \"mentions\", \"Multilingual speech recognition with a single end-to-end model\"), (\"chunk_184\", \"mentions\", \"2018 IEEE International Conference on Acoustics, Speech and Sig-nal Processing (ICASSP)\"), (\"Valk, J.\", \"is_author_of\", \"V oxlingua107: a dataset for spoken\"), (\"chunk_184\", \"mentions\", \"Valk, J.\"), (\"Alum¨ae, T.\", \"is_author_of\", \"V oxlingua107: a dataset for spoken\"), (\"chunk_184\", \"mentions\", \"Alum¨ae, T.\"), (\"V oxlingua107: a dataset for spoken\", \"is_core_idea\", \"true\"), (\"chunk_184\", \"is_core_chunk\", \"true\"), (\"chunk_184\", \"mentions\", \"V oxlingua107: a dataset for spoken\"), (\"Torralba, A.\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"Efros, A. A.\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"Unbiased look at dataset bias\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"CVPR 2011\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"Toshniwal, S.\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"Sainath, T. N.\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"Weiss, R. J.\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"Li, B.\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"Moreno, P. J.\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"Weinstein, E.\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"Rao, K.\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"Multilingual speech recognition with a single end-to-end model\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\"), (\"2018 IEEE International Conference on Acoustics, Speech and Sig-nal Processing (ICASSP)\", \"related_to_core\", \"V oxlingua107: a dataset for spoken\")]\n",
            "✅ Extracted: [('Torralba, A.', 'is_author_of', 'Unbiased look at dataset bias'), ('chunk_184', 'mentions', 'Torralba, A.'), ('Efros, A. A.', 'is_author_of', 'Unbiased look at dataset bias'), ('chunk_184', 'mentions', 'Efros, A. A.'), ('Unbiased look at dataset bias', 'published_in', 'CVPR 2011'), ('chunk_184', 'mentions', 'Unbiased look at dataset bias'), ('chunk_184', 'mentions', 'CVPR 2011'), ('Toshniwal, S.', 'is_author_of', 'Multilingual speech recognition with a single end-to-end model'), ('chunk_184', 'mentions', 'Toshniwal, S.'), ('Sainath, T. N.', 'is_author_of', 'Multilingual speech recognition with a single end-to-end model'), ('chunk_184', 'mentions', 'Sainath, T. N.'), ('Weiss, R. J.', 'is_author_of', 'Multilingual speech recognition with a single end-to-end model'), ('chunk_184', 'mentions', 'Weiss, R. J.'), ('Li, B.', 'is_author_of', 'Multilingual speech recognition with a single end-to-end model'), ('chunk_184', 'mentions', 'Li, B.'), ('Moreno, P. J.', 'is_author_of', 'Multilingual speech recognition with a single end-to-end model'), ('chunk_184', 'mentions', 'Moreno, P. J.'), ('Weinstein, E.', 'is_author_of', 'Multilingual speech recognition with a single end-to-end model'), ('chunk_184', 'mentions', 'Weinstein, E.'), ('Rao, K.', 'is_author_of', 'Multilingual speech recognition with a single end-to-end model'), ('chunk_184', 'mentions', 'Rao, K.'), ('Multilingual speech recognition with a single end-to-end model', 'published_in', '2018 IEEE International Conference on Acoustics, Speech and Sig-nal Processing (ICASSP)'), ('chunk_184', 'mentions', 'Multilingual speech recognition with a single end-to-end model'), ('chunk_184', 'mentions', '2018 IEEE International Conference on Acoustics, Speech and Sig-nal Processing (ICASSP)'), ('Valk, J.', 'is_author_of', 'V oxlingua107: a dataset for spoken'), ('chunk_184', 'mentions', 'Valk, J.'), ('Alum¨ae, T.', 'is_author_of', 'V oxlingua107: a dataset for spoken'), ('chunk_184', 'mentions', 'Alum¨ae, T.'), ('V oxlingua107: a dataset for spoken', 'is_core_idea', 'true'), ('chunk_184', 'is_core_chunk', 'true'), ('chunk_184', 'mentions', 'V oxlingua107: a dataset for spoken'), ('Torralba, A.', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('Efros, A. A.', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('Unbiased look at dataset bias', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('CVPR 2011', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('Toshniwal, S.', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('Sainath, T. N.', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('Weiss, R. J.', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('Li, B.', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('Moreno, P. J.', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('Weinstein, E.', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('Rao, K.', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('Multilingual speech recognition with a single end-to-end model', 'related_to_core', 'V oxlingua107: a dataset for spoken'), ('2018 IEEE International Conference on Acoustics, Speech and Sig-nal Processing (ICASSP)', 'related_to_core', 'V oxlingua107: a dataset for spoken')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_185...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"language recognition\", \"is_core_idea\", \"true\"), (\"chunk_185\", \"is_core_chunk\", \"true\"), (\"chunk_185\", \"mentions\", \"language recognition\"), (\"IEEE Spoken Language Technology Workshop\", \"related_to_core\", \"language recognition\"), (\"neural information processing systems\", \"related_to_core\", \"language recognition\"), (\"IEEE Spoken Language Technology Workshop\", \"mentions\", \"IEEE Spoken Language Technology Workshop\"), (\"neural information processing systems\", \"mentions\", \"neural information processing systems\")]\n",
            "✅ Extracted: [('language recognition', 'is_core_idea', 'true'), ('chunk_185', 'is_core_chunk', 'true'), ('chunk_185', 'mentions', 'language recognition'), ('IEEE Spoken Language Technology Workshop', 'related_to_core', 'language recognition'), ('neural information processing systems', 'related_to_core', 'language recognition'), ('IEEE Spoken Language Technology Workshop', 'mentions', 'IEEE Spoken Language Technology Workshop'), ('neural information processing systems', 'mentions', 'neural information processing systems')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_186...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"SciPy 1.0\", \"is_core_idea\", \"true\"), (\"chunk_186\", \"is_core_chunk\", \"true\"), (\"chunk_186\", \"mentions\", \"Wilson\"), (\"Wilson\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Millman\"), (\"Millman\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Mayorov\"), (\"Mayorov\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Nelson\"), (\"Nelson\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Jones\"), (\"Jones\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Kern\"), (\"Kern\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Larson\"), (\"Larson\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Carey\"), (\"Carey\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Polat\"), (\"Polat\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Feng\"), (\"Feng\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Moore\"), (\"Moore\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"VanderPlas\"), (\"VanderPlas\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Laxalde\"), (\"Laxalde\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Perktold\"), (\"Perktold\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Cimrman\"), (\"Cimrman\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Henriksen\"), (\"Henriksen\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Quintero\"), (\"Quintero\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Harris\"), (\"Harris\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Archibald\"), (\"Archibald\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Ribeiro\"), (\"Ribeiro\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Pedregosa\"), (\"Pedregosa\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"van Mulbregt\"), (\"van Mulbregt\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Fundamental Algorithms for Scientiﬁc Computing in Python\"), (\"Fundamental Algorithms for Scientiﬁc Computing in Python\", \"related_to_core\", \"SciPy 1.0\"), (\"chunk_186\", \"mentions\", \"Nature Methods\"), (\"Nature Methods\", \"related_to_core\", \"SciPy 1.0\")]\n",
            "✅ Extracted: [('SciPy 1.0', 'is_core_idea', 'true'), ('chunk_186', 'is_core_chunk', 'true'), ('chunk_186', 'mentions', 'Wilson'), ('Wilson', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Millman'), ('Millman', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Mayorov'), ('Mayorov', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Nelson'), ('Nelson', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Jones'), ('Jones', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Kern'), ('Kern', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Larson'), ('Larson', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Carey'), ('Carey', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Polat'), ('Polat', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Feng'), ('Feng', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Moore'), ('Moore', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'VanderPlas'), ('VanderPlas', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Laxalde'), ('Laxalde', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Perktold'), ('Perktold', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Cimrman'), ('Cimrman', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Henriksen'), ('Henriksen', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Quintero'), ('Quintero', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Harris'), ('Harris', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Archibald'), ('Archibald', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Ribeiro'), ('Ribeiro', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Pedregosa'), ('Pedregosa', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'van Mulbregt'), ('van Mulbregt', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Fundamental Algorithms for Scientiﬁc Computing in Python'), ('Fundamental Algorithms for Scientiﬁc Computing in Python', 'related_to_core', 'SciPy 1.0'), ('chunk_186', 'mentions', 'Nature Methods'), ('Nature Methods', 'related_to_core', 'SciPy 1.0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_187...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"fairseq s2t\", \"is_core_idea\", \"true\"), (\"chunk_187\", \"is_core_chunk\", \"true\"), (\"speech-to-text modeling\", \"related_to_core\", \"fairseq s2t\"), (\"Covost 2\", \"related_to_core\", \"fairseq s2t\"), (\"massively multilingual speech-to-text translation\", \"related_to_core\", \"fairseq s2t\"), (\"V oxpopuli\", \"related_to_core\", \"fairseq s2t\"), (\"large-scale multilingual speech corpus\", \"related_to_core\", \"fairseq s2t\"), (\"fairseq s2t\", \"mentions\", \"Fast speech-to-text modeling\"), (\"fairseq s2t\", \"mentions\", \"fairseq\"), (\"speech-to-text modeling\", \"mentions\", \"speech-to-text modeling\"), (\"Covost 2\", \"mentions\", \"Covost 2\"), (\"massively multilingual speech-to-text translation\", \"mentions\", \"massively multilingual speech-to-text translation\"), (\"V oxpopuli\", \"mentions\", \"V oxpopuli\"), (\"large-scale multilingual speech corpus\", \"mentions\", \"large-scale multilingual speech corpus\"), (\"chunk_187\", \"mentions\", \"fairseq s2t\"), (\"chunk_187\", \"mentions\", \"speech-to-text modeling\"), (\"chunk_187\", \"mentions\", \"Covost 2\"), (\"chunk_187\", \"mentions\", \"massively multilingual speech-to-text translation\"), (\"chunk_187\", \"mentions\", \"V oxpopuli\"), (\"chunk_187\", \"mentions\", \"large-scale multilingual speech corpus\")]\n",
            "✅ Extracted: [('fairseq s2t', 'is_core_idea', 'true'), ('chunk_187', 'is_core_chunk', 'true'), ('speech-to-text modeling', 'related_to_core', 'fairseq s2t'), ('Covost 2', 'related_to_core', 'fairseq s2t'), ('massively multilingual speech-to-text translation', 'related_to_core', 'fairseq s2t'), ('V oxpopuli', 'related_to_core', 'fairseq s2t'), ('large-scale multilingual speech corpus', 'related_to_core', 'fairseq s2t'), ('fairseq s2t', 'mentions', 'Fast speech-to-text modeling'), ('fairseq s2t', 'mentions', 'fairseq'), ('speech-to-text modeling', 'mentions', 'speech-to-text modeling'), ('Covost 2', 'mentions', 'Covost 2'), ('massively multilingual speech-to-text translation', 'mentions', 'massively multilingual speech-to-text translation'), ('V oxpopuli', 'mentions', 'V oxpopuli'), ('large-scale multilingual speech corpus', 'mentions', 'large-scale multilingual speech corpus'), ('chunk_187', 'mentions', 'fairseq s2t'), ('chunk_187', 'mentions', 'speech-to-text modeling'), ('chunk_187', 'mentions', 'Covost 2'), ('chunk_187', 'mentions', 'massively multilingual speech-to-text translation'), ('chunk_187', 'mentions', 'V oxpopuli'), ('chunk_187', 'mentions', 'large-scale multilingual speech corpus')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_188...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"semi-supervised learning\", \"related_to_core\", \"learning\"), (\"interpretation\", \"related_to_core\", \"learning\"), (\"learning\", \"is_core_idea\", \"true\"), (\"chunk_188\", \"is_core_chunk\", \"true\"), (\"learning\", \"mentions\", \"semi-supervised learning\"), (\"learning\", \"mentions\", \"interpretation\"), (\"chunk_188\", \"mentions\", \"learning\"), (\"arXiv preprint\", \"mentions\", \"arXiv:2101.00390\"), (\"chunk_188\", \"mentions\", \"arXiv preprint\"), (\"text data\", \"mentions\", \"text data\"), (\"speech recognition\", \"mentions\", \"speech recognition\"), (\"end-to-end speech recognition\", \"mentions\", \"end-to-end speech recognition\"), (\"arXiv preprint\", \"mentions\", \"arXiv:2010.14318\"), (\"multispeaker speech recognition\", \"mentions\", \"multispeaker speech recognition\"), (\"unsegmented recordings\", \"mentions\", \"unsegmented recordings\"), (\"semi-supervised learning\", \"is_a\", \"learning\"), (\"interpretation\", \"is_a\", \"learning\")]\n",
            "✅ Extracted: [('semi-supervised learning', 'related_to_core', 'learning'), ('interpretation', 'related_to_core', 'learning'), ('learning', 'is_core_idea', 'true'), ('chunk_188', 'is_core_chunk', 'true'), ('learning', 'mentions', 'semi-supervised learning'), ('learning', 'mentions', 'interpretation'), ('chunk_188', 'mentions', 'learning'), ('arXiv preprint', 'mentions', 'arXiv:2101.00390'), ('chunk_188', 'mentions', 'arXiv preprint'), ('text data', 'mentions', 'text data'), ('speech recognition', 'mentions', 'speech recognition'), ('end-to-end speech recognition', 'mentions', 'end-to-end speech recognition'), ('arXiv preprint', 'mentions', 'arXiv:2010.14318'), ('multispeaker speech recognition', 'mentions', 'multispeaker speech recognition'), ('unsegmented recordings', 'mentions', 'unsegmented recordings'), ('semi-supervised learning', 'is_a', 'learning'), ('interpretation', 'is_a', 'learning')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_189...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"speech recognition\", \"is_core_idea\", \"true\"), (\"chunk_189\", \"is_core_chunk\", \"true\"), (\"arXiv:2004.09249\", \"related_to_core\", \"speech recognition\"), (\"Self-training\", \"related_to_core\", \"speech recognition\"), (\"pre-training\", \"related_to_core\", \"speech recognition\"), (\"ICASSP\", \"related_to_core\", \"speech recognition\"), (\"IEEE International Conference on Acoustics, Speech and Signal Processing\", \"related_to_core\", \"speech recognition\"), (\"chunk_189\", \"mentions\", \"arXiv:2004.09249\"), (\"chunk_189\", \"mentions\", \"Self-training\"), (\"chunk_189\", \"mentions\", \"pre-training\"), (\"chunk_189\", \"mentions\", \"speech recognition\"), (\"chunk_189\", \"mentions\", \"ICASSP\"), (\"chunk_189\", \"mentions\", \"IEEE International Conference on Acoustics, Speech and Signal Processing\"), (\"Self-training\", \"are complementary for\", \"speech recognition\"), (\"pre-training\", \"are complementary for\", \"speech recognition\")]\n",
            "✅ Extracted: [('speech recognition', 'is_core_idea', 'true'), ('chunk_189', 'is_core_chunk', 'true'), ('arXiv:2004.09249', 'related_to_core', 'speech recognition'), ('Self-training', 'related_to_core', 'speech recognition'), ('pre-training', 'related_to_core', 'speech recognition'), ('ICASSP', 'related_to_core', 'speech recognition'), ('IEEE International Conference on Acoustics, Speech and Signal Processing', 'related_to_core', 'speech recognition'), ('chunk_189', 'mentions', 'arXiv:2004.09249'), ('chunk_189', 'mentions', 'Self-training'), ('chunk_189', 'mentions', 'pre-training'), ('chunk_189', 'mentions', 'speech recognition'), ('chunk_189', 'mentions', 'ICASSP'), ('chunk_189', 'mentions', 'IEEE International Conference on Acoustics, Speech and Signal Processing'), ('Self-training', 'are complementary for', 'speech recognition'), ('pre-training', 'are complementary for', 'speech recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_190...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"supervised learning\", \"for\", \"automatic speech recognition\"), (\"chunk_190\", \"mentions\", \"supervised learning\"), (\"chunk_190\", \"mentions\", \"automatic speech recognition\"), (\"automatic speech recognition\", \"is_core_idea\", \"true\"), (\"chunk_190\", \"is_core_chunk\", \"true\"), (\"supervised learning\", \"related_to_core\", \"automatic speech recognition\")]\n",
            "✅ Extracted: [('supervised learning', 'for', 'automatic speech recognition'), ('chunk_190', 'mentions', 'supervised learning'), ('chunk_190', 'mentions', 'automatic speech recognition'), ('automatic speech recognition', 'is_core_idea', 'true'), ('chunk_190', 'is_core_chunk', 'true'), ('supervised learning', 'related_to_core', 'automatic speech recognition')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_191...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"Robust Speech Recognition\", \"is_core_idea\", \"true\"), (\"chunk_191\", \"is_core_chunk\", \"true\"), (\"chunk_191\", \"mentions\", \"Robust Speech Recognition\"), (\"Evaluation Datasets\", \"related_to_core\", \"Robust Speech Recognition\"), (\"Short-form English-only datasets\", \"related_to_core\", \"Robust Speech Recognition\"), (\"LibriSpeech\", \"related_to_core\", \"Robust Speech Recognition\"), (\"TED-LIUM 3\", \"related_to_core\", \"Robust Speech Recognition\"), (\"chunk_191\", \"mentions\", \"Evaluation Datasets\"), (\"chunk_191\", \"mentions\", \"Short-form English-only datasets\"), (\"chunk_191\", \"mentions\", \"LibriSpeech\"), (\"chunk_191\", \"mentions\", \"TED-LIUM 3\"), (\"LibriSpeech ASR corpus\", \"part_of\", \"LibriSpeech\"), (\"TED-LIUM Release 3\", \"part_of\", \"TED-LIUM 3\"), (\"LibriSpeech\", \"is_ASR_corpus\", \"LibriSpeech ASR corpus\"), (\"TED-LIUM 3\", \"is_release\", \"TED-LIUM Release 3\")]\n",
            "✅ Extracted: [('Robust Speech Recognition', 'is_core_idea', 'true'), ('chunk_191', 'is_core_chunk', 'true'), ('chunk_191', 'mentions', 'Robust Speech Recognition'), ('Evaluation Datasets', 'related_to_core', 'Robust Speech Recognition'), ('Short-form English-only datasets', 'related_to_core', 'Robust Speech Recognition'), ('LibriSpeech', 'related_to_core', 'Robust Speech Recognition'), ('TED-LIUM 3', 'related_to_core', 'Robust Speech Recognition'), ('chunk_191', 'mentions', 'Evaluation Datasets'), ('chunk_191', 'mentions', 'Short-form English-only datasets'), ('chunk_191', 'mentions', 'LibriSpeech'), ('chunk_191', 'mentions', 'TED-LIUM 3'), ('LibriSpeech ASR corpus', 'part_of', 'LibriSpeech'), ('TED-LIUM Release 3', 'part_of', 'TED-LIUM 3'), ('LibriSpeech', 'is_ASR_corpus', 'LibriSpeech ASR corpus'), ('TED-LIUM 3', 'is_release', 'TED-LIUM Release 3')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_192...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"transcripts\", \"included_in\", \"release\"), (\"chunk_192\", \"mentions\", \"transcripts\"), (\"chunk_192\", \"mentions\", \"Common Voice 5.1\"), (\"Common Voice 5.1\", \"is_core_idea\", \"true\"), (\"chunk_192\", \"is_core_chunk\", \"true\"), (\"Ardila et al.\", \"related_to_core\", \"Common Voice 5.1\"), (\"Ardila et al.\", \"created\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"Ardila et al.\"), (\"English subset\", \"part_of\", \"Common Voice Corpus 5.1\"), (\"chunk_192\", \"mentions\", \"English subset\"), (\"Common Voice Corpus 5.1\", \"related_to_core\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"Common Voice Corpus 5.1\"), (\"Artie bias corpus\", \"is_subset_of\", \"Common Voice dataset\"), (\"chunk_192\", \"mentions\", \"Artie bias corpus\"), (\"Artie bias corpus\", \"related_to_core\", \"Common Voice 5.1\"), (\"Meyer et al.\", \"created\", \"Artie bias corpus\"), (\"chunk_192\", \"mentions\", \"Meyer et al.\"), (\"Meyer et al.\", \"related_to_core\", \"Common Voice 5.1\"), (\"Common Voice dataset\", \"related_to_core\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"Common Voice dataset\"), (\"CallHome\", \"related_to_core\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"CallHome\"), (\"Switchboard\", \"related_to_core\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"Switchboard\"), (\"LDC2002S09\", \"related_to_core\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"LDC2002S09\"), (\"LDC2002T43\", \"related_to_core\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"LDC2002T43\"), (\"WSJ\", \"related_to_core\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"WSJ\"), (\"LDC93S6B\", \"related_to_core\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"LDC93S6B\"), (\"LDC94S13B\", \"related_to_core\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"LDC94S13B\"), (\"s5 recipe\", \"related_to_core\", \"Common Voice 5.1\"), (\"chunk_192\", \"mentions\", \"s5 recipe\")]\n",
            "✅ Extracted: [('transcripts', 'included_in', 'release'), ('chunk_192', 'mentions', 'transcripts'), ('chunk_192', 'mentions', 'Common Voice 5.1'), ('Common Voice 5.1', 'is_core_idea', 'true'), ('chunk_192', 'is_core_chunk', 'true'), ('Ardila et al.', 'related_to_core', 'Common Voice 5.1'), ('Ardila et al.', 'created', 'Common Voice 5.1'), ('chunk_192', 'mentions', 'Ardila et al.'), ('English subset', 'part_of', 'Common Voice Corpus 5.1'), ('chunk_192', 'mentions', 'English subset'), ('Common Voice Corpus 5.1', 'related_to_core', 'Common Voice 5.1'), ('chunk_192', 'mentions', 'Common Voice Corpus 5.1'), ('Artie bias corpus', 'is_subset_of', 'Common Voice dataset'), ('chunk_192', 'mentions', 'Artie bias corpus'), ('Artie bias corpus', 'related_to_core', 'Common Voice 5.1'), ('Meyer et al.', 'created', 'Artie bias corpus'), ('chunk_192', 'mentions', 'Meyer et al.'), ('Meyer et al.', 'related_to_core', 'Common Voice 5.1'), ('Common Voice dataset', 'related_to_core', 'Common Voice 5.1'), ('chunk_192', 'mentions', 'Common Voice dataset'), ('CallHome', 'related_to_core', 'Common Voice 5.1'), ('chunk_192', 'mentions', 'CallHome'), ('Switchboard', 'related_to_core', 'Common Voice 5.1'), ('chunk_192', 'mentions', 'Switchboard'), ('LDC2002S09', 'related_to_core', 'Common Voice 5.1'), ('chunk_192', 'mentions', 'LDC2002S09'), ('LDC2002T43', 'related_to_core', 'Common Voice 5.1'), ('chunk_192', 'mentions', 'LDC2002T43'), ('WSJ', 'related_to_core', 'Common Voice 5.1'), ('chunk_192', 'mentions', 'WSJ'), ('LDC93S6B', 'related_to_core', 'Common Voice 5.1'), ('chunk_192', 'mentions', 'LDC93S6B'), ('LDC94S13B', 'related_to_core', 'Common Voice 5.1'), ('chunk_192', 'mentions', 'LDC94S13B'), ('s5 recipe', 'related_to_core', 'Common Voice 5.1'), ('chunk_192', 'mentions', 's5 recipe')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_193...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"CORAAL\", \"mentions\", \"Kendall & Farrington\"), (\"CORAAL\", \"mentions\", \"FairSpeech project\"), (\"CORAAL\", \"is_core_idea\", \"true\"), (\"chunk_193\", \"is_core_chunk\", \"true\"), (\"chunk_193\", \"mentions\", \"CORAAL\"), (\"chunk_193\", \"mentions\", \"Kendall & Farrington\"), (\"chunk_193\", \"mentions\", \"FairSpeech project\"), (\"chunk_193\", \"mentions\", \"CHiME-6\"), (\"chunk_193\", \"mentions\", \"Watanabe et al.\"), (\"chunk_193\", \"mentions\", \"CHiME-5 dataset\"), (\"chunk_193\", \"mentions\", \"s5 track1 recipe\"), (\"chunk_193\", \"mentions\", \"binaural recordings\"), (\"Kendall & Farrington\", \"related_to_core\", \"CORAAL\"), (\"FairSpeech project\", \"related_to_core\", \"CORAAL\"), (\"CHiME-6\", \"related_to_core\", \"CORAAL\"), (\"Watanabe et al.\", \"related_to_core\", \"CORAAL\"), (\"CHiME-5 dataset\", \"related_to_core\", \"CORAAL\"), (\"s5 track1 recipe\", \"related_to_core\", \"CORAAL\"), (\"binaural recordings\", \"related_to_core\", \"CORAAL\"), (\"CHiME-6\", \"mentions\", \"Watanabe et al.\"), (\"CHiME-6\", \"mentions\", \"CHiME-5 dataset\"), (\"CHiME-6\", \"mentions\", \"s5 track1 recipe\"), (\"CHiME-6\", \"mentions\", \"binaural recordings\")]\n",
            "✅ Extracted: [('CORAAL', 'mentions', 'Kendall & Farrington'), ('CORAAL', 'mentions', 'FairSpeech project'), ('CORAAL', 'is_core_idea', 'true'), ('chunk_193', 'is_core_chunk', 'true'), ('chunk_193', 'mentions', 'CORAAL'), ('chunk_193', 'mentions', 'Kendall & Farrington'), ('chunk_193', 'mentions', 'FairSpeech project'), ('chunk_193', 'mentions', 'CHiME-6'), ('chunk_193', 'mentions', 'Watanabe et al.'), ('chunk_193', 'mentions', 'CHiME-5 dataset'), ('chunk_193', 'mentions', 's5 track1 recipe'), ('chunk_193', 'mentions', 'binaural recordings'), ('Kendall & Farrington', 'related_to_core', 'CORAAL'), ('FairSpeech project', 'related_to_core', 'CORAAL'), ('CHiME-6', 'related_to_core', 'CORAAL'), ('Watanabe et al.', 'related_to_core', 'CORAAL'), ('CHiME-5 dataset', 'related_to_core', 'CORAAL'), ('s5 track1 recipe', 'related_to_core', 'CORAAL'), ('binaural recordings', 'related_to_core', 'CORAAL'), ('CHiME-6', 'mentions', 'Watanabe et al.'), ('CHiME-6', 'mentions', 'CHiME-5 dataset'), ('CHiME-6', 'mentions', 's5 track1 recipe'), ('CHiME-6', 'mentions', 'binaural recordings')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_194...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"AMI-IHM\", \"mentions\", \"AMI Corpus\"), (\"AMI-SDM1\", \"mentions\", \"AMI Corpus\"), (\"AMI Corpus\", \"related_to_core\", \"TED-LIUM 3\"), (\"AMI-IHM\", \"related_to_core\", \"TED-LIUM 3\"), (\"AMI-SDM1\", \"related_to_core\", \"TED-LIUM 3\"), (\"s5b recipe\", \"related_to_core\", \"TED-LIUM 3\"), (\"TED-LIUM 3\", \"is_core_idea\", \"true\"), (\"chunk_194\", \"is_core_chunk\", \"true\"), (\"AMI-IHM\", \"mentions\", \"AMI-IHM\"), (\"AMI-SDM1\", \"mentions\", \"AMI-SDM1\"), (\"AMI Corpus\", \"subject\", \"s5b recipe\"), (\"TED-LIUM 3\", \"mentions\", \"TED-LIUM 3\"), (\"s5b recipe\", \"mentions\", \"s5b recipe\"), (\"chunk_194\", \"mentions\", \"AMI-IHM\"), (\"chunk_194\", \"mentions\", \"AMI-SDM1\"), (\"chunk_194\", \"mentions\", \"AMI Corpus\"), (\"chunk_194\", \"mentions\", \"TED-LIUM 3\"), (\"chunk_194\", \"mentions\", \"s5b recipe\")]\n",
            "✅ Extracted: [('AMI-IHM', 'mentions', 'AMI Corpus'), ('AMI-SDM1', 'mentions', 'AMI Corpus'), ('AMI Corpus', 'related_to_core', 'TED-LIUM 3'), ('AMI-IHM', 'related_to_core', 'TED-LIUM 3'), ('AMI-SDM1', 'related_to_core', 'TED-LIUM 3'), ('s5b recipe', 'related_to_core', 'TED-LIUM 3'), ('TED-LIUM 3', 'is_core_idea', 'true'), ('chunk_194', 'is_core_chunk', 'true'), ('AMI-IHM', 'mentions', 'AMI-IHM'), ('AMI-SDM1', 'mentions', 'AMI-SDM1'), ('AMI Corpus', 'subject', 's5b recipe'), ('TED-LIUM 3', 'mentions', 'TED-LIUM 3'), ('s5b recipe', 'mentions', 's5b recipe'), ('chunk_194', 'mentions', 'AMI-IHM'), ('chunk_194', 'mentions', 'AMI-SDM1'), ('chunk_194', 'mentions', 'AMI Corpus'), ('chunk_194', 'mentions', 'TED-LIUM 3'), ('chunk_194', 'mentions', 's5b recipe')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_195...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"dataset\", \"mentions\", \"The Late Show with Stephen Colbert\"), (\"chunk_195\", \"mentions\", \"dataset\"), (\"The Late Show with Stephen Colbert\", \"related_to_core\", \"dataset\"), (\"chunk_195\", \"is_core_chunk\", \"true\"), (\"dataset\", \"is_core_idea\", \"true\"), (\"chunk_195\", \"mentions\", \"YouTube video ID\"), (\"YouTube video ID\", \"related_to_core\", \"dataset\"), (\"chunk_195\", \"mentions\", \"timestamps\"), (\"timestamps\", \"related_to_core\", \"dataset\"), (\"chunk_195\", \"mentions\", \"labels\"), (\"labels\", \"related_to_core\", \"dataset\"), (\"labels\", \"collected from\", \"closed-caption data\"), (\"chunk_195\", \"mentions\", \"closed-caption data\"), (\"closed-caption data\", \"related_to_core\", \"dataset\"), (\"labels\", \"corrected with\", \"manual inspection\"), (\"chunk_195\", \"mentions\", \"manual inspection\"), (\"manual inspection\", \"related_to_core\", \"dataset\"), (\"chunk_195\", \"mentions\", \"Rev16\"), (\"Rev16\", \"related_to_core\", \"dataset\"), (\"chunk_195\", \"mentions\", \"podcast episodes\"), (\"podcast episodes\", \"related_to_core\", \"dataset\"), (\"podcast episodes\", \"in\", \"Rev.AI's Podcast Transcription Benchmark\"), (\"chunk_195\", \"mentions\", \"Rev.AI's Podcast Transcription Benchmark\"), (\"Rev.AI's Podcast Transcription Benchmark\", \"related_to_core\", \"dataset\")]\n",
            "✅ Extracted: [('dataset', 'mentions', 'The Late Show with Stephen Colbert'), ('chunk_195', 'mentions', 'dataset'), ('The Late Show with Stephen Colbert', 'related_to_core', 'dataset'), ('chunk_195', 'is_core_chunk', 'true'), ('dataset', 'is_core_idea', 'true'), ('chunk_195', 'mentions', 'YouTube video ID'), ('YouTube video ID', 'related_to_core', 'dataset'), ('chunk_195', 'mentions', 'timestamps'), ('timestamps', 'related_to_core', 'dataset'), ('chunk_195', 'mentions', 'labels'), ('labels', 'related_to_core', 'dataset'), ('labels', 'collected from', 'closed-caption data'), ('chunk_195', 'mentions', 'closed-caption data'), ('closed-caption data', 'related_to_core', 'dataset'), ('labels', 'corrected with', 'manual inspection'), ('chunk_195', 'mentions', 'manual inspection'), ('manual inspection', 'related_to_core', 'dataset'), ('chunk_195', 'mentions', 'Rev16'), ('Rev16', 'related_to_core', 'dataset'), ('chunk_195', 'mentions', 'podcast episodes'), ('podcast episodes', 'related_to_core', 'dataset'), ('podcast episodes', 'in', \"Rev.AI's Podcast Transcription Benchmark\"), ('chunk_195', 'mentions', \"Rev.AI's Podcast Transcription Benchmark\"), (\"Rev.AI's Podcast Transcription Benchmark\", 'related_to_core', 'dataset')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_196...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"audio\", \"related_to_core\", \"dataset\"), (\"labels\", \"related_to_core\", \"dataset\"), (\"episodes\", \"related_to_core\", \"dataset\"), (\"audio ﬁles\", \"related_to_core\", \"dataset\"), (\"transcripts\", \"related_to_core\", \"dataset\"), (\"audio\", \"did not match\", \"labels\"), (\"dataset\", \"consists of\", \"audio ﬁles\"), (\"dataset\", \"consists of\", \"transcripts\"), (\"chunk_196\", \"mentions\", \"audio\"), (\"chunk_196\", \"mentions\", \"labels\"), (\"chunk_196\", \"mentions\", \"episodes\"), (\"chunk_196\", \"mentions\", \"audio ﬁles\"), (\"chunk_196\", \"mentions\", \"transcripts\"), (\"dataset\", \"is_core_idea\", \"true\"), (\"chunk_196\", \"is_core_chunk\", \"true\"), (\"Kincaid46\", \"instance of\", \"dataset\")]\n",
            "✅ Extracted: [('audio', 'related_to_core', 'dataset'), ('labels', 'related_to_core', 'dataset'), ('episodes', 'related_to_core', 'dataset'), ('audio ﬁles', 'related_to_core', 'dataset'), ('transcripts', 'related_to_core', 'dataset'), ('audio', 'did not match', 'labels'), ('dataset', 'consists of', 'audio ﬁles'), ('dataset', 'consists of', 'transcripts'), ('chunk_196', 'mentions', 'audio'), ('chunk_196', 'mentions', 'labels'), ('chunk_196', 'mentions', 'episodes'), ('chunk_196', 'mentions', 'audio ﬁles'), ('chunk_196', 'mentions', 'transcripts'), ('dataset', 'is_core_idea', 'true'), ('chunk_196', 'is_core_chunk', 'true'), ('Kincaid46', 'instance of', 'dataset')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_197...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"automatic transcription service\", \"is_core_idea\", \"true\"), (\"chunk_197\", \"is_core_chunk\", \"true\"), (\"chunk_197\", \"mentions\", \"automatic transcription service\"), (\"audio ﬁles\", \"related_to_core\", \"automatic transcription service\"), (\"reference transcripts\", \"related_to_core\", \"automatic transcription service\"), (\"Airtable widget\", \"related_to_core\", \"automatic transcription service\"), (\"human transcription benchmark\", \"related_to_core\", \"automatic transcription service\"), (\"speech-datasets repository\", \"related_to_core\", \"automatic transcription service\"), (\"audio ﬁles\", \"mentions\", \"audio ﬁles\"), (\"reference transcripts\", \"mentions\", \"reference transcripts\"), (\"Airtable widget\", \"mentions\", \"Airtable widget\"), (\"human transcription benchmark\", \"mentions\", \"human transcription benchmark\"), (\"speech-datasets repository\", \"mentions\", \"speech-datasets repository\"), (\"chunk_197\", \"mentions\", \"Earnings-21\"), (\"chunk_197\", \"mentions\", \"Earnings-22\"), (\"Earnings-21\", \"related_to_core\", \"automatic transcription service\"), (\"Earnings-22\", \"related_to_core\", \"automatic transcription service\"), (\"Earnings-21\", \"mentions\", \"Earnings-21\"), (\"Earnings-22\", \"mentions\", \"Earnings-22\")]\n",
            "✅ Extracted: [('automatic transcription service', 'is_core_idea', 'true'), ('chunk_197', 'is_core_chunk', 'true'), ('chunk_197', 'mentions', 'automatic transcription service'), ('audio ﬁles', 'related_to_core', 'automatic transcription service'), ('reference transcripts', 'related_to_core', 'automatic transcription service'), ('Airtable widget', 'related_to_core', 'automatic transcription service'), ('human transcription benchmark', 'related_to_core', 'automatic transcription service'), ('speech-datasets repository', 'related_to_core', 'automatic transcription service'), ('audio ﬁles', 'mentions', 'audio ﬁles'), ('reference transcripts', 'mentions', 'reference transcripts'), ('Airtable widget', 'mentions', 'Airtable widget'), ('human transcription benchmark', 'mentions', 'human transcription benchmark'), ('speech-datasets repository', 'mentions', 'speech-datasets repository'), ('chunk_197', 'mentions', 'Earnings-21'), ('chunk_197', 'mentions', 'Earnings-22'), ('Earnings-21', 'related_to_core', 'automatic transcription service'), ('Earnings-22', 'related_to_core', 'automatic transcription service'), ('Earnings-21', 'mentions', 'Earnings-21'), ('Earnings-22', 'mentions', 'Earnings-22')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_198...\n",
            "🧪 Cleaned response for parsing:\n",
            " [(\"202206 version\", \"is_core_idea\", \"true\"), (\"chunk_198\", \"is_core_chunk\", \"true\"), (\"CORAAL\", \"related_to_core\", \"202206 version\"), (\"231 full-length interviews\", \"related_to_core\", \"202206 version\"), (\"transcripts\", \"related_to_core\", \"202206 version\"), (\"Kendall & Farrington\", \"related_to_core\", \"202206 version\"), (\"202206 version\", \"mentions\", \"version\"), (\"chunk_198\", \"mentions\", \"202206 version\"), (\"CORAAL\", \"mentions\", \"CORAAL\"), (\"chunk_198\", \"mentions\", \"CORAAL\"), (\"231 full-length interviews\", \"mentions\", \"interviews\"), (\"chunk_198\", \"mentions\", \"231 full-length interviews\"), (\"transcripts\", \"mentions\", \"transcripts\"), (\"chunk_198\", \"mentions\", \"transcripts\"), (\"Kendall & Farrington\", \"mentions\", \"Kendall & Farrington\"), (\"chunk_198\", \"mentions\", \"Kendall & Farrington\")]\n",
            "✅ Extracted: [('202206 version', 'is_core_idea', 'true'), ('chunk_198', 'is_core_chunk', 'true'), ('CORAAL', 'related_to_core', '202206 version'), ('231 full-length interviews', 'related_to_core', '202206 version'), ('transcripts', 'related_to_core', '202206 version'), ('Kendall & Farrington', 'related_to_core', '202206 version'), ('202206 version', 'mentions', 'version'), ('chunk_198', 'mentions', '202206 version'), ('CORAAL', 'mentions', 'CORAAL'), ('chunk_198', 'mentions', 'CORAAL'), ('231 full-length interviews', 'mentions', 'interviews'), ('chunk_198', 'mentions', '231 full-length interviews'), ('transcripts', 'mentions', 'transcripts'), ('chunk_198', 'mentions', 'transcripts'), ('Kendall & Farrington', 'mentions', 'Kendall & Farrington'), ('chunk_198', 'mentions', 'Kendall & Farrington')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2387680520.py:155: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 200\n",
            "Please retry in 57.605945131s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 200\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 57\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing chunk_199...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 200\n",
            "Please retry in 55.521703228s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 200\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 55\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 200\n",
            "Please retry in 51.426500703s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 200\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 51\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 200\n",
            "Please retry in 43.337349222s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 200\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 43\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 200\n",
            "Please retry in 27.253537068s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 200\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 27\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhausted",
          "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 200\nPlease retry in 55.159048619s. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 200\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 55\n}\n]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2387680520.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"🔍 Processing {chunk_id}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mtriples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_entities_and_triples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Extracted:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2387680520.py\u001b[0m in \u001b[0;36mextract_entities_and_triples\u001b[0;34m(text, chunk_id)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##to remove spaces and any thing except text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m     def _get_ls_params(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m         return cast(\n\u001b[1;32m    394\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1022\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 results.append(\n\u001b[0;32m--> 840\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    841\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1090\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"max_retries\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_retries\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     )\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"location is not supported\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    870\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 200\nPlease retry in 55.159048619s. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 200\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 55\n}\n]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import ast\n",
        "from dotenv import load_dotenv\n",
        "from neo4j import GraphDatabase\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import re\n",
        "# =======================\n",
        "# 1. Load environment\n",
        "# =======================\n",
        "load_dotenv(dotenv_path=\"/content/app.env\")\n",
        "\n",
        "# =======================\n",
        "# 2. Initialize LLM (Gemini)\n",
        "# =======================\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.5,google_api_key=\"AIzaSyAmKJYmkyia2uJxKeD_TxjXtnyeV0ZFYaI\" )\n",
        "\n",
        "def extract_entities_and_triples(text, chunk_id):\n",
        "    prompt = f\"\"\"\n",
        "You are a scientific knowledge graph extractor.\n",
        "\n",
        "Given the chunk below, extract:\n",
        "\n",
        "1. All technical or scientific **entities**.\n",
        "2. All **relationships** between entities as (subject, predicate, object).\n",
        "3. A triple linking the chunk to each entity it mentions:\n",
        "   → (\"{chunk_id}\", \"mentions\", \"EntityName\")\n",
        "\n",
        "4. If this chunk contains the **main idea**, identify the core entity and mark:\n",
        "   (\"EntityName\", \"is_core_idea\", \"true\")\n",
        "   (\"{chunk_id}\", \"is_core_chunk\", \"true\")\n",
        "\n",
        "5. If a core entity is found, link **all other entities** to it:\n",
        "   → (\"OtherEntity\", \"related_to_core\", \"CoreEntity\")\n",
        "\n",
        "📌 Format: Return a flat Python list of triples like:\n",
        "[(\"Entity1\", \"relation\", \"Entity2\"), (\"{chunk_id}\", \"mentions\", \"Entity1\")]\n",
        "\n",
        "❗ No explanation. No markdown. No code blocks.\n",
        "\n",
        "Chunk ID: {chunk_id}\n",
        "\n",
        "Text:\n",
        "\\\"\\\"\\\"{chunk_text}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    raw = response.content.strip() ##to remove spaces and any thing except text\n",
        "\n",
        "    # 1. Remove markdown or code blocks if any\n",
        "    if raw.startswith(\"```\"):\n",
        "        raw = re.sub(r\"```.*?\\n\", \"\", raw)  # remove ```python or ```text etc.\n",
        "        raw = raw.replace(\"```\", \"\").strip()\n",
        "\n",
        "    # 2. Normalize unicode symbols (e.g., convert curly quotes to ASCII)\n",
        "    raw = raw.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"’\", \"'\")\n",
        "\n",
        "    print(\"🧪 Cleaned response for parsing:\\n\", raw)\n",
        "\n",
        "    try:\n",
        "        result = ast.literal_eval(raw) #to parse returing string into list or python object\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(\"❌ Parse error:\", e)\n",
        "        return []\n",
        "# =======================\n",
        "# 3. Store triples in Neo4j\n",
        "# =======================\n",
        "def insert_triples(tx, triples, chunk_id=None, chunk_text=None):\n",
        "    for triple in triples:\n",
        "        if not isinstance(triple, (tuple, list)) or len(triple) != 3:\n",
        "            print(\"⚠️ Skipping invalid triple:\", triple)\n",
        "            continue  # skip anything that's not a 3-item tuple\n",
        "\n",
        "        s, p, o = map(str, triple)\n",
        "\n",
        "        if s.startswith(\"chunk_\") and chunk_id == s and chunk_text:\n",
        "            tx.run(\"MERGE (c:Chunk {id: $id}) SET c.text = $text\", id=s, text=chunk_text)\n",
        "        elif s.startswith(\"chunk_\"):\n",
        "            tx.run(\"MERGE (c:Chunk {id: $id})\", id=s)\n",
        "\n",
        "        if o.startswith(\"chunk_\") and chunk_id == o and chunk_text:\n",
        "            tx.run(\"MERGE (c:Chunk {id: $id}) SET c.text = $text\", id=o, text=chunk_text)\n",
        "        elif o.startswith(\"chunk_\"):\n",
        "            tx.run(\"MERGE (c:Chunk {id: $id})\", id=o)\n",
        "\n",
        "        if not s.startswith(\"chunk_\") and p != \"is_core_idea\":\n",
        "            tx.run(\"MERGE (e:Entity {name: $name})\", name=s)\n",
        "        if not o.startswith(\"chunk_\") and o.lower() != \"true\":\n",
        "            tx.run(\"MERGE (e:Entity {name: $name})\", name=o)\n",
        "\n",
        "        if p == \"mentions\":\n",
        "            tx.run(\"\"\"\n",
        "                MATCH (c:Chunk {id: $chunk_id}), (e:Entity {name: $entity})\n",
        "                MERGE (c)-[:MENTIONS]->(e)\n",
        "            \"\"\", chunk_id=s, entity=o)\n",
        "\n",
        "        elif p == \"is_core_idea\" and o.lower() == \"true\":\n",
        "            tx.run(\"\"\"\n",
        "                MATCH (e:Entity {name: $name})\n",
        "                SET e.CoreTopic = true\n",
        "            \"\"\", name=s)\n",
        "\n",
        "        elif p not in [\"mentions\", \"is_core_idea\"]:\n",
        "            tx.run(\"\"\"\n",
        "                MATCH (a:Entity {name: $s}), (b:Entity {name: $o})\n",
        "                MERGE (a)-[:RELATION {type: $p}]->(b)\n",
        "            \"\"\", s=s, o=o, p=p)\n",
        "\n",
        "# =======================\n",
        "# 4. Load and split PDF\n",
        "# =======================\n",
        "pdf_path = \"sample.pdf\"  # 📝 replace with your actual file\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "pages = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "# =======================\n",
        "# 5. Connect to Neo4j\n",
        "# =======================\n",
        "load_dotenv()\n",
        "\n",
        "print(\"URI:\", os.getenv(\"NEO4J_URI\"))\n",
        "print(\"USER:\", os.getenv(\"NEO4J_USERNAME\"))\n",
        "print(\"PASSWORD:\", os.getenv(\"NEO4J_PASSWORD\"))\n",
        "\n",
        "driver = GraphDatabase.driver(\n",
        "    os.getenv(\"NEO4J_URI\"),\n",
        "auth=(os.getenv(\"NEO4J_USERNAME\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
        ")\n",
        "def clear_database(driver):\n",
        "    with driver.session() as session:\n",
        "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
        "        print(\"🧹 Neo4j database cleared.\")\n",
        "clear_database(driver)\n",
        "# =======================\n",
        "# 6. Loop through chunks\n",
        "# =======================\n",
        "for i, chunk in enumerate(chunks):\n",
        "    chunk_id = f\"chunk_{i+1}\"\n",
        "    chunk_text = chunk.page_content\n",
        "\n",
        "    print(f\"🔍 Processing {chunk_id}...\")\n",
        "    triples = extract_entities_and_triples(chunk_text, chunk_id)\n",
        "    print(\"✅ Extracted:\", triples)\n",
        "\n",
        "    if triples:\n",
        "        with driver.session() as session:\n",
        "            session.write_transaction(insert_triples, triples, chunk_id, chunk_text)\n",
        "\n",
        "    time.sleep(2)  # to respect Gemini rate limits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8JM1pRwzoJC"
      },
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "with driver.session() as session:\n",
        "    results = session.run(\"MATCH (n)-[r]->(m) RETURN n, r, m\")\n",
        "    for record in results:\n",
        "        print(record)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S9KqvB9ZhjaU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MoBWD33aAEg-",
        "4PdQxq-4_smC",
        "Y4u-NuRukrcX"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}